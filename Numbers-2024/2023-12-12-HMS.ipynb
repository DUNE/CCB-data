{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb68654-fabc-4be8-a95b-0c8b0f37ab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/schellma/miniconda/envs/ccqe/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13bb1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUNE plot style enabled\n"
     ]
    }
   ],
   "source": [
    "# code to generate yearly summaries of DUNE data volumes from input parameters\n",
    "# rewritten from the version in the CDR - mainly by using maps of years instead of arrays to make it clearer what is in each year.\n",
    "# HMS 2022-10-23\n",
    "\n",
    "# if you have json problems, run the program ../strip.py on your file to take off comments\n",
    "# and then test using https://jsonlint.com\n",
    "#import numberutils\n",
    "\n",
    "import os,sys,string,time,commentjson,datetime, math\n",
    "import nbconvert\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "DEBUG = False\n",
    "DRAW = True\n",
    "import numpy as np\n",
    "import scipy\n",
    "import dunestyle.matplotlib as dunestyle\n",
    "\n",
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import cumulateMap\n",
    "from NumberUtils import DrawDet\n",
    "from NumberUtils import DrawType\n",
    "from NumberUtils import makeArray\n",
    "from NumberUtils import ToCSV1\n",
    "from NumberUtils import ToCSV2\n",
    "from NumberUtils import SumOver1\n",
    "from NumberUtils import SumOver2\n",
    "from NumberUtils import TableTex\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import BothTex\n",
    "from NumberUtils import extendMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9374cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many histograms to draw in multi-hist plots\n",
    "N_HISTS = 8   # exhibits all the colors in the Okabe-Ito cycler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b82775-71b5-4772-b6c5-c3dc3c5a6780",
   "metadata": {},
   "source": [
    "# specify the json file here.  Will create a subdirectory for plots with a similar name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa8269e",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONLibraryException",
     "evalue": "JSON Library Exception\n\nException thrown by library (json): \u001b[4;37m('Unable to parse text', '{ \"Version\":15,\\n    \"Changes\":[\\n        \"2023-12-12 Heidi add in HD/VD stuff\",\\n        \"2023-12-11 Heidi increase sim for ND to x4\",\\n        \"2023-11-03 Heidi commits all old changes and adds option to not do MWC\",\\n        \"2023-07-03 Kirby added some comments for documentation and worked on adding GPU for ND-LAr\",\\n        \"2023-06-30 lower memory for FD reco to 2GB\",\\n        \"2023-06-29 new ND from Mat\",\\n        \"2023-06-20 new VD/HD #\\'s from Dom\",\\n        \"2023-06-28 make NDLAr optional controled by CombinedDetectors\",\\n        \"2023-06-24 add support for analysis by detector\",\\n        \"2023-06-23 match to milestones, add NDLAr\",\\n        \"2023-06-22 update for DOE review, extend PD analysis, raise analysis levels for FD/ND\",\\n        \"2023-05-05 update for DOE review, delay PD2 yet again\",\\n        \"2023-01-31 version for FCSRG - change CERN/FNAL weights, raise ND test for 2x2\",\\n        \"2022-11-21 make units Memory weighted\",\\n        \"2022-11-18 introduce memory scaling for CPU\",\\n        \"2022-11-07 double FD Sim\",\\n        \"2022-11-07 add in memory use so cores, rescale analysis as smaller\",\\n        \"Number reprocessing is only X percent of original as you keep the hits?\",\\n        \"Number why does CPU ->0 even though Sim still running in 2027\",\\n        \"2022-10-23 update the code\",\\n        \"2022-05-19 revert pre 2023 to CdunCB sim numbers but keep updated daq estimates\",\\n        \"2022-05-18 add in MARS\",\\n        \"2022-02-21 add in new numbers for PD2, FD sim, reflect daq document\",\\n        \"2022-01-22 add actual numbers\\'s\",\\n        \"2022-01-14 updates for VD channels and new drift times.\",\\n        \"2021-07-25 see effects of PD 2 delay\",\\n        \"2021-04-27 change HSPEC06 to 11 from 15 per CMS numbers from Kirby\",\\n        \"2021-04-21 clarify CERN vs Collab for first 10 years\",\\n        \"2021-03-26 clearer plots, go to v3 of the code to preserve the RRB code in v2\",\\n        \"2021-03-24 try with CERN/FNAL combined for raw and test.\",\\n        \"2021-03-22 add Collab vs FNAL shares, restore sim disk lifetime to 2.\"\\n    ],\\n  \"Interpretation\":\" Real numbers from 2021 are shown. Disk usage was lower than the model predicts as rucio duplication was not fully implemented until late in the year so most  reconstructed data and simulation  had 1 instead of the desired 2 copies. CPU usage was lower as the detector data were not fully reprocessed in 2021. \\\\\\\\\\\\\\\\The long term model for ProtoDUNE II and the Far detector has evolved to reflect 14-bit digitization and the channel count for the vertical drift detector.\\\\\\\\pagebreak \",\\n  \"Years\":[\\n        2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        2038,  2039,   2040\\n    ],\\n  #\"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"HD\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"], # SP+DP and HD+VD are merged into ProtoDUNE and FD later\\n  \"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"LBL\",\"HighE\",\"Calib\",\"LowE\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n  \"Cap\":30, # cap in PB\\n  \"MWCWeight\":0, # logical to do MWC weight\\n  \"Base-Memory\":2000, # mb assumed memory use used for rescaling CPU.\\n  \"MaxYear\":2040,\\n  \"MinYear\":2020,\\n  \"Units\":\\n  {\"Events\":\"Million\", \"Raw-Store\":\"PB\", \"Test\":\"PB\",\"Raw+Test\":\"PB\", \"Reco-Data-Store\":\"PB\", \"Reco-Data-CPU\":\"MWC-CPU MHrs\",\\n   \"Sim-Events\":\"M\", \"Sim-Store\":\"PB\", \"Sim-CPU\":\"MWC-CPU MHrs\",\"Analysis-CPU\":\"MWC-CPU MHrs\", \"All\":\"PB\", \"Years\":\"\",\\n   \"Total-CPU\":\"MWC-CPU MHrs\", \"Cumulative-Tape\":\"PB\", \"Cumulative-Disk\":\"PB\", \"Tape\":\"PB\", \"Disk\":\"PB\",\"Cores\":\"2020-vintage MWC Cores\",\\n   \"HS23\":\"Memory weighted kHS23-yrs\", \"Wall\":\"Memory Weighted Wall MHrs\",\"HPC-Storage\":\"PB\",\"HPC-CPU\":\"MWC-CPU MHrs\",\\n   \"Reco-Data-GPU\":\"GPU MHrs\", \"Sim-GPU\":\"GPU MHrs\"\\n  },\\n  \"Formats\":\\n  {\"Events\":\"%8.1f\", \"Raw-Store\":\"%8.1f\", \"Test\":\"%8.1f\",\"Raw+Test\":\"%8.1f\", \"Reco-Data-Store\":\"%8.1f\", \"Reco-Data-CPU\":\"%8.1f\",\\n   \"Sim-Events\":\"%8.1f\", \"Sim-Store\":\"%8.1f\", \"Sim-CPU\":\"%8.1f\", \"Analysis-CPU\":\"%8.1f\",\"All\":\"%8.1f\", \"Years\":\"%d\",\\n   \"Total-CPU\":\"%8.1f\", \"Cumulative-Tape\":\"%8.1f\", \"Cumulative-Disk\":\"%8.1f\", \"Tape\":\"%8.1f\", \"Disk\":\"%8.1f\",\"Cores\":\"%d\",\\n   \"HS23\":\"%d\",\"Wall\":\"%d\",\"HPC-Storage\":\"%f8.1f\",\"HPC-CPU\":\"%8.1f\", \"Reco-Data-GPU\":\"%8.1f\", \"Sim-GPU\":\"%8.1f\"\\n    },\\n  \"CombinedDetectors\":[\"PDs\",\"FDs\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n\\n  \"//comment_about_detectors\":\"This is the start of the definitions of the different inputs for things listed in Detectors\",\\n  \"//comment_about_detectors\":\"each detector listed in the Detectors item above has an entry defining its event projections, storage, and processing profile\",\\n  \"//comment_about_detectors\":\"this includes CPU an GPU, and a memory profile for the CPU processing\",\\n\\n  \"SP\":\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":70, # from first beam test in MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, #ratio of Analysis to reco+sim\\n        \"Events\":[  10.9,   19.4,   6.5,    6.5,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[    157,    600,    500,    0,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  1.25,   5,  5,  10,     5,     0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"PDHD\":  # UPDATE FOR 2023 delay\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":140, # no compression MB/Event, 4 APA 14 bit\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        #\"Years\":[\\n        #    2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        #    2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        #    2038,  2039,   2040\\n        #],\\n        \"Events\":[  0,  0,  0,  0,  5,  5, 20, 20,  5,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5,  5,     5,     5,     5,  5,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"DP\":{\\n        \"Comment\":\"extend testing to 2024\",\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[  0,  0.5,    0.9,    2,  0,     0,     0,     0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\\n        \"Test\":[0, 42, 500, 231, 231, 231, 500, 500, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0],\\n        \"Sim-Events\":[1.25, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0]\\n    },\\n    \"PDVD\":\\n    {\"Comment\":\"extend testing to 2024\",  # 2025?\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, # Hr/Event\\n        \"Sim-CPU\":0.75, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":220, # MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  5.1,  5.1, 20.4, 20.4,  5.1,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5.1,  5.1,    5.1,     5.1,     5.1,  5.1,\\n            0.0,  0.0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"HD\":{\"Comment\":\"make testing continue from 2027\",\\n        \"Raw-Store\":3750, # no compression MB/Event\\n        \"Reco-Data-CPU\":1.25, # Hr/Event comes from scaling up ~30 sec/apa to 150 + PR\\n        \"Sim-CPU\":0.08, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40, # MB/Event based on large VD sample\\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":3000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.5, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 1000, 5000,\\n            5000, 6000, 6000, 6000, 6000, 6000, 6000,6000, 6000, 1000,\\n            1000, 1000, 1000 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 0, 10, 10, 10, 10, 10,\\n            10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\\n            10, 10, 10] #millions\\n    },\\n    \"VD\":\\n    { \"Comment\":\"make testing continue from 2028\",\\n        \"Raw-Store\":8000, # MB/Event no compression\\n        \"Reco-Data-CPU\":1.33, # # Hr/Event scale up from 30 s/CRP\\n        \"Sim-CPU\":0.13, # MB/Event\\n        \"Reco-Data-GPU\":0.1, #Hr/Event\\n        \"Sim-GPU\":0.1, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40,   # MB/Event drop hits, 2x6 \\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":4000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.0, 1.1, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            5100, 5100, 6100, 6100,6100, 6100, 6100,6100, 6100, 1100,\\n            1100, 1100, 1100 ], # small offset so you can see it\\n        \"Sim-Events\":[0, 0, 0, 0, 5.1, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2] # small offset so you can see it\\n    },\\n    \"ND-SAND\":\\n    {\"Comment\":\"Just Sand from MAT 6/29/23\",\\n        \"Raw-Store\":5, # MB/Event \\n        \"Reco-Data-CPU\":0.0022, # Hr/Event\\n        \"Sim-CPU\":0.24, # Hr/Event note that this includes the 3x data scaling for simulation\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":10, # MB/Event\\n        \"Sim-Store\":25, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n          0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n        15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    \"ND-LAr+TMS\":\\n    {\"Comment\":\"new as very different needs a lot of input from 2x2 \",\\n        \"Raw-Store\":10, # MB/Event\\n        \"Reco-Data-CPU\":0.76, # Hr/Event \\n        \"Sim-CPU\":4.6, # Hr/Event this comes from (0.384 (fid sim) x3 for data stats) + 1.15 (rock sim)) then double for systematic samples\\n        \"Reco-Data-GPU\":0.76, #Hr/Event\\n        \"Sim-GPU\":4.6, #Hr/Event this comes from (0.768 (fid sim) x3 for data stats) + 0 for sim rock) then double for systematic samples\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":50, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,  # fraction of the CPU use -  decrease as MC goes up\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n          15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    #  Parameters\\n    #\"Analysis\":\\n    #{\"Scale\":[0, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5, 0.5, 0.5,0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5,0.5,0.5],\\n    #    \"Add\":[\"PDs\", \"FDs\", \"ND-SAND\",\"ND-LAr+TMS\"]\\n    #},\\n    \"LBL\":\\n    {\"Comment\":\"NA”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  0,  0, 0, 0,  0,  0, 0,  0,  0,  0,  0.00136,  0,  0.004080,  0,  0.008160,  0, 0.016320,  0,  0.021761], #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  0,  24,    24,    0,     0,  24, 0,  0,  0,  24,  24,  0,  24,  0,  24,  0, 24,  0,  24] #millions\\n},\\n\\n    \"HighE\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 0,  0.00249,  0,  0.01,  0.015,  0,  0,  0.04,  0,  0, 0.07,  0,  0] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 14, 0,  14,  0, 14,  14,  0,  0,  14,  0,  0,  14,  0,  0, 14,  0,  0], #millions\\n},\\n\\n\\n  \"Calib\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 1.83,  3.65,  3.65,  3.65,  3.65,  3.65,  5.48,  5.48,  7.3,  7.3, 7.3,  7.3,  7.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 2.6, 2.6,  2.6,  2.6, 2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6, 2.6,  2.6,  2.6], #millions\\n},\\n\\n\\n\\n\\n    \"LowE\":\\n    {\"Comment\":This has used LBL numbers where possible, but radiologicals complicate (inflate) things.  Memory based on tests for the upcoming production”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.4, # Hr/Event   #Maybe sped up by multithreading but tests not been done \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":1500, # MB/Event             #Assumed not saving rawdigits #radiologicals\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":24000, #MB      #Radiologicals in the full FD will be a problem\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,   0,   0,   0,   0,   0,   0,    0,     0,  0, 0,  0.0091,  0,  0.046,  0,  0,  0.1,  0,  0,  0.19, 0,  0,  0.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  10, 0, 0,  10,  0, 0,  10, 0, 10,  0,  0,  10,  0,  0,  10, 0,  0,  10], #millions\\n},\\n\\n\"Reprocess\":{\"SP\":3,\"DP\":3,\"PDHD\":3, \"PDVD\":3, \"PDs\":3,\"VD\":100,\"HD\":100,\"FDs\":100,\"ND-SAND\":100,\\n        \"ND-LAr+TMS\":100,\"LBL\":100,\"Calib\":100,\"HighE\":100,\"LowE\":100}, # of years of data reprocessed when do a new pass\\n\"AnalysisExtend\":2, # of years of analysis after end of reco/sim extends CPU, and GPU and disk\\n    \"PatternFraction\":{\"SP\":0.7,\"PDHD\":0.7,\"DP\":0.7,\"PDVD\":0.7,\"PDs\":0.7,\"HD\":0.1,\"VD\":0.1,\"FDs\":0.1,\\n\\t\\t       \"ND-SAND\":0.9,\"ND-LAr+TMS\":0.9,\"MARS\":0}, #fraction of time spent on PR as opposed to hit-finding\\n    \"TapeLifetimes\":{\"Raw-Store\":100, \"Test\":0.5, \"Reco-Data-Store\":15, \"Sim-Store\":15},\\n    \"DiskLifetimes\":{\"Raw-Store\":1, \"Test\":0.5, \"Reco-Data-Store\":3, \"Sim-Store\":2},  # raw and test only hang around a short while, can be restaged\\n    \"TapeCopies\":{\"Raw-Store\":2, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1},  # will take some coding to make these work out with 2 copies.\\n    \"DiskCopies\":{\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":2, \"Sim-Store\":1.5},\\n    \"PerYear\":\\n    {\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1, \"Events\":1, \"Sim-Events\":1, \"Reco-Data-CPU\":1, \"Sim-CPU\":1, \"Analysis\":1, \"Analysis-CPU\":1, \"Reco-Data-GPU\":1, \"Sim-GPU\":1}, # of times you redo them per year, CPU is reco CPU, Sim-CPU is sim CPU\\n    \"Cores\":{\\n        \"Efficiency\":0.7,  # CPU conversion to Wall time, per K. Herner\\n        \"2020Units\":1  # raise this # if machines get faster\\n    },\\n    \"kHEPSPEC06PerCPU\":0.011,\\n    \"FiscalYearStart\":\"April 1\",\\n    \"CPU Accounting\":\"end of fiscal year\",\\n    \"Tape Accounting\":\"end of fiscal year\",\\n    \"Disk Accounting\":\"October 1\",\\n    \"TypeColors\": {\"Raw-Store\":\"blue\",\"Raw+Test\":\"green\", \"Test\":\"orange\", \"Reco-Data-Store\":\"red\", \"Sim-Store\":\"grey\", \"Total\":\"black\",\"FNAL\":\"blue\",\"UK\":\"red\",\"CZ\":\"green\",\"CERN\":\"cyan\",\"US\":\"orange\"},\\n    \"TypeLines\": {\"Raw-Store\":\"solid\",\"Raw+Test\":\"solid\", \"Test\":\"dashed\", \"Reco-Data-Store\":\"solid\", \"Sim-Store\":\"dashed\", \"Total\":\"solid\"},\\n    \"DetColors\": {\"SP\":\"green\",\"PDHD\":\"green\", \"DP\":\"magenta\",\"PDVD\":\"magenta\", \"PDs\":\"blue\", \"HD\":\"red\",\\n        \"VD\":\"red\",\"FDs\":\"red\",\"ND-SAND\":\"grey\",\"ND-LAr+TMS\":\"black\",\"Analysis\":\"orange\", \"Total\":\"black\",\"MARS\":\"purple\",\\n        \"Production\":\"blue\", \"FNAL\":\"orange\", \"CERN\":\"cyan\", \"National\":\"green\", \"LBL\":\"magenta\",\"Calib\":\"cyan\",\"HighE\":\"purple\",\"LowE\":\"blue\"\\n    },\\n    \"DetLines\": {\"SP\":\"solid\",\"PDHD\":\"dashed\", \"DP\":\"solid\",\"PDVD\":\"dotted\", \"PDs\":\"solid\", \"HD\":\"solid\",\\n        \"VD\":\"dashed\",\"FDs\":\"solid\",\"ND-SAND\":\"solid\",\"ND-LAr+TMS\":\"dashed\", \"MARS\":\"dashed\",\"Analysis\":\"dashed\", \"Total\":\"solid\",\"FNAL\":\"solid\", \"CERN\":\"solid\", \"National\":\"solid\",\"LBL\":\"dotted\",\"Calib\":\"dotted\",\"HighE\":\"dotted\",\"LowE\":\"dotted\"\\n        \\n    },\\n    \"SplitsYear\":2029,\\n    \"SplitsEarly\":{ # these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Reco-Data-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0}\\n        },\\n        \"Disk\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Reco-Data-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.00}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5}}\\n    },\\n    \"SplitsLater\":{# these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.50},\\n            \"Sim-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Reco-Data-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"Disk\":{\\n            #\"Disk\":{\"Raw-Store\":0.0,\"Sim-Store\":0.75,\"Reco-Data-Store\":0.75,\"Test\":0.00} old version\\n            \"Raw-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Reco-Data-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}}\\n    },\\n    \\n    \"Explain\":{\\n        \"Detectors\":\"Detectors included in the calculation\",\\n        \"Cap\":\"Cap on Raw data/year in PB\",\\n        \"Base-Memory\":\"MB of memory per slot assumed as the average\",\\n        \"MaxYear\":\"Plot until year\",\\n        \"MinYear\":\"Plot starting with year\",\\n        \"Reprocess\":\"Number of years of data reprocessed when doing a new pass\",\\n        \"AnalysisExtend\":\"Years analysis continues after last reco/sim\",\\n        \"PatternFraction\":\"Fraction of time taken in pattern recognition\",\\n        \"TapeLifetimes\":\"Number of years kept on tape\",\\n        \"DiskLifetimes\":\"Number of years kept on disk\",\\n        \"TapeCopies\":\"Number of copies kept on tape\",\\n        \"DiskCopies\":\"Number of copies kept on disk\",\\n        \"PerYear\":\"Number of reprocessing done per year\",\\n        \"Cores\":\"Description of cores, efficiency and speed relative to 2020 vintage\",\\n        \"kHEPSPEC06PerCPU\":\"kHEPSPEC06 per core assumed\",\\n        \"SplitsYear\":\"Year CERN no longer responsible for disk or tape\",\\n        \"SplitsEarly\":\"Division between FNAL/CERN/National for storage until SplitsYear\",\\n        \"SplitsLater\":\"Division between FNAL/CERN/National for storage after SplitsYear\"\\n    },\\n    // \"Actual\":{\\n    //     \"wallactual\": {\"2021\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3},\\n    //         \"2022\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3}\\n    //     },\\n\\n    //     \"diskactual\":{\\n    //         \"2021\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30},\\n    //         \"2022\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30}\\n    //     },\\n    //     \"tapeactual\":{\\n    //         \"2021\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0},\\n    //         \"2022\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0}\\n    //     }\\n    // }\\n}\\n')\u001b[0m\n\n    Traceback (most recent call last):\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 598, in lex\n        token = self.root_lexer.next_token(lexer_state, parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 528, in next_token\n        raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n    lark.exceptions.UnexpectedCharacters: No terminal matches '\"' in the current parser context, at line 248 col 16\n    \n        {\"Comment\":\"NA”\n                   ^\n    Expected one of: \n    \t* COLON\n    \t* LBRACE\n    \t* TRUE\n    \t* FALSE\n    \t* SIGNED_NUMBER\n    \t* NULL\n    \t* RBRACE\n    \t* TRAILING_COMMA\n    \t* ESCAPED_STRING\n    \t* RSQB\n    \t* LSQB\n    \n    Previous tokens: Token('COLON', ':')\n    \n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 180, in loads\n        parsed = _remove_trailing_commas(parser.parse(text))\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lark.py\", line 645, in parse\n        return self.parser.parse(text, start=start, on_error=on_error)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parser_frontends.py\", line 96, in parse\n        return self.parser.parse(stream, chosen_start, **kw)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 41, in parse\n        return self.parser.parse(lexer, start)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 171, in parse\n        return self.parse_from_state(parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 188, in parse_from_state\n        raise e\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 178, in parse_from_state\n        for token in state.lexer.lex(state):\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 601, in lex\n        raise e  # Raise the original UnexpectedCharacters. The root lexer raises it with the wrong expected set.\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 590, in lex\n        yield lexer.next_token(lexer_state, parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 528, in next_token\n        raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n    lark.exceptions.UnexpectedCharacters: No terminal matches '\"' in the current parser context, at line 248 col 16\n    \n        {\"Comment\":\"NA”\n                   ^\n    Expected one of: \n    \t* LBRACE\n    \t* TRUE\n    \t* FALSE\n    \t* SIGNED_NUMBER\n    \t* NULL\n    \t* ESCAPED_STRING\n    \t* LSQB\n    \n    Previous tokens: Token('COLON', ':')\n    \n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 215, in load\n        return loads(fp.read(), **kwargs)\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 183, in loads\n        raise ValueError('Unable to parse text', text)\n    ValueError: ('Unable to parse text', '{ \"Version\":15,\\n    \"Changes\":[\\n        \"2023-12-12 Heidi add in HD/VD stuff\",\\n        \"2023-12-11 Heidi increase sim for ND to x4\",\\n        \"2023-11-03 Heidi commits all old changes and adds option to not do MWC\",\\n        \"2023-07-03 Kirby added some comments for documentation and worked on adding GPU for ND-LAr\",\\n        \"2023-06-30 lower memory for FD reco to 2GB\",\\n        \"2023-06-29 new ND from Mat\",\\n        \"2023-06-20 new VD/HD #\\'s from Dom\",\\n        \"2023-06-28 make NDLAr optional controled by CombinedDetectors\",\\n        \"2023-06-24 add support for analysis by detector\",\\n        \"2023-06-23 match to milestones, add NDLAr\",\\n        \"2023-06-22 update for DOE review, extend PD analysis, raise analysis levels for FD/ND\",\\n        \"2023-05-05 update for DOE review, delay PD2 yet again\",\\n        \"2023-01-31 version for FCSRG - change CERN/FNAL weights, raise ND test for 2x2\",\\n        \"2022-11-21 make units Memory weighted\",\\n        \"2022-11-18 introduce memory scaling for CPU\",\\n        \"2022-11-07 double FD Sim\",\\n        \"2022-11-07 add in memory use so cores, rescale analysis as smaller\",\\n        \"Number reprocessing is only X percent of original as you keep the hits?\",\\n        \"Number why does CPU ->0 even though Sim still running in 2027\",\\n        \"2022-10-23 update the code\",\\n        \"2022-05-19 revert pre 2023 to CdunCB sim numbers but keep updated daq estimates\",\\n        \"2022-05-18 add in MARS\",\\n        \"2022-02-21 add in new numbers for PD2, FD sim, reflect daq document\",\\n        \"2022-01-22 add actual numbers\\'s\",\\n        \"2022-01-14 updates for VD channels and new drift times.\",\\n        \"2021-07-25 see effects of PD 2 delay\",\\n        \"2021-04-27 change HSPEC06 to 11 from 15 per CMS numbers from Kirby\",\\n        \"2021-04-21 clarify CERN vs Collab for first 10 years\",\\n        \"2021-03-26 clearer plots, go to v3 of the code to preserve the RRB code in v2\",\\n        \"2021-03-24 try with CERN/FNAL combined for raw and test.\",\\n        \"2021-03-22 add Collab vs FNAL shares, restore sim disk lifetime to 2.\"\\n    ],\\n  \"Interpretation\":\" Real numbers from 2021 are shown. Disk usage was lower than the model predicts as rucio duplication was not fully implemented until late in the year so most  reconstructed data and simulation  had 1 instead of the desired 2 copies. CPU usage was lower as the detector data were not fully reprocessed in 2021. \\\\\\\\\\\\\\\\The long term model for ProtoDUNE II and the Far detector has evolved to reflect 14-bit digitization and the channel count for the vertical drift detector.\\\\\\\\pagebreak \",\\n  \"Years\":[\\n        2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        2038,  2039,   2040\\n    ],\\n  #\"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"HD\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"], # SP+DP and HD+VD are merged into ProtoDUNE and FD later\\n  \"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"LBL\",\"HighE\",\"Calib\",\"LowE\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n  \"Cap\":30, # cap in PB\\n  \"MWCWeight\":0, # logical to do MWC weight\\n  \"Base-Memory\":2000, # mb assumed memory use used for rescaling CPU.\\n  \"MaxYear\":2040,\\n  \"MinYear\":2020,\\n  \"Units\":\\n  {\"Events\":\"Million\", \"Raw-Store\":\"PB\", \"Test\":\"PB\",\"Raw+Test\":\"PB\", \"Reco-Data-Store\":\"PB\", \"Reco-Data-CPU\":\"MWC-CPU MHrs\",\\n   \"Sim-Events\":\"M\", \"Sim-Store\":\"PB\", \"Sim-CPU\":\"MWC-CPU MHrs\",\"Analysis-CPU\":\"MWC-CPU MHrs\", \"All\":\"PB\", \"Years\":\"\",\\n   \"Total-CPU\":\"MWC-CPU MHrs\", \"Cumulative-Tape\":\"PB\", \"Cumulative-Disk\":\"PB\", \"Tape\":\"PB\", \"Disk\":\"PB\",\"Cores\":\"2020-vintage MWC Cores\",\\n   \"HS23\":\"Memory weighted kHS23-yrs\", \"Wall\":\"Memory Weighted Wall MHrs\",\"HPC-Storage\":\"PB\",\"HPC-CPU\":\"MWC-CPU MHrs\",\\n   \"Reco-Data-GPU\":\"GPU MHrs\", \"Sim-GPU\":\"GPU MHrs\"\\n  },\\n  \"Formats\":\\n  {\"Events\":\"%8.1f\", \"Raw-Store\":\"%8.1f\", \"Test\":\"%8.1f\",\"Raw+Test\":\"%8.1f\", \"Reco-Data-Store\":\"%8.1f\", \"Reco-Data-CPU\":\"%8.1f\",\\n   \"Sim-Events\":\"%8.1f\", \"Sim-Store\":\"%8.1f\", \"Sim-CPU\":\"%8.1f\", \"Analysis-CPU\":\"%8.1f\",\"All\":\"%8.1f\", \"Years\":\"%d\",\\n   \"Total-CPU\":\"%8.1f\", \"Cumulative-Tape\":\"%8.1f\", \"Cumulative-Disk\":\"%8.1f\", \"Tape\":\"%8.1f\", \"Disk\":\"%8.1f\",\"Cores\":\"%d\",\\n   \"HS23\":\"%d\",\"Wall\":\"%d\",\"HPC-Storage\":\"%f8.1f\",\"HPC-CPU\":\"%8.1f\", \"Reco-Data-GPU\":\"%8.1f\", \"Sim-GPU\":\"%8.1f\"\\n    },\\n  \"CombinedDetectors\":[\"PDs\",\"FDs\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n\\n  \"//comment_about_detectors\":\"This is the start of the definitions of the different inputs for things listed in Detectors\",\\n  \"//comment_about_detectors\":\"each detector listed in the Detectors item above has an entry defining its event projections, storage, and processing profile\",\\n  \"//comment_about_detectors\":\"this includes CPU an GPU, and a memory profile for the CPU processing\",\\n\\n  \"SP\":\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":70, # from first beam test in MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, #ratio of Analysis to reco+sim\\n        \"Events\":[  10.9,   19.4,   6.5,    6.5,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[    157,    600,    500,    0,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  1.25,   5,  5,  10,     5,     0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"PDHD\":  # UPDATE FOR 2023 delay\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":140, # no compression MB/Event, 4 APA 14 bit\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        #\"Years\":[\\n        #    2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        #    2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        #    2038,  2039,   2040\\n        #],\\n        \"Events\":[  0,  0,  0,  0,  5,  5, 20, 20,  5,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5,  5,     5,     5,     5,  5,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"DP\":{\\n        \"Comment\":\"extend testing to 2024\",\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[  0,  0.5,    0.9,    2,  0,     0,     0,     0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\\n        \"Test\":[0, 42, 500, 231, 231, 231, 500, 500, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0],\\n        \"Sim-Events\":[1.25, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0]\\n    },\\n    \"PDVD\":\\n    {\"Comment\":\"extend testing to 2024\",  # 2025?\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, # Hr/Event\\n        \"Sim-CPU\":0.75, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":220, # MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  5.1,  5.1, 20.4, 20.4,  5.1,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5.1,  5.1,    5.1,     5.1,     5.1,  5.1,\\n            0.0,  0.0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"HD\":{\"Comment\":\"make testing continue from 2027\",\\n        \"Raw-Store\":3750, # no compression MB/Event\\n        \"Reco-Data-CPU\":1.25, # Hr/Event comes from scaling up ~30 sec/apa to 150 + PR\\n        \"Sim-CPU\":0.08, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40, # MB/Event based on large VD sample\\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":3000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.5, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 1000, 5000,\\n            5000, 6000, 6000, 6000, 6000, 6000, 6000,6000, 6000, 1000,\\n            1000, 1000, 1000 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 0, 10, 10, 10, 10, 10,\\n            10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\\n            10, 10, 10] #millions\\n    },\\n    \"VD\":\\n    { \"Comment\":\"make testing continue from 2028\",\\n        \"Raw-Store\":8000, # MB/Event no compression\\n        \"Reco-Data-CPU\":1.33, # # Hr/Event scale up from 30 s/CRP\\n        \"Sim-CPU\":0.13, # MB/Event\\n        \"Reco-Data-GPU\":0.1, #Hr/Event\\n        \"Sim-GPU\":0.1, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40,   # MB/Event drop hits, 2x6 \\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":4000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.0, 1.1, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            5100, 5100, 6100, 6100,6100, 6100, 6100,6100, 6100, 1100,\\n            1100, 1100, 1100 ], # small offset so you can see it\\n        \"Sim-Events\":[0, 0, 0, 0, 5.1, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2] # small offset so you can see it\\n    },\\n    \"ND-SAND\":\\n    {\"Comment\":\"Just Sand from MAT 6/29/23\",\\n        \"Raw-Store\":5, # MB/Event \\n        \"Reco-Data-CPU\":0.0022, # Hr/Event\\n        \"Sim-CPU\":0.24, # Hr/Event note that this includes the 3x data scaling for simulation\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":10, # MB/Event\\n        \"Sim-Store\":25, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n          0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n        15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    \"ND-LAr+TMS\":\\n    {\"Comment\":\"new as very different needs a lot of input from 2x2 \",\\n        \"Raw-Store\":10, # MB/Event\\n        \"Reco-Data-CPU\":0.76, # Hr/Event \\n        \"Sim-CPU\":4.6, # Hr/Event this comes from (0.384 (fid sim) x3 for data stats) + 1.15 (rock sim)) then double for systematic samples\\n        \"Reco-Data-GPU\":0.76, #Hr/Event\\n        \"Sim-GPU\":4.6, #Hr/Event this comes from (0.768 (fid sim) x3 for data stats) + 0 for sim rock) then double for systematic samples\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":50, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,  # fraction of the CPU use -  decrease as MC goes up\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n          15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    #  Parameters\\n    #\"Analysis\":\\n    #{\"Scale\":[0, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5, 0.5, 0.5,0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5,0.5,0.5],\\n    #    \"Add\":[\"PDs\", \"FDs\", \"ND-SAND\",\"ND-LAr+TMS\"]\\n    #},\\n    \"LBL\":\\n    {\"Comment\":\"NA”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  0,  0, 0, 0,  0,  0, 0,  0,  0,  0,  0.00136,  0,  0.004080,  0,  0.008160,  0, 0.016320,  0,  0.021761], #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  0,  24,    24,    0,     0,  24, 0,  0,  0,  24,  24,  0,  24,  0,  24,  0, 24,  0,  24] #millions\\n},\\n\\n    \"HighE\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 0,  0.00249,  0,  0.01,  0.015,  0,  0,  0.04,  0,  0, 0.07,  0,  0] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 14, 0,  14,  0, 14,  14,  0,  0,  14,  0,  0,  14,  0,  0, 14,  0,  0], #millions\\n},\\n\\n\\n  \"Calib\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 1.83,  3.65,  3.65,  3.65,  3.65,  3.65,  5.48,  5.48,  7.3,  7.3, 7.3,  7.3,  7.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 2.6, 2.6,  2.6,  2.6, 2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6, 2.6,  2.6,  2.6], #millions\\n},\\n\\n\\n\\n\\n    \"LowE\":\\n    {\"Comment\":This has used LBL numbers where possible, but radiologicals complicate (inflate) things.  Memory based on tests for the upcoming production”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.4, # Hr/Event   #Maybe sped up by multithreading but tests not been done \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":1500, # MB/Event             #Assumed not saving rawdigits #radiologicals\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":24000, #MB      #Radiologicals in the full FD will be a problem\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,   0,   0,   0,   0,   0,   0,    0,     0,  0, 0,  0.0091,  0,  0.046,  0,  0,  0.1,  0,  0,  0.19, 0,  0,  0.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  10, 0, 0,  10,  0, 0,  10, 0, 10,  0,  0,  10,  0,  0,  10, 0,  0,  10], #millions\\n},\\n\\n\"Reprocess\":{\"SP\":3,\"DP\":3,\"PDHD\":3, \"PDVD\":3, \"PDs\":3,\"VD\":100,\"HD\":100,\"FDs\":100,\"ND-SAND\":100,\\n        \"ND-LAr+TMS\":100,\"LBL\":100,\"Calib\":100,\"HighE\":100,\"LowE\":100}, # of years of data reprocessed when do a new pass\\n\"AnalysisExtend\":2, # of years of analysis after end of reco/sim extends CPU, and GPU and disk\\n    \"PatternFraction\":{\"SP\":0.7,\"PDHD\":0.7,\"DP\":0.7,\"PDVD\":0.7,\"PDs\":0.7,\"HD\":0.1,\"VD\":0.1,\"FDs\":0.1,\\n\\t\\t       \"ND-SAND\":0.9,\"ND-LAr+TMS\":0.9,\"MARS\":0}, #fraction of time spent on PR as opposed to hit-finding\\n    \"TapeLifetimes\":{\"Raw-Store\":100, \"Test\":0.5, \"Reco-Data-Store\":15, \"Sim-Store\":15},\\n    \"DiskLifetimes\":{\"Raw-Store\":1, \"Test\":0.5, \"Reco-Data-Store\":3, \"Sim-Store\":2},  # raw and test only hang around a short while, can be restaged\\n    \"TapeCopies\":{\"Raw-Store\":2, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1},  # will take some coding to make these work out with 2 copies.\\n    \"DiskCopies\":{\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":2, \"Sim-Store\":1.5},\\n    \"PerYear\":\\n    {\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1, \"Events\":1, \"Sim-Events\":1, \"Reco-Data-CPU\":1, \"Sim-CPU\":1, \"Analysis\":1, \"Analysis-CPU\":1, \"Reco-Data-GPU\":1, \"Sim-GPU\":1}, # of times you redo them per year, CPU is reco CPU, Sim-CPU is sim CPU\\n    \"Cores\":{\\n        \"Efficiency\":0.7,  # CPU conversion to Wall time, per K. Herner\\n        \"2020Units\":1  # raise this # if machines get faster\\n    },\\n    \"kHEPSPEC06PerCPU\":0.011,\\n    \"FiscalYearStart\":\"April 1\",\\n    \"CPU Accounting\":\"end of fiscal year\",\\n    \"Tape Accounting\":\"end of fiscal year\",\\n    \"Disk Accounting\":\"October 1\",\\n    \"TypeColors\": {\"Raw-Store\":\"blue\",\"Raw+Test\":\"green\", \"Test\":\"orange\", \"Reco-Data-Store\":\"red\", \"Sim-Store\":\"grey\", \"Total\":\"black\",\"FNAL\":\"blue\",\"UK\":\"red\",\"CZ\":\"green\",\"CERN\":\"cyan\",\"US\":\"orange\"},\\n    \"TypeLines\": {\"Raw-Store\":\"solid\",\"Raw+Test\":\"solid\", \"Test\":\"dashed\", \"Reco-Data-Store\":\"solid\", \"Sim-Store\":\"dashed\", \"Total\":\"solid\"},\\n    \"DetColors\": {\"SP\":\"green\",\"PDHD\":\"green\", \"DP\":\"magenta\",\"PDVD\":\"magenta\", \"PDs\":\"blue\", \"HD\":\"red\",\\n        \"VD\":\"red\",\"FDs\":\"red\",\"ND-SAND\":\"grey\",\"ND-LAr+TMS\":\"black\",\"Analysis\":\"orange\", \"Total\":\"black\",\"MARS\":\"purple\",\\n        \"Production\":\"blue\", \"FNAL\":\"orange\", \"CERN\":\"cyan\", \"National\":\"green\", \"LBL\":\"magenta\",\"Calib\":\"cyan\",\"HighE\":\"purple\",\"LowE\":\"blue\"\\n    },\\n    \"DetLines\": {\"SP\":\"solid\",\"PDHD\":\"dashed\", \"DP\":\"solid\",\"PDVD\":\"dotted\", \"PDs\":\"solid\", \"HD\":\"solid\",\\n        \"VD\":\"dashed\",\"FDs\":\"solid\",\"ND-SAND\":\"solid\",\"ND-LAr+TMS\":\"dashed\", \"MARS\":\"dashed\",\"Analysis\":\"dashed\", \"Total\":\"solid\",\"FNAL\":\"solid\", \"CERN\":\"solid\", \"National\":\"solid\",\"LBL\":\"dotted\",\"Calib\":\"dotted\",\"HighE\":\"dotted\",\"LowE\":\"dotted\"\\n        \\n    },\\n    \"SplitsYear\":2029,\\n    \"SplitsEarly\":{ # these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Reco-Data-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0}\\n        },\\n        \"Disk\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Reco-Data-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.00}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5}}\\n    },\\n    \"SplitsLater\":{# these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.50},\\n            \"Sim-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Reco-Data-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"Disk\":{\\n            #\"Disk\":{\"Raw-Store\":0.0,\"Sim-Store\":0.75,\"Reco-Data-Store\":0.75,\"Test\":0.00} old version\\n            \"Raw-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Reco-Data-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}}\\n    },\\n    \\n    \"Explain\":{\\n        \"Detectors\":\"Detectors included in the calculation\",\\n        \"Cap\":\"Cap on Raw data/year in PB\",\\n        \"Base-Memory\":\"MB of memory per slot assumed as the average\",\\n        \"MaxYear\":\"Plot until year\",\\n        \"MinYear\":\"Plot starting with year\",\\n        \"Reprocess\":\"Number of years of data reprocessed when doing a new pass\",\\n        \"AnalysisExtend\":\"Years analysis continues after last reco/sim\",\\n        \"PatternFraction\":\"Fraction of time taken in pattern recognition\",\\n        \"TapeLifetimes\":\"Number of years kept on tape\",\\n        \"DiskLifetimes\":\"Number of years kept on disk\",\\n        \"TapeCopies\":\"Number of copies kept on tape\",\\n        \"DiskCopies\":\"Number of copies kept on disk\",\\n        \"PerYear\":\"Number of reprocessing done per year\",\\n        \"Cores\":\"Description of cores, efficiency and speed relative to 2020 vintage\",\\n        \"kHEPSPEC06PerCPU\":\"kHEPSPEC06 per core assumed\",\\n        \"SplitsYear\":\"Year CERN no longer responsible for disk or tape\",\\n        \"SplitsEarly\":\"Division between FNAL/CERN/National for storage until SplitsYear\",\\n        \"SplitsLater\":\"Division between FNAL/CERN/National for storage after SplitsYear\"\\n    },\\n    // \"Actual\":{\\n    //     \"wallactual\": {\"2021\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3},\\n    //         \"2022\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3}\\n    //     },\\n\\n    //     \"diskactual\":{\\n    //         \"2021\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30},\\n    //         \"2022\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30}\\n    //     },\\n    //     \"tapeactual\":{\\n    //         \"2021\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0},\\n    //         \"2022\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0}\\n    //     }\\n    // }\\n}\\n')\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py:598\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    597\u001b[0m last_token \u001b[38;5;241m=\u001b[39m lexer_state\u001b[38;5;241m.\u001b[39mlast_token  \u001b[38;5;66;03m# Save last_token. Calling root_lexer.next_token will change this to the wrong token\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_lexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, e\u001b[38;5;241m.\u001b[39mallowed, state\u001b[38;5;241m=\u001b[39mparser_state, token_history\u001b[38;5;241m=\u001b[39m[last_token], terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mterminals_by_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py:528\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[0;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[1;32m    527\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[1;32m    529\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[1;32m    530\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    532\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m: No terminal matches '\"' in the current parser context, at line 248 col 16\n\n    {\"Comment\":\"NA”\n               ^\nExpected one of: \n\t* COLON\n\t* LBRACE\n\t* TRUE\n\t* FALSE\n\t* SIGNED_NUMBER\n\t* NULL\n\t* RBRACE\n\t* TRAILING_COMMA\n\t* ESCAPED_STRING\n\t* RSQB\n\t* LSQB\n\nPrevious tokens: Token('COLON', ':')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py:180\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(text, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m _remove_trailing_commas(\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    181\u001b[0m     final_text \u001b[38;5;241m=\u001b[39m serializer\u001b[38;5;241m.\u001b[39mreconstruct(parsed)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lark.py:645\u001b[0m, in \u001b[0;36mLark.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parser_frontends.py:96\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m     95\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py:41\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py:171\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py:188\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py:178\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    177\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mlexer\u001b[38;5;241m.\u001b[39mlex(state):\n\u001b[1;32m    179\u001b[0m     state\u001b[38;5;241m.\u001b[39mfeed_token(token)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py:601\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedCharacters:\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py:590\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    589\u001b[0m         lexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexers[parser_state\u001b[38;5;241m.\u001b[39mposition]\n\u001b[0;32m--> 590\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py:528\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[0;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[1;32m    527\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[1;32m    529\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[1;32m    530\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    532\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m: No terminal matches '\"' in the current parser context, at line 248 col 16\n\n    {\"Comment\":\"NA”\n               ^\nExpected one of: \n\t* LBRACE\n\t* TRUE\n\t* FALSE\n\t* SIGNED_NUMBER\n\t* NULL\n\t* ESCAPED_STRING\n\t* LSQB\n\nPrevious tokens: Token('COLON', ':')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py:215\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py:183\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(text, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m lark\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mUnexpectedCharacters:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to parse text\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(final_text, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: ('Unable to parse text', '{ \"Version\":15,\\n    \"Changes\":[\\n        \"2023-12-12 Heidi add in HD/VD stuff\",\\n        \"2023-12-11 Heidi increase sim for ND to x4\",\\n        \"2023-11-03 Heidi commits all old changes and adds option to not do MWC\",\\n        \"2023-07-03 Kirby added some comments for documentation and worked on adding GPU for ND-LAr\",\\n        \"2023-06-30 lower memory for FD reco to 2GB\",\\n        \"2023-06-29 new ND from Mat\",\\n        \"2023-06-20 new VD/HD #\\'s from Dom\",\\n        \"2023-06-28 make NDLAr optional controled by CombinedDetectors\",\\n        \"2023-06-24 add support for analysis by detector\",\\n        \"2023-06-23 match to milestones, add NDLAr\",\\n        \"2023-06-22 update for DOE review, extend PD analysis, raise analysis levels for FD/ND\",\\n        \"2023-05-05 update for DOE review, delay PD2 yet again\",\\n        \"2023-01-31 version for FCSRG - change CERN/FNAL weights, raise ND test for 2x2\",\\n        \"2022-11-21 make units Memory weighted\",\\n        \"2022-11-18 introduce memory scaling for CPU\",\\n        \"2022-11-07 double FD Sim\",\\n        \"2022-11-07 add in memory use so cores, rescale analysis as smaller\",\\n        \"Number reprocessing is only X percent of original as you keep the hits?\",\\n        \"Number why does CPU ->0 even though Sim still running in 2027\",\\n        \"2022-10-23 update the code\",\\n        \"2022-05-19 revert pre 2023 to CdunCB sim numbers but keep updated daq estimates\",\\n        \"2022-05-18 add in MARS\",\\n        \"2022-02-21 add in new numbers for PD2, FD sim, reflect daq document\",\\n        \"2022-01-22 add actual numbers\\'s\",\\n        \"2022-01-14 updates for VD channels and new drift times.\",\\n        \"2021-07-25 see effects of PD 2 delay\",\\n        \"2021-04-27 change HSPEC06 to 11 from 15 per CMS numbers from Kirby\",\\n        \"2021-04-21 clarify CERN vs Collab for first 10 years\",\\n        \"2021-03-26 clearer plots, go to v3 of the code to preserve the RRB code in v2\",\\n        \"2021-03-24 try with CERN/FNAL combined for raw and test.\",\\n        \"2021-03-22 add Collab vs FNAL shares, restore sim disk lifetime to 2.\"\\n    ],\\n  \"Interpretation\":\" Real numbers from 2021 are shown. Disk usage was lower than the model predicts as rucio duplication was not fully implemented until late in the year so most  reconstructed data and simulation  had 1 instead of the desired 2 copies. CPU usage was lower as the detector data were not fully reprocessed in 2021. \\\\\\\\\\\\\\\\The long term model for ProtoDUNE II and the Far detector has evolved to reflect 14-bit digitization and the channel count for the vertical drift detector.\\\\\\\\pagebreak \",\\n  \"Years\":[\\n        2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        2038,  2039,   2040\\n    ],\\n  #\"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"HD\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"], # SP+DP and HD+VD are merged into ProtoDUNE and FD later\\n  \"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"LBL\",\"HighE\",\"Calib\",\"LowE\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n  \"Cap\":30, # cap in PB\\n  \"MWCWeight\":0, # logical to do MWC weight\\n  \"Base-Memory\":2000, # mb assumed memory use used for rescaling CPU.\\n  \"MaxYear\":2040,\\n  \"MinYear\":2020,\\n  \"Units\":\\n  {\"Events\":\"Million\", \"Raw-Store\":\"PB\", \"Test\":\"PB\",\"Raw+Test\":\"PB\", \"Reco-Data-Store\":\"PB\", \"Reco-Data-CPU\":\"MWC-CPU MHrs\",\\n   \"Sim-Events\":\"M\", \"Sim-Store\":\"PB\", \"Sim-CPU\":\"MWC-CPU MHrs\",\"Analysis-CPU\":\"MWC-CPU MHrs\", \"All\":\"PB\", \"Years\":\"\",\\n   \"Total-CPU\":\"MWC-CPU MHrs\", \"Cumulative-Tape\":\"PB\", \"Cumulative-Disk\":\"PB\", \"Tape\":\"PB\", \"Disk\":\"PB\",\"Cores\":\"2020-vintage MWC Cores\",\\n   \"HS23\":\"Memory weighted kHS23-yrs\", \"Wall\":\"Memory Weighted Wall MHrs\",\"HPC-Storage\":\"PB\",\"HPC-CPU\":\"MWC-CPU MHrs\",\\n   \"Reco-Data-GPU\":\"GPU MHrs\", \"Sim-GPU\":\"GPU MHrs\"\\n  },\\n  \"Formats\":\\n  {\"Events\":\"%8.1f\", \"Raw-Store\":\"%8.1f\", \"Test\":\"%8.1f\",\"Raw+Test\":\"%8.1f\", \"Reco-Data-Store\":\"%8.1f\", \"Reco-Data-CPU\":\"%8.1f\",\\n   \"Sim-Events\":\"%8.1f\", \"Sim-Store\":\"%8.1f\", \"Sim-CPU\":\"%8.1f\", \"Analysis-CPU\":\"%8.1f\",\"All\":\"%8.1f\", \"Years\":\"%d\",\\n   \"Total-CPU\":\"%8.1f\", \"Cumulative-Tape\":\"%8.1f\", \"Cumulative-Disk\":\"%8.1f\", \"Tape\":\"%8.1f\", \"Disk\":\"%8.1f\",\"Cores\":\"%d\",\\n   \"HS23\":\"%d\",\"Wall\":\"%d\",\"HPC-Storage\":\"%f8.1f\",\"HPC-CPU\":\"%8.1f\", \"Reco-Data-GPU\":\"%8.1f\", \"Sim-GPU\":\"%8.1f\"\\n    },\\n  \"CombinedDetectors\":[\"PDs\",\"FDs\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n\\n  \"//comment_about_detectors\":\"This is the start of the definitions of the different inputs for things listed in Detectors\",\\n  \"//comment_about_detectors\":\"each detector listed in the Detectors item above has an entry defining its event projections, storage, and processing profile\",\\n  \"//comment_about_detectors\":\"this includes CPU an GPU, and a memory profile for the CPU processing\",\\n\\n  \"SP\":\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":70, # from first beam test in MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, #ratio of Analysis to reco+sim\\n        \"Events\":[  10.9,   19.4,   6.5,    6.5,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[    157,    600,    500,    0,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  1.25,   5,  5,  10,     5,     0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"PDHD\":  # UPDATE FOR 2023 delay\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":140, # no compression MB/Event, 4 APA 14 bit\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        #\"Years\":[\\n        #    2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        #    2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        #    2038,  2039,   2040\\n        #],\\n        \"Events\":[  0,  0,  0,  0,  5,  5, 20, 20,  5,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5,  5,     5,     5,     5,  5,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"DP\":{\\n        \"Comment\":\"extend testing to 2024\",\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[  0,  0.5,    0.9,    2,  0,     0,     0,     0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\\n        \"Test\":[0, 42, 500, 231, 231, 231, 500, 500, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0],\\n        \"Sim-Events\":[1.25, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0]\\n    },\\n    \"PDVD\":\\n    {\"Comment\":\"extend testing to 2024\",  # 2025?\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, # Hr/Event\\n        \"Sim-CPU\":0.75, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":220, # MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  5.1,  5.1, 20.4, 20.4,  5.1,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5.1,  5.1,    5.1,     5.1,     5.1,  5.1,\\n            0.0,  0.0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"HD\":{\"Comment\":\"make testing continue from 2027\",\\n        \"Raw-Store\":3750, # no compression MB/Event\\n        \"Reco-Data-CPU\":1.25, # Hr/Event comes from scaling up ~30 sec/apa to 150 + PR\\n        \"Sim-CPU\":0.08, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40, # MB/Event based on large VD sample\\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":3000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.5, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 1000, 5000,\\n            5000, 6000, 6000, 6000, 6000, 6000, 6000,6000, 6000, 1000,\\n            1000, 1000, 1000 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 0, 10, 10, 10, 10, 10,\\n            10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\\n            10, 10, 10] #millions\\n    },\\n    \"VD\":\\n    { \"Comment\":\"make testing continue from 2028\",\\n        \"Raw-Store\":8000, # MB/Event no compression\\n        \"Reco-Data-CPU\":1.33, # # Hr/Event scale up from 30 s/CRP\\n        \"Sim-CPU\":0.13, # MB/Event\\n        \"Reco-Data-GPU\":0.1, #Hr/Event\\n        \"Sim-GPU\":0.1, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40,   # MB/Event drop hits, 2x6 \\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":4000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.0, 1.1, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            5100, 5100, 6100, 6100,6100, 6100, 6100,6100, 6100, 1100,\\n            1100, 1100, 1100 ], # small offset so you can see it\\n        \"Sim-Events\":[0, 0, 0, 0, 5.1, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2] # small offset so you can see it\\n    },\\n    \"ND-SAND\":\\n    {\"Comment\":\"Just Sand from MAT 6/29/23\",\\n        \"Raw-Store\":5, # MB/Event \\n        \"Reco-Data-CPU\":0.0022, # Hr/Event\\n        \"Sim-CPU\":0.24, # Hr/Event note that this includes the 3x data scaling for simulation\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":10, # MB/Event\\n        \"Sim-Store\":25, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n          0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n        15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    \"ND-LAr+TMS\":\\n    {\"Comment\":\"new as very different needs a lot of input from 2x2 \",\\n        \"Raw-Store\":10, # MB/Event\\n        \"Reco-Data-CPU\":0.76, # Hr/Event \\n        \"Sim-CPU\":4.6, # Hr/Event this comes from (0.384 (fid sim) x3 for data stats) + 1.15 (rock sim)) then double for systematic samples\\n        \"Reco-Data-GPU\":0.76, #Hr/Event\\n        \"Sim-GPU\":4.6, #Hr/Event this comes from (0.768 (fid sim) x3 for data stats) + 0 for sim rock) then double for systematic samples\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":50, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,  # fraction of the CPU use -  decrease as MC goes up\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n          15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    #  Parameters\\n    #\"Analysis\":\\n    #{\"Scale\":[0, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5, 0.5, 0.5,0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5,0.5,0.5],\\n    #    \"Add\":[\"PDs\", \"FDs\", \"ND-SAND\",\"ND-LAr+TMS\"]\\n    #},\\n    \"LBL\":\\n    {\"Comment\":\"NA”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  0,  0, 0, 0,  0,  0, 0,  0,  0,  0,  0.00136,  0,  0.004080,  0,  0.008160,  0, 0.016320,  0,  0.021761], #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  0,  24,    24,    0,     0,  24, 0,  0,  0,  24,  24,  0,  24,  0,  24,  0, 24,  0,  24] #millions\\n},\\n\\n    \"HighE\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 0,  0.00249,  0,  0.01,  0.015,  0,  0,  0.04,  0,  0, 0.07,  0,  0] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 14, 0,  14,  0, 14,  14,  0,  0,  14,  0,  0,  14,  0,  0, 14,  0,  0], #millions\\n},\\n\\n\\n  \"Calib\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 1.83,  3.65,  3.65,  3.65,  3.65,  3.65,  5.48,  5.48,  7.3,  7.3, 7.3,  7.3,  7.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 2.6, 2.6,  2.6,  2.6, 2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6, 2.6,  2.6,  2.6], #millions\\n},\\n\\n\\n\\n\\n    \"LowE\":\\n    {\"Comment\":This has used LBL numbers where possible, but radiologicals complicate (inflate) things.  Memory based on tests for the upcoming production”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.4, # Hr/Event   #Maybe sped up by multithreading but tests not been done \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":1500, # MB/Event             #Assumed not saving rawdigits #radiologicals\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":24000, #MB      #Radiologicals in the full FD will be a problem\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,   0,   0,   0,   0,   0,   0,    0,     0,  0, 0,  0.0091,  0,  0.046,  0,  0,  0.1,  0,  0,  0.19, 0,  0,  0.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  10, 0, 0,  10,  0, 0,  10, 0, 10,  0,  0,  10,  0,  0,  10, 0,  0,  10], #millions\\n},\\n\\n\"Reprocess\":{\"SP\":3,\"DP\":3,\"PDHD\":3, \"PDVD\":3, \"PDs\":3,\"VD\":100,\"HD\":100,\"FDs\":100,\"ND-SAND\":100,\\n        \"ND-LAr+TMS\":100,\"LBL\":100,\"Calib\":100,\"HighE\":100,\"LowE\":100}, # of years of data reprocessed when do a new pass\\n\"AnalysisExtend\":2, # of years of analysis after end of reco/sim extends CPU, and GPU and disk\\n    \"PatternFraction\":{\"SP\":0.7,\"PDHD\":0.7,\"DP\":0.7,\"PDVD\":0.7,\"PDs\":0.7,\"HD\":0.1,\"VD\":0.1,\"FDs\":0.1,\\n\\t\\t       \"ND-SAND\":0.9,\"ND-LAr+TMS\":0.9,\"MARS\":0}, #fraction of time spent on PR as opposed to hit-finding\\n    \"TapeLifetimes\":{\"Raw-Store\":100, \"Test\":0.5, \"Reco-Data-Store\":15, \"Sim-Store\":15},\\n    \"DiskLifetimes\":{\"Raw-Store\":1, \"Test\":0.5, \"Reco-Data-Store\":3, \"Sim-Store\":2},  # raw and test only hang around a short while, can be restaged\\n    \"TapeCopies\":{\"Raw-Store\":2, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1},  # will take some coding to make these work out with 2 copies.\\n    \"DiskCopies\":{\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":2, \"Sim-Store\":1.5},\\n    \"PerYear\":\\n    {\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1, \"Events\":1, \"Sim-Events\":1, \"Reco-Data-CPU\":1, \"Sim-CPU\":1, \"Analysis\":1, \"Analysis-CPU\":1, \"Reco-Data-GPU\":1, \"Sim-GPU\":1}, # of times you redo them per year, CPU is reco CPU, Sim-CPU is sim CPU\\n    \"Cores\":{\\n        \"Efficiency\":0.7,  # CPU conversion to Wall time, per K. Herner\\n        \"2020Units\":1  # raise this # if machines get faster\\n    },\\n    \"kHEPSPEC06PerCPU\":0.011,\\n    \"FiscalYearStart\":\"April 1\",\\n    \"CPU Accounting\":\"end of fiscal year\",\\n    \"Tape Accounting\":\"end of fiscal year\",\\n    \"Disk Accounting\":\"October 1\",\\n    \"TypeColors\": {\"Raw-Store\":\"blue\",\"Raw+Test\":\"green\", \"Test\":\"orange\", \"Reco-Data-Store\":\"red\", \"Sim-Store\":\"grey\", \"Total\":\"black\",\"FNAL\":\"blue\",\"UK\":\"red\",\"CZ\":\"green\",\"CERN\":\"cyan\",\"US\":\"orange\"},\\n    \"TypeLines\": {\"Raw-Store\":\"solid\",\"Raw+Test\":\"solid\", \"Test\":\"dashed\", \"Reco-Data-Store\":\"solid\", \"Sim-Store\":\"dashed\", \"Total\":\"solid\"},\\n    \"DetColors\": {\"SP\":\"green\",\"PDHD\":\"green\", \"DP\":\"magenta\",\"PDVD\":\"magenta\", \"PDs\":\"blue\", \"HD\":\"red\",\\n        \"VD\":\"red\",\"FDs\":\"red\",\"ND-SAND\":\"grey\",\"ND-LAr+TMS\":\"black\",\"Analysis\":\"orange\", \"Total\":\"black\",\"MARS\":\"purple\",\\n        \"Production\":\"blue\", \"FNAL\":\"orange\", \"CERN\":\"cyan\", \"National\":\"green\", \"LBL\":\"magenta\",\"Calib\":\"cyan\",\"HighE\":\"purple\",\"LowE\":\"blue\"\\n    },\\n    \"DetLines\": {\"SP\":\"solid\",\"PDHD\":\"dashed\", \"DP\":\"solid\",\"PDVD\":\"dotted\", \"PDs\":\"solid\", \"HD\":\"solid\",\\n        \"VD\":\"dashed\",\"FDs\":\"solid\",\"ND-SAND\":\"solid\",\"ND-LAr+TMS\":\"dashed\", \"MARS\":\"dashed\",\"Analysis\":\"dashed\", \"Total\":\"solid\",\"FNAL\":\"solid\", \"CERN\":\"solid\", \"National\":\"solid\",\"LBL\":\"dotted\",\"Calib\":\"dotted\",\"HighE\":\"dotted\",\"LowE\":\"dotted\"\\n        \\n    },\\n    \"SplitsYear\":2029,\\n    \"SplitsEarly\":{ # these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Reco-Data-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0}\\n        },\\n        \"Disk\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Reco-Data-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.00}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5}}\\n    },\\n    \"SplitsLater\":{# these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.50},\\n            \"Sim-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Reco-Data-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"Disk\":{\\n            #\"Disk\":{\"Raw-Store\":0.0,\"Sim-Store\":0.75,\"Reco-Data-Store\":0.75,\"Test\":0.00} old version\\n            \"Raw-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Reco-Data-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}}\\n    },\\n    \\n    \"Explain\":{\\n        \"Detectors\":\"Detectors included in the calculation\",\\n        \"Cap\":\"Cap on Raw data/year in PB\",\\n        \"Base-Memory\":\"MB of memory per slot assumed as the average\",\\n        \"MaxYear\":\"Plot until year\",\\n        \"MinYear\":\"Plot starting with year\",\\n        \"Reprocess\":\"Number of years of data reprocessed when doing a new pass\",\\n        \"AnalysisExtend\":\"Years analysis continues after last reco/sim\",\\n        \"PatternFraction\":\"Fraction of time taken in pattern recognition\",\\n        \"TapeLifetimes\":\"Number of years kept on tape\",\\n        \"DiskLifetimes\":\"Number of years kept on disk\",\\n        \"TapeCopies\":\"Number of copies kept on tape\",\\n        \"DiskCopies\":\"Number of copies kept on disk\",\\n        \"PerYear\":\"Number of reprocessing done per year\",\\n        \"Cores\":\"Description of cores, efficiency and speed relative to 2020 vintage\",\\n        \"kHEPSPEC06PerCPU\":\"kHEPSPEC06 per core assumed\",\\n        \"SplitsYear\":\"Year CERN no longer responsible for disk or tape\",\\n        \"SplitsEarly\":\"Division between FNAL/CERN/National for storage until SplitsYear\",\\n        \"SplitsLater\":\"Division between FNAL/CERN/National for storage after SplitsYear\"\\n    },\\n    // \"Actual\":{\\n    //     \"wallactual\": {\"2021\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3},\\n    //         \"2022\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3}\\n    //     },\\n\\n    //     \"diskactual\":{\\n    //         \"2021\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30},\\n    //         \"2022\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30}\\n    //     },\\n    //     \"tapeactual\":{\\n    //         \"2021\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0},\\n    //         \"2022\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0}\\n    //     }\\n    // }\\n}\\n')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONLibraryException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(configfilename):\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(configfilename,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#x = f.read()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print (x[6000:6960])\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mcommentjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno config file\u001b[39m\u001b[38;5;124m\"\u001b[39m,configfilename)\n",
      "File \u001b[0;32m~/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py:217\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONLibraryException(e)\n",
      "\u001b[0;31mJSONLibraryException\u001b[0m: JSON Library Exception\n\nException thrown by library (json): \u001b[4;37m('Unable to parse text', '{ \"Version\":15,\\n    \"Changes\":[\\n        \"2023-12-12 Heidi add in HD/VD stuff\",\\n        \"2023-12-11 Heidi increase sim for ND to x4\",\\n        \"2023-11-03 Heidi commits all old changes and adds option to not do MWC\",\\n        \"2023-07-03 Kirby added some comments for documentation and worked on adding GPU for ND-LAr\",\\n        \"2023-06-30 lower memory for FD reco to 2GB\",\\n        \"2023-06-29 new ND from Mat\",\\n        \"2023-06-20 new VD/HD #\\'s from Dom\",\\n        \"2023-06-28 make NDLAr optional controled by CombinedDetectors\",\\n        \"2023-06-24 add support for analysis by detector\",\\n        \"2023-06-23 match to milestones, add NDLAr\",\\n        \"2023-06-22 update for DOE review, extend PD analysis, raise analysis levels for FD/ND\",\\n        \"2023-05-05 update for DOE review, delay PD2 yet again\",\\n        \"2023-01-31 version for FCSRG - change CERN/FNAL weights, raise ND test for 2x2\",\\n        \"2022-11-21 make units Memory weighted\",\\n        \"2022-11-18 introduce memory scaling for CPU\",\\n        \"2022-11-07 double FD Sim\",\\n        \"2022-11-07 add in memory use so cores, rescale analysis as smaller\",\\n        \"Number reprocessing is only X percent of original as you keep the hits?\",\\n        \"Number why does CPU ->0 even though Sim still running in 2027\",\\n        \"2022-10-23 update the code\",\\n        \"2022-05-19 revert pre 2023 to CdunCB sim numbers but keep updated daq estimates\",\\n        \"2022-05-18 add in MARS\",\\n        \"2022-02-21 add in new numbers for PD2, FD sim, reflect daq document\",\\n        \"2022-01-22 add actual numbers\\'s\",\\n        \"2022-01-14 updates for VD channels and new drift times.\",\\n        \"2021-07-25 see effects of PD 2 delay\",\\n        \"2021-04-27 change HSPEC06 to 11 from 15 per CMS numbers from Kirby\",\\n        \"2021-04-21 clarify CERN vs Collab for first 10 years\",\\n        \"2021-03-26 clearer plots, go to v3 of the code to preserve the RRB code in v2\",\\n        \"2021-03-24 try with CERN/FNAL combined for raw and test.\",\\n        \"2021-03-22 add Collab vs FNAL shares, restore sim disk lifetime to 2.\"\\n    ],\\n  \"Interpretation\":\" Real numbers from 2021 are shown. Disk usage was lower than the model predicts as rucio duplication was not fully implemented until late in the year so most  reconstructed data and simulation  had 1 instead of the desired 2 copies. CPU usage was lower as the detector data were not fully reprocessed in 2021. \\\\\\\\\\\\\\\\The long term model for ProtoDUNE II and the Far detector has evolved to reflect 14-bit digitization and the channel count for the vertical drift detector.\\\\\\\\pagebreak \",\\n  \"Years\":[\\n        2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        2038,  2039,   2040\\n    ],\\n  #\"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"HD\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"], # SP+DP and HD+VD are merged into ProtoDUNE and FD later\\n  \"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"LBL\",\"HighE\",\"Calib\",\"LowE\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n  \"Cap\":30, # cap in PB\\n  \"MWCWeight\":0, # logical to do MWC weight\\n  \"Base-Memory\":2000, # mb assumed memory use used for rescaling CPU.\\n  \"MaxYear\":2040,\\n  \"MinYear\":2020,\\n  \"Units\":\\n  {\"Events\":\"Million\", \"Raw-Store\":\"PB\", \"Test\":\"PB\",\"Raw+Test\":\"PB\", \"Reco-Data-Store\":\"PB\", \"Reco-Data-CPU\":\"MWC-CPU MHrs\",\\n   \"Sim-Events\":\"M\", \"Sim-Store\":\"PB\", \"Sim-CPU\":\"MWC-CPU MHrs\",\"Analysis-CPU\":\"MWC-CPU MHrs\", \"All\":\"PB\", \"Years\":\"\",\\n   \"Total-CPU\":\"MWC-CPU MHrs\", \"Cumulative-Tape\":\"PB\", \"Cumulative-Disk\":\"PB\", \"Tape\":\"PB\", \"Disk\":\"PB\",\"Cores\":\"2020-vintage MWC Cores\",\\n   \"HS23\":\"Memory weighted kHS23-yrs\", \"Wall\":\"Memory Weighted Wall MHrs\",\"HPC-Storage\":\"PB\",\"HPC-CPU\":\"MWC-CPU MHrs\",\\n   \"Reco-Data-GPU\":\"GPU MHrs\", \"Sim-GPU\":\"GPU MHrs\"\\n  },\\n  \"Formats\":\\n  {\"Events\":\"%8.1f\", \"Raw-Store\":\"%8.1f\", \"Test\":\"%8.1f\",\"Raw+Test\":\"%8.1f\", \"Reco-Data-Store\":\"%8.1f\", \"Reco-Data-CPU\":\"%8.1f\",\\n   \"Sim-Events\":\"%8.1f\", \"Sim-Store\":\"%8.1f\", \"Sim-CPU\":\"%8.1f\", \"Analysis-CPU\":\"%8.1f\",\"All\":\"%8.1f\", \"Years\":\"%d\",\\n   \"Total-CPU\":\"%8.1f\", \"Cumulative-Tape\":\"%8.1f\", \"Cumulative-Disk\":\"%8.1f\", \"Tape\":\"%8.1f\", \"Disk\":\"%8.1f\",\"Cores\":\"%d\",\\n   \"HS23\":\"%d\",\"Wall\":\"%d\",\"HPC-Storage\":\"%f8.1f\",\"HPC-CPU\":\"%8.1f\", \"Reco-Data-GPU\":\"%8.1f\", \"Sim-GPU\":\"%8.1f\"\\n    },\\n  \"CombinedDetectors\":[\"PDs\",\"FDs\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n\\n  \"//comment_about_detectors\":\"This is the start of the definitions of the different inputs for things listed in Detectors\",\\n  \"//comment_about_detectors\":\"each detector listed in the Detectors item above has an entry defining its event projections, storage, and processing profile\",\\n  \"//comment_about_detectors\":\"this includes CPU an GPU, and a memory profile for the CPU processing\",\\n\\n  \"SP\":\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":70, # from first beam test in MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, #ratio of Analysis to reco+sim\\n        \"Events\":[  10.9,   19.4,   6.5,    6.5,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[    157,    600,    500,    0,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  1.25,   5,  5,  10,     5,     0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"PDHD\":  # UPDATE FOR 2023 delay\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":140, # no compression MB/Event, 4 APA 14 bit\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        #\"Years\":[\\n        #    2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        #    2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        #    2038,  2039,   2040\\n        #],\\n        \"Events\":[  0,  0,  0,  0,  5,  5, 20, 20,  5,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5,  5,     5,     5,     5,  5,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"DP\":{\\n        \"Comment\":\"extend testing to 2024\",\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[  0,  0.5,    0.9,    2,  0,     0,     0,     0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\\n        \"Test\":[0, 42, 500, 231, 231, 231, 500, 500, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0],\\n        \"Sim-Events\":[1.25, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0]\\n    },\\n    \"PDVD\":\\n    {\"Comment\":\"extend testing to 2024\",  # 2025?\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, # Hr/Event\\n        \"Sim-CPU\":0.75, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":220, # MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  5.1,  5.1, 20.4, 20.4,  5.1,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5.1,  5.1,    5.1,     5.1,     5.1,  5.1,\\n            0.0,  0.0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"HD\":{\"Comment\":\"make testing continue from 2027\",\\n        \"Raw-Store\":3750, # no compression MB/Event\\n        \"Reco-Data-CPU\":1.25, # Hr/Event comes from scaling up ~30 sec/apa to 150 + PR\\n        \"Sim-CPU\":0.08, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40, # MB/Event based on large VD sample\\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":3000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.5, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 1000, 5000,\\n            5000, 6000, 6000, 6000, 6000, 6000, 6000,6000, 6000, 1000,\\n            1000, 1000, 1000 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 0, 10, 10, 10, 10, 10,\\n            10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\\n            10, 10, 10] #millions\\n    },\\n    \"VD\":\\n    { \"Comment\":\"make testing continue from 2028\",\\n        \"Raw-Store\":8000, # MB/Event no compression\\n        \"Reco-Data-CPU\":1.33, # # Hr/Event scale up from 30 s/CRP\\n        \"Sim-CPU\":0.13, # MB/Event\\n        \"Reco-Data-GPU\":0.1, #Hr/Event\\n        \"Sim-GPU\":0.1, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40,   # MB/Event drop hits, 2x6 \\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":4000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.0, 1.1, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            5100, 5100, 6100, 6100,6100, 6100, 6100,6100, 6100, 1100,\\n            1100, 1100, 1100 ], # small offset so you can see it\\n        \"Sim-Events\":[0, 0, 0, 0, 5.1, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2] # small offset so you can see it\\n    },\\n    \"ND-SAND\":\\n    {\"Comment\":\"Just Sand from MAT 6/29/23\",\\n        \"Raw-Store\":5, # MB/Event \\n        \"Reco-Data-CPU\":0.0022, # Hr/Event\\n        \"Sim-CPU\":0.24, # Hr/Event note that this includes the 3x data scaling for simulation\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":10, # MB/Event\\n        \"Sim-Store\":25, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n          0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n        15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    \"ND-LAr+TMS\":\\n    {\"Comment\":\"new as very different needs a lot of input from 2x2 \",\\n        \"Raw-Store\":10, # MB/Event\\n        \"Reco-Data-CPU\":0.76, # Hr/Event \\n        \"Sim-CPU\":4.6, # Hr/Event this comes from (0.384 (fid sim) x3 for data stats) + 1.15 (rock sim)) then double for systematic samples\\n        \"Reco-Data-GPU\":0.76, #Hr/Event\\n        \"Sim-GPU\":4.6, #Hr/Event this comes from (0.768 (fid sim) x3 for data stats) + 0 for sim rock) then double for systematic samples\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":50, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,  # fraction of the CPU use -  decrease as MC goes up\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n          15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    #  Parameters\\n    #\"Analysis\":\\n    #{\"Scale\":[0, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5, 0.5, 0.5,0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5,0.5,0.5],\\n    #    \"Add\":[\"PDs\", \"FDs\", \"ND-SAND\",\"ND-LAr+TMS\"]\\n    #},\\n    \"LBL\":\\n    {\"Comment\":\"NA”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  0,  0, 0, 0,  0,  0, 0,  0,  0,  0,  0.00136,  0,  0.004080,  0,  0.008160,  0, 0.016320,  0,  0.021761], #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  0,  24,    24,    0,     0,  24, 0,  0,  0,  24,  24,  0,  24,  0,  24,  0, 24,  0,  24] #millions\\n},\\n\\n    \"HighE\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 0,  0.00249,  0,  0.01,  0.015,  0,  0,  0.04,  0,  0, 0.07,  0,  0] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 14, 0,  14,  0, 14,  14,  0,  0,  14,  0,  0,  14,  0,  0, 14,  0,  0], #millions\\n},\\n\\n\\n  \"Calib\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 1.83,  3.65,  3.65,  3.65,  3.65,  3.65,  5.48,  5.48,  7.3,  7.3, 7.3,  7.3,  7.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 2.6, 2.6,  2.6,  2.6, 2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6, 2.6,  2.6,  2.6], #millions\\n},\\n\\n\\n\\n\\n    \"LowE\":\\n    {\"Comment\":This has used LBL numbers where possible, but radiologicals complicate (inflate) things.  Memory based on tests for the upcoming production”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.4, # Hr/Event   #Maybe sped up by multithreading but tests not been done \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":1500, # MB/Event             #Assumed not saving rawdigits #radiologicals\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":24000, #MB      #Radiologicals in the full FD will be a problem\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,   0,   0,   0,   0,   0,   0,    0,     0,  0, 0,  0.0091,  0,  0.046,  0,  0,  0.1,  0,  0,  0.19, 0,  0,  0.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  10, 0, 0,  10,  0, 0,  10, 0, 10,  0,  0,  10,  0,  0,  10, 0,  0,  10], #millions\\n},\\n\\n\"Reprocess\":{\"SP\":3,\"DP\":3,\"PDHD\":3, \"PDVD\":3, \"PDs\":3,\"VD\":100,\"HD\":100,\"FDs\":100,\"ND-SAND\":100,\\n        \"ND-LAr+TMS\":100,\"LBL\":100,\"Calib\":100,\"HighE\":100,\"LowE\":100}, # of years of data reprocessed when do a new pass\\n\"AnalysisExtend\":2, # of years of analysis after end of reco/sim extends CPU, and GPU and disk\\n    \"PatternFraction\":{\"SP\":0.7,\"PDHD\":0.7,\"DP\":0.7,\"PDVD\":0.7,\"PDs\":0.7,\"HD\":0.1,\"VD\":0.1,\"FDs\":0.1,\\n\\t\\t       \"ND-SAND\":0.9,\"ND-LAr+TMS\":0.9,\"MARS\":0}, #fraction of time spent on PR as opposed to hit-finding\\n    \"TapeLifetimes\":{\"Raw-Store\":100, \"Test\":0.5, \"Reco-Data-Store\":15, \"Sim-Store\":15},\\n    \"DiskLifetimes\":{\"Raw-Store\":1, \"Test\":0.5, \"Reco-Data-Store\":3, \"Sim-Store\":2},  # raw and test only hang around a short while, can be restaged\\n    \"TapeCopies\":{\"Raw-Store\":2, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1},  # will take some coding to make these work out with 2 copies.\\n    \"DiskCopies\":{\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":2, \"Sim-Store\":1.5},\\n    \"PerYear\":\\n    {\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1, \"Events\":1, \"Sim-Events\":1, \"Reco-Data-CPU\":1, \"Sim-CPU\":1, \"Analysis\":1, \"Analysis-CPU\":1, \"Reco-Data-GPU\":1, \"Sim-GPU\":1}, # of times you redo them per year, CPU is reco CPU, Sim-CPU is sim CPU\\n    \"Cores\":{\\n        \"Efficiency\":0.7,  # CPU conversion to Wall time, per K. Herner\\n        \"2020Units\":1  # raise this # if machines get faster\\n    },\\n    \"kHEPSPEC06PerCPU\":0.011,\\n    \"FiscalYearStart\":\"April 1\",\\n    \"CPU Accounting\":\"end of fiscal year\",\\n    \"Tape Accounting\":\"end of fiscal year\",\\n    \"Disk Accounting\":\"October 1\",\\n    \"TypeColors\": {\"Raw-Store\":\"blue\",\"Raw+Test\":\"green\", \"Test\":\"orange\", \"Reco-Data-Store\":\"red\", \"Sim-Store\":\"grey\", \"Total\":\"black\",\"FNAL\":\"blue\",\"UK\":\"red\",\"CZ\":\"green\",\"CERN\":\"cyan\",\"US\":\"orange\"},\\n    \"TypeLines\": {\"Raw-Store\":\"solid\",\"Raw+Test\":\"solid\", \"Test\":\"dashed\", \"Reco-Data-Store\":\"solid\", \"Sim-Store\":\"dashed\", \"Total\":\"solid\"},\\n    \"DetColors\": {\"SP\":\"green\",\"PDHD\":\"green\", \"DP\":\"magenta\",\"PDVD\":\"magenta\", \"PDs\":\"blue\", \"HD\":\"red\",\\n        \"VD\":\"red\",\"FDs\":\"red\",\"ND-SAND\":\"grey\",\"ND-LAr+TMS\":\"black\",\"Analysis\":\"orange\", \"Total\":\"black\",\"MARS\":\"purple\",\\n        \"Production\":\"blue\", \"FNAL\":\"orange\", \"CERN\":\"cyan\", \"National\":\"green\", \"LBL\":\"magenta\",\"Calib\":\"cyan\",\"HighE\":\"purple\",\"LowE\":\"blue\"\\n    },\\n    \"DetLines\": {\"SP\":\"solid\",\"PDHD\":\"dashed\", \"DP\":\"solid\",\"PDVD\":\"dotted\", \"PDs\":\"solid\", \"HD\":\"solid\",\\n        \"VD\":\"dashed\",\"FDs\":\"solid\",\"ND-SAND\":\"solid\",\"ND-LAr+TMS\":\"dashed\", \"MARS\":\"dashed\",\"Analysis\":\"dashed\", \"Total\":\"solid\",\"FNAL\":\"solid\", \"CERN\":\"solid\", \"National\":\"solid\",\"LBL\":\"dotted\",\"Calib\":\"dotted\",\"HighE\":\"dotted\",\"LowE\":\"dotted\"\\n        \\n    },\\n    \"SplitsYear\":2029,\\n    \"SplitsEarly\":{ # these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Reco-Data-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0}\\n        },\\n        \"Disk\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Reco-Data-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.00}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5}}\\n    },\\n    \"SplitsLater\":{# these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.50},\\n            \"Sim-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Reco-Data-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"Disk\":{\\n            #\"Disk\":{\"Raw-Store\":0.0,\"Sim-Store\":0.75,\"Reco-Data-Store\":0.75,\"Test\":0.00} old version\\n            \"Raw-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Reco-Data-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}}\\n    },\\n    \\n    \"Explain\":{\\n        \"Detectors\":\"Detectors included in the calculation\",\\n        \"Cap\":\"Cap on Raw data/year in PB\",\\n        \"Base-Memory\":\"MB of memory per slot assumed as the average\",\\n        \"MaxYear\":\"Plot until year\",\\n        \"MinYear\":\"Plot starting with year\",\\n        \"Reprocess\":\"Number of years of data reprocessed when doing a new pass\",\\n        \"AnalysisExtend\":\"Years analysis continues after last reco/sim\",\\n        \"PatternFraction\":\"Fraction of time taken in pattern recognition\",\\n        \"TapeLifetimes\":\"Number of years kept on tape\",\\n        \"DiskLifetimes\":\"Number of years kept on disk\",\\n        \"TapeCopies\":\"Number of copies kept on tape\",\\n        \"DiskCopies\":\"Number of copies kept on disk\",\\n        \"PerYear\":\"Number of reprocessing done per year\",\\n        \"Cores\":\"Description of cores, efficiency and speed relative to 2020 vintage\",\\n        \"kHEPSPEC06PerCPU\":\"kHEPSPEC06 per core assumed\",\\n        \"SplitsYear\":\"Year CERN no longer responsible for disk or tape\",\\n        \"SplitsEarly\":\"Division between FNAL/CERN/National for storage until SplitsYear\",\\n        \"SplitsLater\":\"Division between FNAL/CERN/National for storage after SplitsYear\"\\n    },\\n    // \"Actual\":{\\n    //     \"wallactual\": {\"2021\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3},\\n    //         \"2022\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3}\\n    //     },\\n\\n    //     \"diskactual\":{\\n    //         \"2021\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30},\\n    //         \"2022\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30}\\n    //     },\\n    //     \"tapeactual\":{\\n    //         \"2021\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0},\\n    //         \"2022\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0}\\n    //     }\\n    // }\\n}\\n')\u001b[0m\n\n    Traceback (most recent call last):\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 598, in lex\n        token = self.root_lexer.next_token(lexer_state, parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 528, in next_token\n        raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n    lark.exceptions.UnexpectedCharacters: No terminal matches '\"' in the current parser context, at line 248 col 16\n    \n        {\"Comment\":\"NA”\n                   ^\n    Expected one of: \n    \t* COLON\n    \t* LBRACE\n    \t* TRUE\n    \t* FALSE\n    \t* SIGNED_NUMBER\n    \t* NULL\n    \t* RBRACE\n    \t* TRAILING_COMMA\n    \t* ESCAPED_STRING\n    \t* RSQB\n    \t* LSQB\n    \n    Previous tokens: Token('COLON', ':')\n    \n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 180, in loads\n        parsed = _remove_trailing_commas(parser.parse(text))\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lark.py\", line 645, in parse\n        return self.parser.parse(text, start=start, on_error=on_error)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parser_frontends.py\", line 96, in parse\n        return self.parser.parse(stream, chosen_start, **kw)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 41, in parse\n        return self.parser.parse(lexer, start)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 171, in parse\n        return self.parse_from_state(parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 188, in parse_from_state\n        raise e\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/parsers/lalr_parser.py\", line 178, in parse_from_state\n        for token in state.lexer.lex(state):\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 601, in lex\n        raise e  # Raise the original UnexpectedCharacters. The root lexer raises it with the wrong expected set.\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 590, in lex\n        yield lexer.next_token(lexer_state, parser_state)\n      File \"/Users/schellma/.local/lib/python3.9/site-packages/lark-1.1.4-py3.9.egg/lark/lexer.py\", line 528, in next_token\n        raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n    lark.exceptions.UnexpectedCharacters: No terminal matches '\"' in the current parser context, at line 248 col 16\n    \n        {\"Comment\":\"NA”\n                   ^\n    Expected one of: \n    \t* LBRACE\n    \t* TRUE\n    \t* FALSE\n    \t* SIGNED_NUMBER\n    \t* NULL\n    \t* ESCAPED_STRING\n    \t* LSQB\n    \n    Previous tokens: Token('COLON', ':')\n    \n    \n    During handling of the above exception, another exception occurred:\n    \n    Traceback (most recent call last):\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 215, in load\n        return loads(fp.read(), **kwargs)\n      File \"/Users/schellma/miniconda/envs/ccqe/lib/python3.9/site-packages/commentjson/commentjson.py\", line 183, in loads\n        raise ValueError('Unable to parse text', text)\n    ValueError: ('Unable to parse text', '{ \"Version\":15,\\n    \"Changes\":[\\n        \"2023-12-12 Heidi add in HD/VD stuff\",\\n        \"2023-12-11 Heidi increase sim for ND to x4\",\\n        \"2023-11-03 Heidi commits all old changes and adds option to not do MWC\",\\n        \"2023-07-03 Kirby added some comments for documentation and worked on adding GPU for ND-LAr\",\\n        \"2023-06-30 lower memory for FD reco to 2GB\",\\n        \"2023-06-29 new ND from Mat\",\\n        \"2023-06-20 new VD/HD #\\'s from Dom\",\\n        \"2023-06-28 make NDLAr optional controled by CombinedDetectors\",\\n        \"2023-06-24 add support for analysis by detector\",\\n        \"2023-06-23 match to milestones, add NDLAr\",\\n        \"2023-06-22 update for DOE review, extend PD analysis, raise analysis levels for FD/ND\",\\n        \"2023-05-05 update for DOE review, delay PD2 yet again\",\\n        \"2023-01-31 version for FCSRG - change CERN/FNAL weights, raise ND test for 2x2\",\\n        \"2022-11-21 make units Memory weighted\",\\n        \"2022-11-18 introduce memory scaling for CPU\",\\n        \"2022-11-07 double FD Sim\",\\n        \"2022-11-07 add in memory use so cores, rescale analysis as smaller\",\\n        \"Number reprocessing is only X percent of original as you keep the hits?\",\\n        \"Number why does CPU ->0 even though Sim still running in 2027\",\\n        \"2022-10-23 update the code\",\\n        \"2022-05-19 revert pre 2023 to CdunCB sim numbers but keep updated daq estimates\",\\n        \"2022-05-18 add in MARS\",\\n        \"2022-02-21 add in new numbers for PD2, FD sim, reflect daq document\",\\n        \"2022-01-22 add actual numbers\\'s\",\\n        \"2022-01-14 updates for VD channels and new drift times.\",\\n        \"2021-07-25 see effects of PD 2 delay\",\\n        \"2021-04-27 change HSPEC06 to 11 from 15 per CMS numbers from Kirby\",\\n        \"2021-04-21 clarify CERN vs Collab for first 10 years\",\\n        \"2021-03-26 clearer plots, go to v3 of the code to preserve the RRB code in v2\",\\n        \"2021-03-24 try with CERN/FNAL combined for raw and test.\",\\n        \"2021-03-22 add Collab vs FNAL shares, restore sim disk lifetime to 2.\"\\n    ],\\n  \"Interpretation\":\" Real numbers from 2021 are shown. Disk usage was lower than the model predicts as rucio duplication was not fully implemented until late in the year so most  reconstructed data and simulation  had 1 instead of the desired 2 copies. CPU usage was lower as the detector data were not fully reprocessed in 2021. \\\\\\\\\\\\\\\\The long term model for ProtoDUNE II and the Far detector has evolved to reflect 14-bit digitization and the channel count for the vertical drift detector.\\\\\\\\pagebreak \",\\n  \"Years\":[\\n        2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        2038,  2039,   2040\\n    ],\\n  #\"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"HD\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"], # SP+DP and HD+VD are merged into ProtoDUNE and FD later\\n  \"Detectors\":[\"SP\",\"PDHD\",\"DP\",\"PDVD\",\"LBL\",\"HighE\",\"Calib\",\"LowE\",\"VD\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n  \"Cap\":30, # cap in PB\\n  \"MWCWeight\":0, # logical to do MWC weight\\n  \"Base-Memory\":2000, # mb assumed memory use used for rescaling CPU.\\n  \"MaxYear\":2040,\\n  \"MinYear\":2020,\\n  \"Units\":\\n  {\"Events\":\"Million\", \"Raw-Store\":\"PB\", \"Test\":\"PB\",\"Raw+Test\":\"PB\", \"Reco-Data-Store\":\"PB\", \"Reco-Data-CPU\":\"MWC-CPU MHrs\",\\n   \"Sim-Events\":\"M\", \"Sim-Store\":\"PB\", \"Sim-CPU\":\"MWC-CPU MHrs\",\"Analysis-CPU\":\"MWC-CPU MHrs\", \"All\":\"PB\", \"Years\":\"\",\\n   \"Total-CPU\":\"MWC-CPU MHrs\", \"Cumulative-Tape\":\"PB\", \"Cumulative-Disk\":\"PB\", \"Tape\":\"PB\", \"Disk\":\"PB\",\"Cores\":\"2020-vintage MWC Cores\",\\n   \"HS23\":\"Memory weighted kHS23-yrs\", \"Wall\":\"Memory Weighted Wall MHrs\",\"HPC-Storage\":\"PB\",\"HPC-CPU\":\"MWC-CPU MHrs\",\\n   \"Reco-Data-GPU\":\"GPU MHrs\", \"Sim-GPU\":\"GPU MHrs\"\\n  },\\n  \"Formats\":\\n  {\"Events\":\"%8.1f\", \"Raw-Store\":\"%8.1f\", \"Test\":\"%8.1f\",\"Raw+Test\":\"%8.1f\", \"Reco-Data-Store\":\"%8.1f\", \"Reco-Data-CPU\":\"%8.1f\",\\n   \"Sim-Events\":\"%8.1f\", \"Sim-Store\":\"%8.1f\", \"Sim-CPU\":\"%8.1f\", \"Analysis-CPU\":\"%8.1f\",\"All\":\"%8.1f\", \"Years\":\"%d\",\\n   \"Total-CPU\":\"%8.1f\", \"Cumulative-Tape\":\"%8.1f\", \"Cumulative-Disk\":\"%8.1f\", \"Tape\":\"%8.1f\", \"Disk\":\"%8.1f\",\"Cores\":\"%d\",\\n   \"HS23\":\"%d\",\"Wall\":\"%d\",\"HPC-Storage\":\"%f8.1f\",\"HPC-CPU\":\"%8.1f\", \"Reco-Data-GPU\":\"%8.1f\", \"Sim-GPU\":\"%8.1f\"\\n    },\\n  \"CombinedDetectors\":[\"PDs\",\"FDs\",\"ND-SAND\",\"ND-LAr+TMS\"],\\n\\n  \"//comment_about_detectors\":\"This is the start of the definitions of the different inputs for things listed in Detectors\",\\n  \"//comment_about_detectors\":\"each detector listed in the Detectors item above has an entry defining its event projections, storage, and processing profile\",\\n  \"//comment_about_detectors\":\"this includes CPU an GPU, and a memory profile for the CPU processing\",\\n\\n  \"SP\":\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":70, # from first beam test in MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, #ratio of Analysis to reco+sim\\n        \"Events\":[  10.9,   19.4,   6.5,    6.5,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[    157,    600,    500,    0,    0,  0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  1.25,   5,  5,  10,     5,     0,  0,  0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"PDHD\":  # UPDATE FOR 2023 delay\\n    {\"Comment\":\"move main test beam to 2023, extend cosmics by one year\",\\n        \"Raw-Store\":140, # no compression MB/Event, 4 APA 14 bit\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        #\"Years\":[\\n        #    2018,  2019,   2020,   2021,   2022,   2023,   2024,   2025,   2026,   2027,\\n        #    2028,  2029,   2030,   2031,   2032,   2033,   2034,   2035,   2036,   2037,\\n        #    2038,  2039,   2040\\n        #],\\n        \"Events\":[  0,  0,  0,  0,  5,  5, 20, 20,  5,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5,  5,     5,     5,     5,  5,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"DP\":{\\n        \"Comment\":\"extend testing to 2024\",\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, #Hr/Event\\n        \"Sim-CPU\":0.75, #Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":35, #MB/Event\\n        \"Sim-Store\":220, #MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[  0,  0.5,    0.9,    2,  0,     0,     0,     0,  0,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\\n        \"Test\":[0, 42, 500, 231, 231, 231, 500, 500, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0],\\n        \"Sim-Events\":[1.25, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0]\\n    },\\n    \"PDVD\":\\n    {\"Comment\":\"extend testing to 2024\",  # 2025?\\n        \"Raw-Store\":110, # MB/Event\\n        \"Reco-Data-CPU\":0.1667, # Hr/Event\\n        \"Sim-CPU\":0.75, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":220, # MB/Event\\n        \"Reco-Memory\":4000, #MB\\n        \"Sim-Memory\":6000, #MB\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  5.1,  5.1, 20.4, 20.4,  5.1,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], #millions\\n        \"Test\":[0,  0,  0,  0,  1000,   1000,    100,   500, 500,  0,\\n            0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  5.1,  5.1,    5.1,     5.1,     5.1,  5.1,\\n            0.0,  0.0,  0,  0,  0,  0,  0,  0,  0,  0,\\n            0,  0,  0] #millions\\n    },\\n    \"HD\":{\"Comment\":\"make testing continue from 2027\",\\n        \"Raw-Store\":3750, # no compression MB/Event\\n        \"Reco-Data-CPU\":1.25, # Hr/Event comes from scaling up ~30 sec/apa to 150 + PR\\n        \"Sim-CPU\":0.08, # Hr/Event\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40, # MB/Event based on large VD sample\\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":3000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.5, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 1000, 5000,\\n            5000, 6000, 6000, 6000, 6000, 6000, 6000,6000, 6000, 1000,\\n            1000, 1000, 1000 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 0, 10, 10, 10, 10, 10,\\n            10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\\n            10, 10, 10] #millions\\n    },\\n    \"VD\":\\n    { \"Comment\":\"make testing continue from 2028\",\\n        \"Raw-Store\":8000, # MB/Event no compression\\n        \"Reco-Data-CPU\":1.33, # # Hr/Event scale up from 30 s/CRP\\n        \"Sim-CPU\":0.13, # MB/Event\\n        \"Reco-Data-GPU\":0.1, #Hr/Event\\n        \"Sim-GPU\":0.1, #Hr/Event\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":40,   # MB/Event drop hits, 2x6 \\n        \"Reco-Memory\":2000, #MB\\n        \"Sim-Memory\":4000, #MB\\n        \"Analysis-CPU\":0.5,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0.0, 1.1, 2.2, 2.2, 2.2, 2.2, 2.2, 4.4, 4.4, 4.4,\\n            4.4, 4.4, 4.4], # is the doubling in the out years from beam intensity?\\n        \"Test\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            5100, 5100, 6100, 6100,6100, 6100, 6100,6100, 6100, 1100,\\n            1100, 1100, 1100 ], # small offset so you can see it\\n        \"Sim-Events\":[0, 0, 0, 0, 5.1, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2, 10.2,\\n            10.2, 10.2, 10.2] # small offset so you can see it\\n    },\\n    \"ND-SAND\":\\n    {\"Comment\":\"Just Sand from MAT 6/29/23\",\\n        \"Raw-Store\":5, # MB/Event \\n        \"Reco-Data-CPU\":0.0022, # Hr/Event\\n        \"Sim-CPU\":0.24, # Hr/Event note that this includes the 3x data scaling for simulation\\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":10, # MB/Event\\n        \"Sim-Store\":25, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n          0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n        15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    \"ND-LAr+TMS\":\\n    {\"Comment\":\"new as very different needs a lot of input from 2x2 \",\\n        \"Raw-Store\":10, # MB/Event\\n        \"Reco-Data-CPU\":0.76, # Hr/Event \\n        \"Sim-CPU\":4.6, # Hr/Event this comes from (0.384 (fid sim) x3 for data stats) + 1.15 (rock sim)) then double for systematic samples\\n        \"Reco-Data-GPU\":0.76, #Hr/Event\\n        \"Sim-GPU\":4.6, #Hr/Event this comes from (0.768 (fid sim) x3 for data stats) + 0 for sim rock) then double for systematic samples\\n        \"Reco-Data-Store\":20, # MB/Event\\n        \"Sim-Store\":50, # MB/Event\\n        \"Reco-Memory\":2000, # MB\\n        \"Sim-Memory\":2000, # MB\\n        \"Analysis-CPU\":0.25,  # fraction of the CPU use -  decrease as MC goes up\\n        \"Events\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 15, 15, 15, 15, 15, 15, 15,\\n          15, 15, 15,],\\n        \"Test\":[0, 0, 0, 0, 300, 1000, 1000, 1000, 1000, 1000,\\n            1000, 1000, 1000, 1000, 500, 500, 500, 500, 500, 500, 500,500, 500 ],\\n        \"Sim-Events\":[0, 0, 0, 0, 1, 1, 1, 1, 5, 10,\\n            20, 30, 45, 60, 60, 60, 60, 60,60, 60,\\n          60, 60, 60, 60,]\\n    },\\n    #  Parameters\\n    #\"Analysis\":\\n    #{\"Scale\":[0, 0, 0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5, 0.5, 0.5,0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\\n    #   0.5,0.5,0.5],\\n    #    \"Add\":[\"PDs\", \"FDs\", \"ND-SAND\",\"ND-LAr+TMS\"]\\n    #},\\n    \"LBL\":\\n    {\"Comment\":\"NA”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n        \"Events\":[  0,  0,  0,  0,  0,  0, 0, 0,  0,  0, 0,  0,  0,  0,  0.00136,  0,  0.004080,  0,  0.008160,  0, 0.016320,  0,  0.021761], #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        \"Sim-Events\":[  0,  0,  0,  0,  0,  24,    24,    0,     0,  24, 0,  0,  0,  24,  24,  0,  24,  0,  24,  0, 24,  0,  24] #millions\\n},\\n\\n    \"HighE\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 0,  0.00249,  0,  0.01,  0.015,  0,  0,  0.04,  0,  0, 0.07,  0,  0] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 14, 0,  14,  0, 14,  14,  0,  0,  14,  0,  0,  14,  0,  0, 14,  0,  0], #millions\\n},\\n\\n\\n  \"Calib\":\\n    {\"Comment\":\"Uses largely same numbers as for LBL”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.167, # Hr/Event      #Based on Haiwang’s full FD study using 8 threads \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":10, # MB/Event             #Assumed not saving rawdigits\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":6000, #MB      #Haiwang’s full FD study: 8 threads\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,  0,  0,  0,  0,  0,    0,    0,     0,  0, 1.83,  3.65,  3.65,  3.65,  3.65,  3.65,  5.48,  5.48,  7.3,  7.3, 7.3,  7.3,  7.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  0, 2.6, 2.6,  2.6,  2.6, 2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6,  2.6, 2.6,  2.6,  2.6], #millions\\n},\\n\\n\\n\\n\\n    \"LowE\":\\n    {\"Comment\":This has used LBL numbers where possible, but radiologicals complicate (inflate) things.  Memory based on tests for the upcoming production”\\n        \"Raw-Store\":4000, # MB/Event   #scaled PDSP data (57MB/event)\\n        \"Reco-Data-CPU\":0.167, # Hr/Event      #Assumed dominated by signal processing\\n        \"Sim-CPU\":0.4, # Hr/Event   #Maybe sped up by multithreading but tests not been done \\n        \"Reco-Data-GPU\":0, #Hr/Event\\n        \"Sim-GPU\":0, #Hr/Event\\n        \"Reco-Data-Store\":4, # MB/Event     #Assumed dropping raw info\\n        \"Sim-Store\":1500, # MB/Event             #Assumed not saving rawdigits #radiologicals\\n        \"Reco-Memory\":6000, #MB        #A loose estimate based on Haiwang’s full FD study\\n        \"Sim-Memory\":24000, #MB      #Radiologicals in the full FD will be a problem\\n        \"Analysis-CPU\":0.5, \\n\\n        \"Events\":[  0,   0,   0,   0,   0,   0,   0,    0,     0,  0, 0,  0.0091,  0,  0.046,  0,  0,  0.1,  0,  0,  0.19, 0,  0,  0.3] #millions\\n        \"Test\":[0,  0,  0,  0,  0,   0,    0,   0, 0,  0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0,  0,  0], # commissioning stuff in TB\\n        “Sim-Events\":[  0,  0,  0,  0,  0,  10, 0, 0,  10,  0, 0,  10, 0, 10,  0,  0,  10,  0,  0,  10, 0,  0,  10], #millions\\n},\\n\\n\"Reprocess\":{\"SP\":3,\"DP\":3,\"PDHD\":3, \"PDVD\":3, \"PDs\":3,\"VD\":100,\"HD\":100,\"FDs\":100,\"ND-SAND\":100,\\n        \"ND-LAr+TMS\":100,\"LBL\":100,\"Calib\":100,\"HighE\":100,\"LowE\":100}, # of years of data reprocessed when do a new pass\\n\"AnalysisExtend\":2, # of years of analysis after end of reco/sim extends CPU, and GPU and disk\\n    \"PatternFraction\":{\"SP\":0.7,\"PDHD\":0.7,\"DP\":0.7,\"PDVD\":0.7,\"PDs\":0.7,\"HD\":0.1,\"VD\":0.1,\"FDs\":0.1,\\n\\t\\t       \"ND-SAND\":0.9,\"ND-LAr+TMS\":0.9,\"MARS\":0}, #fraction of time spent on PR as opposed to hit-finding\\n    \"TapeLifetimes\":{\"Raw-Store\":100, \"Test\":0.5, \"Reco-Data-Store\":15, \"Sim-Store\":15},\\n    \"DiskLifetimes\":{\"Raw-Store\":1, \"Test\":0.5, \"Reco-Data-Store\":3, \"Sim-Store\":2},  # raw and test only hang around a short while, can be restaged\\n    \"TapeCopies\":{\"Raw-Store\":2, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1},  # will take some coding to make these work out with 2 copies.\\n    \"DiskCopies\":{\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":2, \"Sim-Store\":1.5},\\n    \"PerYear\":\\n    {\"Raw-Store\":1, \"Test\":1, \"Reco-Data-Store\":1, \"Sim-Store\":1, \"Events\":1, \"Sim-Events\":1, \"Reco-Data-CPU\":1, \"Sim-CPU\":1, \"Analysis\":1, \"Analysis-CPU\":1, \"Reco-Data-GPU\":1, \"Sim-GPU\":1}, # of times you redo them per year, CPU is reco CPU, Sim-CPU is sim CPU\\n    \"Cores\":{\\n        \"Efficiency\":0.7,  # CPU conversion to Wall time, per K. Herner\\n        \"2020Units\":1  # raise this # if machines get faster\\n    },\\n    \"kHEPSPEC06PerCPU\":0.011,\\n    \"FiscalYearStart\":\"April 1\",\\n    \"CPU Accounting\":\"end of fiscal year\",\\n    \"Tape Accounting\":\"end of fiscal year\",\\n    \"Disk Accounting\":\"October 1\",\\n    \"TypeColors\": {\"Raw-Store\":\"blue\",\"Raw+Test\":\"green\", \"Test\":\"orange\", \"Reco-Data-Store\":\"red\", \"Sim-Store\":\"grey\", \"Total\":\"black\",\"FNAL\":\"blue\",\"UK\":\"red\",\"CZ\":\"green\",\"CERN\":\"cyan\",\"US\":\"orange\"},\\n    \"TypeLines\": {\"Raw-Store\":\"solid\",\"Raw+Test\":\"solid\", \"Test\":\"dashed\", \"Reco-Data-Store\":\"solid\", \"Sim-Store\":\"dashed\", \"Total\":\"solid\"},\\n    \"DetColors\": {\"SP\":\"green\",\"PDHD\":\"green\", \"DP\":\"magenta\",\"PDVD\":\"magenta\", \"PDs\":\"blue\", \"HD\":\"red\",\\n        \"VD\":\"red\",\"FDs\":\"red\",\"ND-SAND\":\"grey\",\"ND-LAr+TMS\":\"black\",\"Analysis\":\"orange\", \"Total\":\"black\",\"MARS\":\"purple\",\\n        \"Production\":\"blue\", \"FNAL\":\"orange\", \"CERN\":\"cyan\", \"National\":\"green\", \"LBL\":\"magenta\",\"Calib\":\"cyan\",\"HighE\":\"purple\",\"LowE\":\"blue\"\\n    },\\n    \"DetLines\": {\"SP\":\"solid\",\"PDHD\":\"dashed\", \"DP\":\"solid\",\"PDVD\":\"dotted\", \"PDs\":\"solid\", \"HD\":\"solid\",\\n        \"VD\":\"dashed\",\"FDs\":\"solid\",\"ND-SAND\":\"solid\",\"ND-LAr+TMS\":\"dashed\", \"MARS\":\"dashed\",\"Analysis\":\"dashed\", \"Total\":\"solid\",\"FNAL\":\"solid\", \"CERN\":\"solid\", \"National\":\"solid\",\"LBL\":\"dotted\",\"Calib\":\"dotted\",\"HighE\":\"dotted\",\"LowE\":\"dotted\"\\n        \\n    },\\n    \"SplitsYear\":2029,\\n    \"SplitsEarly\":{ # these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Reco-Data-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0}\\n        },\\n        \"Disk\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Reco-Data-Store\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.5,\"National\":0.00}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.4,\"CERN\":0.1,\"National\":0.5}}\\n    },\\n    \"SplitsLater\":{# these define the splits of storage - only for CCB use\\n        \"Tape\":{\\n            \"Raw-Store\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.50},\\n            \"Sim-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Reco-Data-Store\":{\"FNAL\":0.50,\"CERN\":0.0,\"National\":0.50},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"Disk\":{\\n            #\"Disk\":{\"Raw-Store\":0.0,\"Sim-Store\":0.75,\"Reco-Data-Store\":0.75,\"Test\":0.00} old version\\n            \"Raw-Store\":{\"FNAL\":1.0,\"CERN\":0.0,\"National\":0.0},\\n            \"Sim-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Reco-Data-Store\":{\"FNAL\":0.25,\"CERN\":0.0,\"National\":0.75},\\n            \"Test\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}\\n        },\\n        \"CPU\":{\"CPU\":{\"FNAL\":0.5,\"CERN\":0.0,\"National\":0.5}}\\n    },\\n    \\n    \"Explain\":{\\n        \"Detectors\":\"Detectors included in the calculation\",\\n        \"Cap\":\"Cap on Raw data/year in PB\",\\n        \"Base-Memory\":\"MB of memory per slot assumed as the average\",\\n        \"MaxYear\":\"Plot until year\",\\n        \"MinYear\":\"Plot starting with year\",\\n        \"Reprocess\":\"Number of years of data reprocessed when doing a new pass\",\\n        \"AnalysisExtend\":\"Years analysis continues after last reco/sim\",\\n        \"PatternFraction\":\"Fraction of time taken in pattern recognition\",\\n        \"TapeLifetimes\":\"Number of years kept on tape\",\\n        \"DiskLifetimes\":\"Number of years kept on disk\",\\n        \"TapeCopies\":\"Number of copies kept on tape\",\\n        \"DiskCopies\":\"Number of copies kept on disk\",\\n        \"PerYear\":\"Number of reprocessing done per year\",\\n        \"Cores\":\"Description of cores, efficiency and speed relative to 2020 vintage\",\\n        \"kHEPSPEC06PerCPU\":\"kHEPSPEC06 per core assumed\",\\n        \"SplitsYear\":\"Year CERN no longer responsible for disk or tape\",\\n        \"SplitsEarly\":\"Division between FNAL/CERN/National for storage until SplitsYear\",\\n        \"SplitsLater\":\"Division between FNAL/CERN/National for storage after SplitsYear\"\\n    },\\n    // \"Actual\":{\\n    //     \"wallactual\": {\"2021\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3},\\n    //         \"2022\":{\"Total\":41.2,\"Analysis\":9.3,\"MARS\":17.2,\"Production\":9.3}\\n    //     },\\n\\n    //     \"diskactual\":{\\n    //         \"2021\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30},\\n    //         \"2022\":{\"FNAL\":4.6,\"CERN\":0.975,\"UK\":2.177,\"CZ\":0.30}\\n    //     },\\n    //     \"tapeactual\":{\\n    //         \"2021\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0},\\n    //         \"2022\":{\"FNAL\":19.804,\"CERN\":5.02,\"National\":0.0}\\n    //     }\\n    // }\\n}\\n')\n    "
     ]
    }
   ],
   "source": [
    "\"Tex\"# read in a configfile\n",
    "#configfilename = \"Parameters_2022-11-21-2040.json\"\n",
    "\n",
    "#configfilename = \"DOE23-NDLAr_2023-11-03-2040b.json\"\n",
    "configfilename = \"DOE23-NDLAr_FD_2023-12-12-2040.json\"  # increase sim for ND\n",
    "\n",
    "#if len(sys.argv) > 1:\n",
    "#  configfile = sys.argv[1]\n",
    "\n",
    "shortname = configfilename.replace(\".json\",\"\")\n",
    "if os.path.exists(configfilename):\n",
    "  with open(configfilename,'r') as f:\n",
    "    #x = f.read()\n",
    "    #print (x[6000:6960])\n",
    "    config = commentjson.load(f)\n",
    "else:\n",
    "  print (\"no config file\",configfilename)\n",
    "  sys.exit(0)\n",
    "\n",
    "if not \"Version\" in config or config[\"Version\"] < 5:\n",
    "  print (\" this code expects Version >= 2\")\n",
    "  sys.exit(1)\n",
    "\n",
    "#json_formatted_str = commentjson.dumps(config, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15e8fb-85d9-4433-b8e5-f7dfad7d457f",
   "metadata": {},
   "source": [
    "# read in the config parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc556ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MWCWeight = config[\"MWCWeight\"] # do we weight cores by available memory? \n",
    "MaxYear = config[\"MaxYear\"]\n",
    "MWCstring = \"_noMWC\"\n",
    "if MWCWeight: MWCstring=\"\"\n",
    "#config[\"filename\"] = configfilename.replace(\"_\",\"\\_\")\n",
    "config[\"filename\"] = configfilename\n",
    "MinYear = config[\"MinYear\"]\n",
    "Detectors = config[\"Detectors\"]\n",
    "if DEBUG:\n",
    "  Detectors = [\"SP\",\"PDHD\",\"DP\"]\n",
    "#HMS Years = np.array(config[\"Years\"])\n",
    "Years = config[\"Years\"]\n",
    "#if DEBUG:\n",
    "#  Years = Years[0:7]\n",
    "\n",
    "\n",
    "shortname = shortname.replace(\"2040\",\"%d\"%MaxYear)+MWCstring\n",
    "dirname = shortname\n",
    "if not os.path.exists(dirname):\n",
    "    os.mkdir(dirname)\n",
    "shortname = dirname+\"/\"+dirname\n",
    "# make a tex output file\n",
    "texfilename = dirname+\".tex\"\n",
    "texfile = open(texfilename,'w')\n",
    "tablefile = open(os.path.join(dirname,\"tables.tex\"),'w')\n",
    "#texfile.write(\"\\\\input{Header.tex}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "size = len(Years)\n",
    "\n",
    "Units = config[\"Units\"]\n",
    "\n",
    "if not MWCWeight: \n",
    "    print (\"remove MWC\")\n",
    "    for type in Units.keys():\n",
    "        Units[type] = Units[type].replace(\"MWC-\",\"\")\n",
    "        Units[type] = Units[type].replace(\"Memory weighted \",\"\")\n",
    "        Units[type] = Units[type].replace(\"Memory Weighted \",\"\")\n",
    "    print (\"Units\", Units)\n",
    "        \n",
    "Formats = config[\"Formats\"]\n",
    "\n",
    "Detectors = config[\"Detectors\"]\n",
    "\n",
    "Cap = config[\"Cap\"]\n",
    "\n",
    "BaseMemory = config[\"Base-Memory\"]\n",
    "\n",
    "print (Detectors)\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "\n",
    "\n",
    "if \"Comment\" in DetectorParameters:\n",
    "    DetectorParameters.remove(\"Comment\")\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "# this is how far you go back each time you reprocess reco.\n",
    "Reprocess = config[\"Reprocess\"]\n",
    "\n",
    "AnalysisExtend = config[\"AnalysisExtend\"]\n",
    "\n",
    "PerYear = config[\"PerYear\"]\n",
    "\n",
    "StorageTypes = list(TapeCopies.keys())\n",
    "\n",
    "\n",
    "# plot config\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "TypeColors=config[\"TypeColors\"]\n",
    "TypeLines = config[\"TypeLines\"]\n",
    "\n",
    "PatternFraction = config[\"PatternFraction\"]\n",
    "\n",
    "SplitsYear = config[\"SplitsYear\"]\n",
    "SplitsEarly = config[\"SplitsEarly\"]\n",
    "SplitsLater = config[\"SplitsLater\"]\n",
    "\n",
    "Explain = config[\"Explain\"]\n",
    "Explain[\"filename\"] = \"Input configuration file\"\n",
    "\n",
    "diskactual = config[\"Actual\"][\"diskactual\"]\n",
    "tapeactual = config[\"Actual\"][\"tapeactual\"]\n",
    "wallactual = config[\"Actual\"][\"wallactual\"]\n",
    "efficiency = config[\"Cores\"][\"Efficiency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15158ba-4a14-42f7-b6ab-7767233cb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output some text that explains your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in Explain.keys():\n",
    "    \n",
    "    tablefile.write(\"{\\\\tt %s:} %s = {\\\\tt %s} \\\\\\\\\\n\"%(f,Explain[f], config[f]))\n",
    "    print (Explain[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d9fc0-5cac-4e80-b40a-291a28916901",
   "metadata": {},
   "source": [
    "# Change from config - which goes 0-N to real year indices = 2018..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8831c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dofirst = [\"Events\",\"Test\",\"Sim-Events\"]\n",
    "print (\"Detector Parameters\",DetectorParameters)\n",
    "# read in the raw information\n",
    "\n",
    "Inputs = {}\n",
    "\n",
    "for det in Detectors:\n",
    "  Inputs[det]={}\n",
    "  for type in dofirst:\n",
    "      Inputs[det][type]={}\n",
    "      if DEBUG: print (det,type,config[det][type])\n",
    "      for year in Years:\n",
    "          Inputs[det][type][year] = float(config[det][type][year-Years[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c352d-9e48-42f3-9f07-d800549d9c76",
   "metadata": {},
   "source": [
    "# Take the raw # of events/year and use cumulate to emulate reprocessing for data.  Then build CPU estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecc2a2-87d0-4929-9b24-d9d84476a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in Detectors:\n",
    "    if DEBUG: print (\"Events\",det,Inputs[det][\"Events\"])\n",
    "    #print (\"see it\", det,Inputs[det].keys())\n",
    "    \n",
    "    if not MWCWeight:\n",
    "        print (\"memory check\",MWCWeight,config[det][\"Reco-Memory\"],config[det][\"Sim-Memory\"])\n",
    "        print (\"disable MWCWeight\")\n",
    "    \n",
    "        config[det][\"Reco-Memory\"]=BaseMemory\n",
    "        config[det][\"Sim-Memory\"]=BaseMemory\n",
    "    print (\"memory check\",MWCWeight,config[det][\"Reco-Memory\"],config[det][\"Sim-Memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884932ef-9f13-4037-9add-01cea9dd97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in other useful arrays\n",
    "for det in Detectors:\n",
    "    if DEBUG: print (\"Events\",det,Inputs[det][\"Events\"])\n",
    "    #print (\"see it\", det,Inputs[det].keys())\n",
    "    \n",
    "    \n",
    "    for key in DetectorParameters:\n",
    "        #print(key,det)\n",
    "        # skip the ones already done\n",
    "        if key in dofirst:\n",
    "          continue\n",
    "        \n",
    "        # sim has its own configuration\n",
    "        # print (\"this is the key\",det,key)\n",
    "        if key == \"Reco-Data-CPU\" and DEBUG:\n",
    "            print (\"reco events\",det,Inputs[det][\"Events\"])\n",
    "        if key in [\"Reco-Data-CPU\",\"Reco-Data-GPU\",\"Reco-Data-Store\"]:  # if doing reco, do over previous events using memory\n",
    "            Inputs[det][key] = cumulateMap(Years,Inputs[det][\"Events\"],Reprocess[det])\n",
    "            for year in Years:\n",
    "                Inputs[det][key][year] *= config[det][key]\n",
    "            \n",
    "            if key == \"Reco-Data-CPU\" and MWCWeight:\n",
    "                if DEBUG: print (\"fix the memory\",config[det][\"Reco-Memory\"]/BaseMemory)\n",
    "                for year in Years:\n",
    "                    Inputs[det][key][year] *= (config[det][\"Reco-Memory\"]/BaseMemory)\n",
    "                if DEBUG: print (\"reco-data-cpu\",det, Inputs[det][key])\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        if key == \"Raw-Store\":\n",
    "            Inputs[det][key] ={}\n",
    "            for year in Years:\n",
    "                Inputs[det][key][year] = Inputs[det][\"Events\"][year]*config[det][key]\n",
    "            continue\n",
    "            \n",
    "        if key in [\"Sim-Store\",\"Sim-CPU\",\"Sim-GPU\"]:\n",
    "            \n",
    "            Inputs[det][key] ={}\n",
    "            for year in Years:\n",
    "                Inputs[det][key][year]=Inputs[det][\"Sim-Events\"][year]*config[det][key]\n",
    "                if key == \"Sim-CPU\" and MWCWeight:\n",
    "                    Inputs[det][key][year]*=(config[det][\"Sim-Memory\"]/BaseMemory)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            if key == \"Sim-Store\" or key == \"Reco-Data-Store\":\n",
    "                print (\"got here\", key)\n",
    "                Inputs[det][key] = extendMap(Years,Inputs[det][key],AnalysisExtend)\n",
    "            continue\n",
    "            \n",
    "         # right now this uses MWC - may be ok as reading in big stuff uses memory\n",
    "            \n",
    "        if key in [\"Analysis-CPU\"]:  # keep analyzing for a few years. \n",
    "            data = {}\n",
    "            mc = {}\n",
    "            Inputs[det][\"Analysis-CPU\"] = {}\n",
    "            data  = extendMap(Years,Inputs[det][\"Reco-Data-CPU\"],AnalysisExtend)\n",
    "            if DEBUG: print (\"data\",data)\n",
    "            mc = extendMap(Years,Inputs[det][\"Sim-CPU\"],AnalysisExtend)\n",
    "            if DEBUG: print (\"mc\",mc)\n",
    "            for year in Years:\n",
    "                total = data[year]\n",
    "                total += mc[year]\n",
    "                Inputs[det][key][year] = total *config[det][\"Analysis-CPU\"]  # this scales by a factor relative to reco/sim-MWC\n",
    "           \n",
    "        if DEBUG: print (\"other key\",det,key)\n",
    "\n",
    "\n",
    "# do a little cleanup\n",
    "\n",
    "for det in Inputs.keys():\n",
    "    \n",
    "    if \"Sim-Memory\" in Inputs[det]:\n",
    "        Inputs[det].pop(\"Sim-Memory\")\n",
    "    if \"Reco-Memory\" in Inputs[det]:\n",
    "        Inputs[det].pop(\"Reco-Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data file which uses # of events to figure out how big samples are\n",
    "\n",
    "if PerYear[\"Reco-Data-Store\"]!=PerYear[\"Reco-Data-CPU\"]:\n",
    "    print (\"Data growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Data-Store\"] = PerYear[\"Reco-Data-CPU\"]\n",
    "if PerYear[\"Sim-Store\"]!=PerYear[\"Sim-CPU\"]:\n",
    "    print (\"Sim growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Sim-Store\"] = PerYear[\"Sim-CPU\"]\n",
    "\n",
    "Data = {}\n",
    "dump = open(\"dump.txt\",'w')\n",
    "\n",
    "    \n",
    "#print (Inputs.keys())\n",
    "fields = list(Inputs[\"ND-SAND\"].keys())\n",
    "print (\"fields\",fields)\n",
    "for dtype in fields:\n",
    "  Data[dtype] = {}\n",
    "  if \"Memory\" in dtype:\n",
    "        continue\n",
    "  for det in Inputs.keys():\n",
    "    Data[dtype][det] = {}\n",
    "    # this allows you to, say, do 2 passes of reco/year\n",
    "    for year in Years:\n",
    "        Data[dtype][det][year] = Inputs[det][dtype][year] * float(PerYear[dtype])\n",
    "    # compensate for nominal units being millions and TB or singles and MB\n",
    "    if Units[dtype] == \"PB\":\n",
    "        for year in Years:\n",
    "            Data[dtype][det][year] *= 0.001\n",
    "    ds = \"data %s %s %f\\n\"%(dtype,det,Data[dtype][det][2022])\n",
    "    dump.write(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7ea5f",
   "metadata": {},
   "source": [
    "- impose a cap at Cap (30 PB/year if set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impose a cap at Cap on things derived from raw data\n",
    "\n",
    "dtype = \"Raw-Store\"\n",
    "\n",
    "Data[\"Raw-Store\"][\"Total\"] = {}\n",
    "for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "for det in Inputs.keys():\n",
    "    for year in Years:\n",
    "        Data[dtype][\"Total\"][year] +=  Data[\"Raw-Store\"][det][year]\n",
    "        \n",
    "dtypes = [\"Raw-Store\"] #,\"Reco-Data-CPU\"]\n",
    "for dtype in dtypes:\n",
    "    for det in Inputs.keys():\n",
    "        #print (dtype,det,2035,1.0,Data[dtype][det][2035] )\n",
    "        for year in Years:\n",
    "            cap = Data[\"Raw-Store\"][\"Total\"][year]/Cap\n",
    "           # print (dtype,det,year,cap,Data[dtype][det][year] )\n",
    "            if cap > 1:\n",
    "                Data[dtype][det][year] /=cap\n",
    "        #print (dtype,det,2035,cap,Data[dtype][det][2035] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fa87a",
   "metadata": {},
   "source": [
    "# Make a total across detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dtypes = [\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]\n",
    "\n",
    "\n",
    "\n",
    "for dtype in dtypes:\n",
    "    Data[dtype][\"Total\"] ={}\n",
    "    \n",
    "        \n",
    "    for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "    for det in Inputs.keys():\n",
    "        #if dtype != \"Analysis\":  # not certain what this does... I think it is leftover. \n",
    "        for year in Years:\n",
    "               Data[dtype][\"Total\"][year]+=  Data[dtype][det][year] \n",
    "    \n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2f815-2faf-4863-8e0b-4f72ab613666",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102174c5-031f-4d8c-ac18-bacef67a024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\",\"Reco-Data-GPU\",\"Sim-GPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "ToCSV2(shortname+\"-Reco-Data-GPU\",\"Reco-Data-GPU\",PlotYears,Data,Units,Formats)\n",
    "ToCSV2(shortname+\"-Sim-GPU\",\"Sim-GPU\",PlotYears,Data,Units,Formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb46116-8c96-422c-907c-a50be38b6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "print (Inputs.keys())\n",
    "other = list(Inputs[\"ND-SAND\"].keys())+[\"Total\"]\n",
    "\n",
    "print (other)\n",
    "\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dee43a-2d39-4476-bc7e-3b98c5c407fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233f531-1f03-4ceb-9fb6-86094ea46d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224b89a-dbe9-4d5e-93f3-5234e02a19e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge protodune info\n",
    "\n",
    "if DEBUG: print (\"Data keys\",Data.keys())\n",
    "\n",
    "for dtype in Data.keys():\n",
    "    if DEBUG: print (\"Merge protodunes\",dtype)\n",
    "    det = \"PDs\" \n",
    "    Data[dtype][det] = {}\n",
    "    for year in Years:  \n",
    "        Data[dtype][det][year] = Data[dtype][\"SP\"][year] + Data[dtype][\"DP\"][year] + Data[dtype][\"PDHD\"][year] + Data[dtype][\"PDVD\"][year]\n",
    "\n",
    "    Data[dtype].pop(\"SP\")\n",
    "    Data[dtype].pop(\"PDHD\")\n",
    "    Data[dtype].pop(\"DP\")\n",
    "    Data[dtype].pop(\"PDVD\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge far detector into \"FDs\n",
    "for dtype in Data.keys():\n",
    "    det = \"FDs\"\n",
    "    print (\"merge FDS\",dtype)\n",
    "    Data[dtype][det] =  {}\n",
    "    for year in Years:  \n",
    "        Data[dtype][det][year] = Data[dtype][\"HD\"][year] + Data[dtype][\"VD\"][year]\n",
    "    Data[dtype].pop(\"HD\")\n",
    "    Data[dtype].pop(\"VD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ce0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a total CPU category\n",
    "\n",
    "Data[\"Total-CPU\"]={}\n",
    "\n",
    "for det in CombinedDetectors:\n",
    "    Data[\"Total-CPU\"][det] =  {}\n",
    "    for year in Years:\n",
    "        Data[\"Total-CPU\"][det][year] = Data[\"Reco-Data-CPU\"][det][year] + Data[\"Sim-CPU\"][det][year] + Data[\"Analysis-CPU\"][det][year]\n",
    "    #print(det,Data[\"Total-CPU\"][det])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee341ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make totals across categories. \n",
    "\n",
    "DataTypes = list(Data.keys())\n",
    "\n",
    "for dt in DataTypes:\n",
    "    Data[dt][\"Total\"] = {}\n",
    "    for year in Years:\n",
    "        Data[dt][\"Total\"][year]=0.0\n",
    "    for k in Data[dt].keys():\n",
    "        if k == \"Total\":\n",
    "          continue  \n",
    "        for year in Years:\n",
    "            Data[dt][\"Total\"][year] += Data[dt][k][year]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a446d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and make a special data type for cores\n",
    "\n",
    "Data[\"Cores\"] = {}\n",
    "Data[\"HS23\"] = {}\n",
    "Data[\"Wall\"] = {}\n",
    " \n",
    "MHrsPerYear = 1000000/365./24.\n",
    "print (\"MHrsPerYear\",MHrsPerYear)\n",
    "print (\"total-CPU keys\",Data[\"Total-CPU\"].keys())\n",
    "for k in Data[\"Total-CPU\"].keys():\n",
    "#     if \"MARS\" not in k :\n",
    "#         efficiency = config[\"Cores\"][\"Efficiency\"]\n",
    "#     else:\n",
    "#         efficiency = 1\n",
    "\n",
    "    scaleTo2020 = config[\"Cores\"][\"2020Units\"]\n",
    "    Data[\"Cores\"][k]={}\n",
    "    Data[\"Wall\"][k]={}\n",
    "    Data[\"HS23\"][k]={}\n",
    "#    Data[\"WALL\"][k]={}\n",
    "    for year in Years:\n",
    "        Data[\"Wall\"][k][year] = Data[\"Total-CPU\"][k][year]/scaleTo2020/efficiency\n",
    "        Data[\"Cores\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency\n",
    "        Data[\"HS23\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency*config[\"kHEPSPEC06PerCPU\"]\n",
    "#        Data[\"WALL\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/efficiency/scaleTo2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683f1a8-bc81-49a5-b4ca-cccc7942aa11",
   "metadata": {},
   "source": [
    "# Yearly info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202449e-e78b-402e-8feb-ebc21da114d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"] \n",
    "DrawDet(shortname+\"_byyear\",\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines)#,cpuactual)\n",
    "DrawDet(shortname+\"_byyear\",\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines)#,coreactual)\n",
    "DrawDet(shortname+\"_byyear\",\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "DrawDet(shortname+\"_byyear\",\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for Storage work out split between different institutions\n",
    "\n",
    "Splits = {}\n",
    "for f in SplitsEarly:\n",
    "    Splits[f] = {}\n",
    "    for t in SplitsEarly[f]:\n",
    "        Splits[f][t] = {}\n",
    "        for loc in SplitsEarly[f][t]: \n",
    "            Splits[f][t][loc] = {}\n",
    "            #print (f,t,Splits[f][t],Splits[f][t][0])\n",
    "    \n",
    "            for y in Years:\n",
    "                if y < SplitsYear:\n",
    "                    Splits[f][t][loc][y]=SplitsEarly[f][t][loc]\n",
    "                else:\n",
    "                    Splits[f][t][loc][y]=SplitsLater[f][t][loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75873e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG: print (Splits[\"CPU\"])\n",
    "\n",
    "for key in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]: \n",
    "    \n",
    "    for site in [\"FNAL\",\"CERN\",\"National\"]:\n",
    "        Data[key][site] = {}\n",
    "        for year in Years:\n",
    "            \n",
    "            Data[key][site][year] = Data[key][\"Total\"][year]*Splits[\"CPU\"][\"CPU\"][site][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5209e-8df6-4fb7-a6ba-b2fc3e3c0b33",
   "metadata": {},
   "source": [
    "# here is where we start doing cumulation across years for disk and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do some Cumulative-work.  Stuff stays on tape/disk for different amounts of time and we have multiple copies\n",
    "\n",
    "Storage = {}\n",
    "for k in StorageTypes:\n",
    "    Storage[k] = {}\n",
    "Storage[\"Total\"] = {}\n",
    "Storage[\"National\"] = {}\n",
    "Storage[\"FNAL\"] = {}\n",
    "Storage[\"CERN\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"National\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"National\"][\"Cumulative-Disk\"] = {}\n",
    "\n",
    "\n",
    "for year in Years:\n",
    "    Storage[\"Total\"][\"Cumulative-Tape\"][year] = 0.0\n",
    "    Storage[\"Total\"][\"Cumulative-Disk\"][year] = 0.0\n",
    "\n",
    "for k in StorageTypes:\n",
    "    Storage[k][\"Tape\"] = {}\n",
    "    Storage[k][\"Disk\"] = {}\n",
    "    for year in Years:\n",
    "        Storage[k][\"Tape\"][year] = Data[k][\"Total\"][year]*TapeCopies[k]\n",
    "        Storage[k][\"Disk\"][year] = Data[k][\"Total\"][year]*DiskCopies[k]\n",
    "    # extend disk for Analysis HMS 6-24-2023\n",
    "    Storage[k][\"Disk\"]  = extendMap(Years,Storage[k][\"Disk\"],AnalysisExtend) \n",
    "    \n",
    "    Storage[k][\"Cumulative-Tape\"] = cumulateMap(Years,Storage[k][\"Tape\"],TapeLifetimes[k])\n",
    "    Storage[k][\"Cumulative-Disk\"] = cumulateMap(Years,Storage[k][\"Disk\"],DiskLifetimes[k])\n",
    "    \n",
    "    for year in Years:\n",
    "        Storage[\"Total\"][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]\n",
    "        Storage[\"Total\"][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]\n",
    "    \n",
    "    \n",
    "        \n",
    "for loc in Splits[\"Disk\"][\"Raw-Store\"]:\n",
    "    for year in Years:\n",
    "        Storage[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "        Storage[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "        for k in StorageTypes:\n",
    "              Storage[loc][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]*Splits[\"Disk\"][k][loc][year]\n",
    "              Storage[loc][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]*Splits[\"Tape\"][k][loc][year]\n",
    "\n",
    "\n",
    "# cdisk = SumOver1(\"Cumulative-Disk\",Data)\n",
    "# print (\"sum over\",cdisk)\n",
    "\n",
    "# for year in Years:\n",
    "#         Data[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "#         Data[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "#         for k in StorageTypes:\n",
    "#               Data[loc][\"Cumulative-Disk\"][year] += Data[k][\"Cumulative-Disk\"][year] \n",
    "#               Data[loc][\"Cumulative-Tape\"][year] += Data[k][\"Cumulative-Tape\"][year] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texfile.write(\"\\\\section{Projected Disk and Tape needs by source and site}\\n\")\n",
    "#ToCSV1(shortname+\"-Disk_by_location\",\"Cumulative-Disk\",PlotYears,Storage,Units,Formats)\n",
    "#ToCSV1(shortname+\"-Tape_by_location\",\"Cumulative-Tape\",PlotYears,Storage,Units,Formats)\n",
    "# s = \"\\\\begin{table}[h]\\n \\\\centering\\\\csvautotabularright\\\n",
    "# {external/DUNERSEUSAGE-2022-11-14.csv}\\n \\\\label{Cumulative-Tape}\\n\\\n",
    "# \\\\caption{Rucio report on storage usage 2022-11-14 from the Scotgrid Dashboard \\\n",
    "# \\\\href{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}.}\\n \\\\end{table}\\n\"\n",
    "# s.replace(\"_\",\"\\_\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# s = TableTex(shortname+\"-Disk_by_location\",\"Disk requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Disk\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "# s = TableTex(shortname+\"-Tape_by_location\",\"Tape requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Tape\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# texfile.write(\"\\\\clearpage\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7de3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do some plots\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"]\n",
    "\n",
    "cpuactual = []\n",
    "coreactual = []\n",
    "wallactual = []\n",
    "\n",
    "Sites = [\"FNAL\",\"CERN\",\"National\",\"Total\"]\n",
    "\n",
    "\n",
    "DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines,cpuactual)\n",
    "DrawDet(shortname,\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines,coreactual)\n",
    "DrawDet(shortname,\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "DrawDet(shortname,\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "# DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Sites,Units,DetColors,DetLines,cpuactual)\n",
    "# DrawDet(shortname,\"Cores\",PlotYears,Data,Sites,Units,DetColors,DetLines,coreactual)\n",
    "# #DrawDet(shortname,\"WALL\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "# DrawDet(shortname,\"HS23\",PlotYears,Data,Sites,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "for x in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]:\n",
    "    ToCSV2(shortname+\"-\"+x,x,PlotYears,Data,Units,Formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43477445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "Captions2 = {\"Events\":\"Projected million of detector events per year.  Reconstructed data resources are based on this number.\",\n",
    "\"Test\":\"Projected PB of Test data per year.\",\n",
    "\"Sim-Events\":\"Projected millions of simulated events per year. Simulated data resources are based on this number. \",\n",
    "\"Raw-Store\":\"Projected raw data written per year in PB, derived from the number of events.\",\n",
    "\"Reco-Data-CPU\":\"Projected CPU needs in core-hrs for data reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction.  Assumes rereconstruction of several years of older data.\",\n",
    "\"Sim-CPU\":\"Projected CPU needs in core-hrs for simulation and reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction. Based directly on the number of simulated Events.\",\n",
    "\"Reco-Data-Store\":\"Projected PB of reconstructed data per year. Includes reprocessing.\",\n",
    "\"Sim-Store\":\"Projected PB of simulated data/year\",\n",
    "\"Total-CPU\":\"Slot weighted CPU needs in core-years. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Cores\":\"Slot weighted CPU needs in number of cores. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"HS23\":\"Slot weighted CPU needs in kHS23 hrs. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Analysis-CPU\":\"Slot weighted analysis CPU needs in core-hrs. Assumed to be a weighted fraction of reco+sim needs.\",\n",
    "            }\n",
    "print (Data[\"Events\"][\"PDs\"])\n",
    "print (Data[\"Events\"][\"FDs\"])\n",
    "print (Data[\"Events\"][\"ND-SAND\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6294a-aab7-4a64-9986-ee9d4e684394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for key in [\"Cores\",\"Total-CPU\",\"HS23\"]:\n",
    "#     print (\"Got to Here\")\n",
    "#     if not key in Units:\n",
    "#         print (\"no units for key\",key)\n",
    "#         continue\n",
    "#     ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "#     s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "#     #DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "#     #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     print  (\"Got to here\")\n",
    "#     s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     #texfile.write(s2)\n",
    "#     tablefile.write(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Storage.keys())\n",
    "    \n",
    "Captions1 = {\"Cumulative-Tape\":\"Cumulative Tape needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\", \n",
    "             \"Cumulative-Disk\":\"Cumulative Disk needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\",\n",
    "            \"HS23\":\"CPU needs in HS23 units\"}\n",
    "            \n",
    "\n",
    "for key in ['Cumulative-Tape', 'Cumulative-Disk']:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    actual = None\n",
    "    if key == \"Cumulative-Tape\":\n",
    "        actual = tapeactual\n",
    "    if key == \"Cumulative-Disk\":\n",
    "        actual = diskactual\n",
    "    print (actual)\n",
    "    ToCSV1(shortname+\"-\"+key,key,PlotYears,Storage,Units,Formats)\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Source\",key,PlotYears,Storage,Units,Formats,['Raw-Store', 'Test', 'Reco-Data-Store', 'Sim-Store', 'Total'])\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Request\",key,PlotYears,Storage,Units,Formats,['National', 'FNAL', 'CERN', 'Total'])\n",
    "    s = TableTex(shortname+\"-\"+key,Captions1[key],key+\"\\n\")\n",
    "    print (key,s)\n",
    "    dunestyle.Preliminary()\n",
    "    DrawType(shortname,key,PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    " \n",
    "    s2 = BothTex(shortname,key+\".png\",Captions1[key],key)\n",
    "\n",
    "    #texfile.write(s2)\n",
    "    texfile.write(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f824b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Types)\n",
    "\n",
    "for key in Types:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "\n",
    "for key in Sites:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tapepoints = np.zeros(len(Years))\n",
    "diskpoints = np.zeros(len(Years))\n",
    "\n",
    "#DrawType(shortname,\"Tape\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Tape\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefile.close()\n",
    "#texfile.write(\"\\\\input{bibmaker.tex}\\n\")\n",
    "#texfile.write(\"\\\\clearpage\\n\")\n",
    "#texfile.write(\"\\\\section{Appendix - Model inputs}\\n\")\n",
    "#texfile.write(\"\\\\input{\"+dirname+\"/tables.tex}\\n\")\n",
    "#texfile.write(\"\\\\end{document}\\n\")\n",
    "texfile.close()\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66a633-04f7-46e4-a967-f3d5e46f7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "jname = configfilename.replace(\".json\",\"_internal.json\")\n",
    "jj = open(jname,'w')\n",
    "commentjson.dump(Data,jj,indent=4)\n",
    "jj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmd='pdflatex MoreSim_2023-06-22-2040.tex'\n",
    "#get_ipython().system('{cmd}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
