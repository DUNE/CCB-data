{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89827bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/schellma/miniconda/envs/rootenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952231a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUNE plot style enabled\n"
     ]
    }
   ],
   "source": [
    "# code to generate yearly summaries of DUNE data volumes from input parameters\n",
    "# rewritten from the version in the CDR - mainly by using maps of years instead of arrays to make it clearer what is in each year.\n",
    "# HMS 2022-10-23\n",
    "\n",
    "# if you have json problems, run the program ../strip.py on your file to take off comments\n",
    "# and then test using https://jsonlint.com\n",
    "#import numberutils\n",
    "\n",
    "import os,sys,string,time,commentjson,datetime, math\n",
    "import json\n",
    "import nbconvert\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "DEBUG = False\n",
    "DRAW = True\n",
    "import numpy as np\n",
    "import scipy\n",
    "import dunestyle.matplotlib as dunestyle\n",
    "\n",
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import cumulateMap\n",
    "from NumberUtils import DrawDet\n",
    "from NumberUtils import DrawType\n",
    "from NumberUtils import makeArray\n",
    "from NumberUtils import ToCSV1\n",
    "from NumberUtils import ToCSV2\n",
    "from NumberUtils import SumOver1\n",
    "from NumberUtils import SumOver2\n",
    "from NumberUtils import TableTex\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import BothTex\n",
    "from NumberUtils import extendMap\n",
    "from NumberUtils import makeParameter\n",
    "\n",
    "from DataHolder import DataHolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c9bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many histograms to draw in multi-hist plots\n",
    "N_HISTS = 8   # exhibits all the colors in the Okabe-Ito cycler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b76a0",
   "metadata": {},
   "source": [
    "# specify the json file here.  Will create a subdirectory for plots with a similar name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94ae3a",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401d49d",
   "metadata": {},
   "source": [
    "\"Tex\"# read in a configfile\n",
    "#configfilename = \"Parameters_2022-11-21-2040.json\"\n",
    "\n",
    "#configfilename = \"DOE23-NDLAr_2023-11-03-2040b.json\"\n",
    "#configfilename = \"DOE23-NDLAr_2023-12-11-2040.json\"  # increase sim for ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea847c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "configfilename = \"NearTerm_2024-06-12-2040.json\"\n",
    "#if len(sys.argv) > 1:\n",
    "#  configfile = sys.argv[1]\n",
    "\n",
    "shortname = configfilename.replace(\".json\",\"\")\n",
    "if os.path.exists(configfilename):\n",
    "  with open(configfilename,'r') as f:\n",
    "    #x = f.read()\n",
    "    #print (x[6000:6960])\n",
    "    config = commentjson.load(f)\n",
    "else:\n",
    "  print (\"no config file\",configfilename)\n",
    "  sys.exit(0)\n",
    "\n",
    "if not \"Version\" in config or config[\"Version\"] < 5:\n",
    "  print (\" this code expects Version >= 2\")\n",
    "  sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f23c2f",
   "metadata": {},
   "source": [
    "# read in the config parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663d8582-c8c8-4b2a-8ace-1123d5fd11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove MWC\n",
      "Units {'Events': 'Million', 'Raw-Store': 'PB', 'Test': 'PB', 'Raw+Test': 'PB', 'Reco-Data-Store': 'PB', 'Reco-Data-CPU': 'CPU MHrs', 'Sim-Events': 'M', 'Sim-Store': 'PB', 'Sim-CPU': 'CPU MHrs', 'Analysis-CPU': 'CPU MHrs', 'All': 'PB', 'Years': '', 'Total-CPU': 'CPU MHrs', 'Cumulative-Tape': 'PB', 'Cumulative-Disk': 'PB', 'Tape': 'PB', 'Disk': 'PB', 'Cores': '2020-vintage MWC Cores', 'HS23': 'kHS23-yrs', 'Wall': 'Wall MHrs', 'HPC-Storage': 'PB', 'HPC-CPU': 'CPU MHrs', 'Reco-Data-GPU': 'GPU MHrs', 'Sim-GPU': 'GPU MHrs'}\n",
      "['SP', 'PDHD', 'DP', 'PDVD', 'HD', 'VD', 'ND-SAND', 'ND-LAr+TMS']\n",
      "['Raw-Store', 'Test', 'Reco-Data-Store', 'Sim-Store']\n"
     ]
    }
   ],
   "source": [
    "MWCWeight = config[\"MWCWeight\"] # do we weight cores by available memory? \n",
    "MaxYear = config[\"MaxYear\"]\n",
    "MWCstring = \"_noMWC\"\n",
    "if MWCWeight: MWCstring=\"\"\n",
    "#config[\"filename\"] = configfilename.replace(\"_\",\"\\_\")\n",
    "config[\"filename\"] = configfilename\n",
    "MinYear = config[\"MinYear\"]\n",
    "Detectors = config[\"Detectors\"]\n",
    "if DEBUG:\n",
    "  Detectors = [\"SP\",\"PDHD\",\"DP\"]\n",
    "#HMS Years = np.array(config[\"Years\"])\n",
    "Years = config[\"Years\"]\n",
    "#if DEBUG:\n",
    "#  Years = Years[0:7]\n",
    "\n",
    "\n",
    "shortname = shortname.replace(\"2040\",\"%d\"%MaxYear)+MWCstring\n",
    "dirname = shortname\n",
    "if not os.path.exists(dirname):\n",
    "    os.mkdir(dirname)\n",
    "shortname = dirname+\"/\"+dirname\n",
    "# make a tex output file\n",
    "texfilename = dirname+\".tex\"\n",
    "texfile = open(texfilename,'w')\n",
    "tablefile = open(os.path.join(dirname,\"tables.tex\"),'w')\n",
    "\n",
    "size = len(Years)\n",
    "\n",
    "Units = config[\"Units\"]\n",
    "\n",
    "RequestYear=2024\n",
    "if \"RequestYear\" in config:\n",
    "    RequestYear= config[\"RequestYear\"]\n",
    "\n",
    "if not MWCWeight: \n",
    "    print (\"remove MWC\")\n",
    "    for type in Units.keys():\n",
    "        Units[type] = Units[type].replace(\"MWC-\",\"\")\n",
    "        Units[type] = Units[type].replace(\"Memory weighted \",\"\")\n",
    "        Units[type] = Units[type].replace(\"Memory Weighted \",\"\")\n",
    "    print (\"Units\", Units)\n",
    "        \n",
    "Formats = config[\"Formats\"]\n",
    "\n",
    "Detectors = config[\"Detectors\"]\n",
    "DataTypes = config[\"DataTypes\"]\n",
    "NativeTypes = config[\"NativeTypes\"]\n",
    "Resources = config[\"Resources\"]\n",
    "Locations = config[\"Locations\"]\n",
    "\n",
    "Cap = config[\"Cap\"]\n",
    "\n",
    "BaseMemory = config[\"Base-Memory\"]\n",
    "\n",
    "print (Detectors)\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "if \"Comment\" in DetectorParameters:\n",
    "    DetectorParameters.remove(\"Comment\")\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "# this is how far you go back each time you reprocess reco.\n",
    "Reprocess = config[\"Reprocess\"]\n",
    "\n",
    "AnalysisExtend = config[\"AnalysisExtend\"]\n",
    "\n",
    "PerYear = config[\"PerYear\"]\n",
    "\n",
    "StorageTypes = list(TapeCopies.keys())\n",
    "\n",
    "print (StorageTypes)\n",
    "\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "TypeColors=config[\"TypeColors\"]\n",
    "TypeLines = config[\"TypeLines\"]\n",
    "\n",
    "PatternFraction = config[\"PatternFraction\"]\n",
    "\n",
    "SplitsYear = config[\"SplitsYear\"]\n",
    "SplitsEarly = config[\"SplitsEarly\"]\n",
    "SplitsLater = config[\"SplitsLater\"]\n",
    "\n",
    "Explain = config[\"Explain\"]\n",
    "Explain[\"filename\"] = \"Input configuration file\"\n",
    "\n",
    "diskactual = config[\"Actual\"][\"diskactual\"]\n",
    "tapeactual = config[\"Actual\"][\"tapeactual\"]\n",
    "wallactual = config[\"Actual\"][\"wallactual\"]\n",
    "efficiency = config[\"Cores\"][\"Efficiency\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9da691-2ed2-43bf-b8b5-c558e362d3c1",
   "metadata": {},
   "source": [
    "# Output some text that explains your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcb3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectors included in the calculation\n",
      "Cap on Raw data per year in PB\n",
      "MB of memory per slot assumed as the average\n",
      "Plot until year\n",
      "Plot starting with year\n",
      "Number of years of data reprocessed when doing a new pass\n",
      "Years analysis continues after last reco/sim\n",
      "Fraction of time taken in pattern recognition\n",
      "Number of years kept on tape\n",
      "Number of years kept on disk\n",
      "Number of copies kept on tape\n",
      "Number of copies kept on disk\n",
      "Number of reprocessing done per year\n",
      "Description of cores, efficiency and speed relative to 2020 vintage\n",
      "kHEPSPEC06 per core assumed\n",
      "Year CERN no longer responsible for disk or tape\n",
      "Division between FNAL/CERN/Global for storage until SplitsYear\n",
      "Division between FNAL/CERN/Global for storage after SplitsYear\n",
      "Input configuration file\n"
     ]
    }
   ],
   "source": [
    "for f in Explain.keys():\n",
    "\n",
    "    field = \"{\\\\tt %s:} %s = {\\\\tt %s} \\\\\\\\\\n\"%(f,Explain[f], config[f])\n",
    "    field = field.replace(\"_\",\"\\_\")\n",
    "    tablefile.write(field)\n",
    "    print (Explain[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c57215",
   "metadata": {},
   "source": [
    "# Change from config - which goes 0-N to real year indices = 2018..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07defaa1-0f7c-45ce-a3ec-4c1d6ec814fd",
   "metadata": {},
   "source": [
    "<!-- dofirst = [\"Events\",\"Test\",\"Sim-Events\"]\n",
    "print (\"Detector Parameters\",DetectorParameters)\n",
    "# read in the raw information\n",
    "\n",
    "Inputs = {}\n",
    "timeline = open(\"timeline.csv\",'w')\n",
    "timeline.write(\"detector, datatype \")\n",
    "for year in Years:\n",
    "    timeline.write(\", %d\"%year)\n",
    "timeline.write(\"\\n\")\n",
    "\n",
    "for det in Detectors:\n",
    "    Inputs[det]={}\n",
    "    for type in dofirst:\n",
    "      Inputs[det][type]={}\n",
    "      if DEBUG: print (det,type,config[det][type])\n",
    "      timeline.write( \"%s, %s\"%(det,type))\n",
    "      for year in Years:\n",
    "          Inputs[det][type][year] = float(config[det][type][year-Years[0]])\n",
    "          timeline.write(\", %f\"%Inputs[det][type][year])\n",
    "      timeline.write(\"\\n\")\n",
    "      if DEBUG: print (\"old\", det,type,Inputs[det][type])\n",
    "        \n",
    "\n",
    "timeline.close() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2550cc",
   "metadata": {},
   "source": [
    "# Read in from file instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394fba1b-be36-4af3-aea6-a1415555dc97",
   "metadata": {},
   "source": [
    "<!-- if \"Timeline\" in config:\n",
    "    print (\"Timeline from \", config[\"Timeline\"])\n",
    "    if not os.path.exists(config[\"Timeline\"]):\n",
    "        print (\"timeline file \", config[\"Timeline\"],\" does not exist:\")\n",
    "        \n",
    "    \n",
    "    Inputs = {}\n",
    "    counter = 0 \n",
    "    with open(config[\"Timeline\"], newline='') as csvfile:\n",
    "        data = reader(csvfile)\n",
    "        for row in data:\n",
    "            if counter == 0: \n",
    "                counter = 1\n",
    "                continue\n",
    "            if DEBUG: print (row)\n",
    "            det = row[0].strip()\n",
    "            if det not in Inputs: \n",
    "                Inputs[det]={}\n",
    "            type = row[1].strip()\n",
    "            if type not in  Inputs[det]:\n",
    "                Inputs[det][type]={}\n",
    "            for year in Years:\n",
    "                \n",
    "                #print (\"test\",row[year - Years[0]+2])\n",
    "                Inputs[det][type][year] = float(row[year - Years[0]+2])\n",
    "            if DEBUG: print (\"new\",det,type,Inputs[det][type])\n",
    "            # print (list(Inputs[det].keys()))\n",
    "    csvfile.close()\n",
    "            \n",
    "# for det in Inputs:\n",
    "#     print (list(Inputs[det].keys()))   -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20dc56a-68be-4281-b349-c76e98cceccd",
   "metadata": {},
   "source": [
    "# Make the data holder and fill from Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c561d928-e9b3-4331-bd1d-609507168549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detectors ['SP', 'PDHD', 'DP', 'PDVD', 'HD', 'VD', 'ND-SAND', 'ND-LAr+TMS']\n",
      "Timeline from  NearTerm_2024-02-05-2040_timeline.csv\n"
     ]
    }
   ],
   "source": [
    "holder = DataHolder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73275f78-1922-4359-8e2d-5c58f9d8df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SP', 'PDHD', 'DP', 'PDVD', 'HD', 'VD', 'ND-SAND', 'ND-LAr+TMS']\n",
      "['Events', 'Sim-Events', 'TP', 'Sim', 'Reco-Data', 'Test', 'Analysis']\n",
      "['Tape', 'Disk', 'GPU', 'CPU', 'dummy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (Detectors)\n",
    "print (DataTypes)\n",
    "print (Resources)\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bccf3-b870-4943-bad3-59801896a8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10d1263b-666f-4e10-a701-4fdf4447d7ac",
   "metadata": {},
   "source": [
    "# Take the raw # of events/year and store them.  Test/TP are in TB alread so need no scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f627593f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mUnits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresource\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     14\u001b[0m     factor \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     15\u001b[0m newtag \u001b[38;5;241m=\u001b[39m holder\u001b[38;5;241m.\u001b[39mscale(detector,datatype,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m,location,{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResources\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m\"\u001b[39m},factor)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Store'"
     ]
    }
   ],
   "source": [
    "# store the raw data\n",
    "\n",
    "for detector in Detectors:\n",
    "    for datatype in [\"Events\",\"TP\",\"Test\"]:\n",
    "        for resource in [\"Store\"]:\n",
    "            for location in [\"ALL\"]:\n",
    "                if holder.hasTag(detector,datatype,\"dummy\",location):\n",
    "                    if DEBUG: holder.printByTag(holder.tag(detector,datatype,\"dummy\",location))\n",
    "                    if datatype == \"Events\":\n",
    "                        factor = config[detector][\"Raw-Store\"]\n",
    "                    else:\n",
    "                        factor = 1.0\n",
    "                    if Units[resource] == \"PB\":\n",
    "                        factor *= 0.001\n",
    "                    newtag = holder.scale(detector,datatype,\"dummy\",location,{\"Resources\":\"Store\"},factor)\n",
    "                    if DEBUG: holder.printByTag(newtag)\n",
    "                else:\n",
    "                    print (\"could not find\", detector,datatype,resource,location)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e6647-0e12-4d71-b1c4-1b361b4fa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the processing and store the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6dcdf9-088c-47ea-9507-f8b65d9dd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  makereco ------------------\") \n",
    "for detector in Detectors:\n",
    "    \n",
    "    # here you need to code reconstruction effects on all resources. \n",
    "\n",
    "    for datatype in [\"Reco-Data\",\"Sim\"]:\n",
    "        if datatype == \"Reco-Data\":\n",
    "            input = \"Events\"\n",
    "        if datatype == \"Reco-Sim\":\n",
    "            input = \"Sim-Events\"\n",
    "        # Reco gets reprocessed so has a special cumulation\n",
    "        for resource in [\"CPU\",\"GPU\",\"Store\"]:\n",
    "            for location in [\"ALL\"]:\n",
    "                if holder.hasTag(detector,input,\"dummy\",location):\n",
    "                    if DEBUG: holder.printByTag(holder.tag(detector,input,\"dummy\",location))                 \n",
    "                    factor = config[detector][datatype+\"-\"+resource]\n",
    "                    if datatype == \"Reco-Data\":  # first extend reprocessing then scale for CPU time\n",
    "                        period = Reprocess[detector]\n",
    "                        factor = config[detector][\"Reco-Data-\"+resource]\n",
    "                        newtag = holder.cumulateMe(detector,input,\"dummy\",location,{\"Resources\":resource,\"DataTypes\":\"Temp\"},period)\n",
    "                        newtag = holder.scale(detector,\"Temp\",resource,location,{\"Resources\":resource,\"DataTypes\":datatype},factor)\n",
    "                    else:\n",
    "                        factor = config[detector][\"Sim-\"+resource]\n",
    "                        newtag = holder.scale(detector,input,\"dummy\",location,{\"Resources\":resource,\"DataTypes\":datatype},factor)\n",
    "                    # extend Recodata. \n",
    "                    if Units[resource] == \"PB\":  # change to PB as a unit\n",
    "                        factor *= 0.001\n",
    "                    if DEBUG: holder.printByTag(newtag)\n",
    "                    if DEBUG:\n",
    "                        print (\"Try to extend\", detector,datatype,resource,location)\n",
    "                    if datatype in [\"Reco-Data\",\"Sim\"]:\n",
    "                        newtag = holder.extendMe(detector,datatype,resource,location,{\"DataTypes\":datatype},AnalysisExtend)\n",
    "                    if DEBUG: holder.printByTag(newtag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed60868-3ac1-4f8a-bbf4-8b2122b66294",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open(\"dump.json\",'w')\n",
    "json.dump(holder.holder,d,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7ac59-bfc7-4af9-a183-270101580db1",
   "metadata": {},
   "source": [
    "<!-- # fill in other useful arrays\n",
    "for det in Detectors:\n",
    "    if DEBUG:print (\"types\",det,list(Inputs[det].keys()))\n",
    "    #print (\"see it\", det,Inputs[det].keys())\n",
    "    \n",
    "    \n",
    "    for key in DetectorParameters:\n",
    "        #print(key,det)\n",
    "        # skip the ones already done\n",
    "        if key in dofirst:\n",
    "          continue\n",
    "        \n",
    "        # sim has its own configuration\n",
    "        # print (\"this is the key\",det,key)\n",
    "        if key == \"Reco-Data-CPU\" and DEBUG:\n",
    "            if DEBUG: print (\"reco events\",det,Inputs[det][\"Events\"])\n",
    "        if key in [\"Reco-Data-CPU\",\"Reco-Data-GPU\",\"Reco-Data-Store\"]:  # if doing reco, do over previous events using memory\n",
    "            Inputs[det][key] = cumulateMap(Years,Inputs[det][\"Events\"],Reprocess[det])\n",
    "            for year in Years:\n",
    "                Inputs[det][key][year] *= config[det][key]\n",
    "                \n",
    "#             if key == \"Reco-Data-Store\":\n",
    "#                 print (\"extend reco data\",det,key,AnalysisExtend)\n",
    "#                 Inputs[det][key] = extendMap(Years,Inputs[det][key],AnalysisExtend,key)\n",
    "            \n",
    "            if key == \"Reco-Data-CPU\" and MWCWeight:\n",
    "                if DEBUG: print (\"fix the memory\",config[det][\"Reco-Memory\"]/BaseMemory)\n",
    "                for year in Years:\n",
    "                    Inputs[det][key][year] *= (config[det][\"Reco-Memory\"]/BaseMemory)\n",
    "                if DEBUG: print (\"reco-data-cpu\",det, Inputs[det][key])\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        if key == \"Raw-Store\":\n",
    "            Inputs[det][key] ={}\n",
    "            if DEBUG:print (det,key)\n",
    "            for year in Years:\n",
    "                \n",
    "                if DEBUG:print (year,float(Inputs[det][\"Events\"][year]),(config[det][key]))\n",
    "                \n",
    "                Inputs[det][key][year] = float(Inputs[det][\"Events\"][year])*config[det][key]\n",
    "            continue\n",
    "            \n",
    "        if key in [\"Sim-Store\",\"Sim-CPU\",\"Sim-GPU\"]:\n",
    "            \n",
    "            Inputs[det][key] ={}\n",
    "            for year in Years:\n",
    "                Inputs[det][key][year]=Inputs[det][\"Sim-Events\"][year]*config[det][key]\n",
    "                if key == \"Sim-CPU\" and MWCWeight:\n",
    "                    Inputs[det][key][year]*=(config[det][\"Sim-Memory\"]/BaseMemory)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "#             if key == \"Sim-Store\":\n",
    "#                 #print (\"got here\", key)\n",
    "#                 Inputs[det][key] = extendMap(Years,Inputs[det][key],AnalysisExtend,key)\n",
    "#             continue\n",
    "            \n",
    "        \n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9c281-6c3a-42bc-a1ba-d53ea9312636",
   "metadata": {},
   "source": [
    "# now figure out analysis which is MC + Data x some factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680be57-db44-4fbf-85ad-394d525bd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457344e-6b13-482b-8404-33e165046ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"Analysis\"\n",
    "for detector in Detectors:\n",
    "    for resource in [\"CPU\",\"GPU\"]:\n",
    "        for location in [\"ALL\"]:\n",
    "            datatag = holder.tag(detector,\"Reco-Data\",resource,location)\n",
    "            mctag = holder.tag(detector,\"Sim\",resource,location)\n",
    "            analysistag = holder.tag(detector,\"Temp\",resource,location)\n",
    "            tmptag = holder.combineByTag([datatag,mctag],analysistag)\n",
    "            newtag = holder.scaleByTag(tmptag,{\"DataTypes\":datatype},config[detector][\"Analysis-CPU\"])\n",
    "            holder.removeTag(tmptag)  # cleanup\n",
    "            if DEBUG: holder.printByTag(newtag)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c16a70-11fa-4b9f-bcf4-d1058eba96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "            \n",
    "#          # right now this uses MWC - may be ok as reading in big stuff uses memory\n",
    "            \n",
    "#         if key in [\"Analysis-CPU\"]:  # keep analyzing for a few years. \n",
    "#             data = {}\n",
    "#             mc = {}\n",
    "#             Inputs[det][\"Analysis-CPU\"] = {}\n",
    "#             data  = extendMap(Years,Inputs[det][\"Reco-Data-CPU\"],AnalysisExtend)\n",
    "#             if DEBUG: print (\"data\",data)\n",
    "#             mc = extendMap(Years,Inputs[det][\"Sim-CPU\"],AnalysisExtend)\n",
    "#             if DEBUG: print (\"mc\",mc)\n",
    "#             for year in Years:\n",
    "#                 total = data[year]\n",
    "#                 total += mc[year]\n",
    "#                 Inputs[det][key][year] = total *config[det][\"Analysis-CPU\"]  # this scales by a factor relative to reco/sim-MWC\n",
    "           \n",
    "#         if DEBUG: print (\"other key\",det,key)\n",
    "\n",
    "\n",
    "# # do a little cleanup\n",
    "\n",
    "# for det in Inputs.keys():\n",
    "    \n",
    "#     if \"Sim-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Sim-Memory\")\n",
    "#     if \"Reco-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Reco-Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63faaff-2d47-4a22-a35e-dbe643ea5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6c42b-5d90-4abb-b1bf-d84dd3874706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data file which uses # of events to figure out how big samples are\n",
    "\n",
    "if PerYear[\"Reco-Data-Store\"]!=PerYear[\"Reco-Data-CPU\"]:\n",
    "    print (\"Data growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Data-Store\"] = PerYear[\"Reco-Data-CPU\"]\n",
    "if PerYear[\"Sim-Store\"]!=PerYear[\"Sim-CPU\"]:\n",
    "    print (\"Sim growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Sim-Store\"] = PerYear[\"Sim-CPU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54d977-7f7e-478d-833a-752ce316b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = {}\n",
    "# dump = open(\"dump.txt\",'w')\n",
    "\n",
    "    \n",
    "# #print (Inputs.keys())\n",
    "# fields = list(Inputs[\"ND-SAND\"].keys())\n",
    "# print (\"fields\",fields)\n",
    "# for dtype in fields:\n",
    "#   Data[dtype] = {}\n",
    "#   if \"Memory\" in dtype:\n",
    "#         continue\n",
    "#   for det in Inputs.keys():\n",
    "#     Data[dtype][det] = {}\n",
    "#     # this allows you to, say, do 2 passes of reco/year\n",
    "    \n",
    "#     # print(\"makeData\",dtype, det, Inputs[det][dtype][year])\n",
    "#     for year in Years:\n",
    "#         Data[dtype][det][year] = float(Inputs[det][dtype][year]) * float(PerYear[dtype])\n",
    "#     # compensate for nominal units being millions and TB or singles and MB\n",
    "#     if Units[dtype] == \"PB\":\n",
    "#         for year in Years:\n",
    "#             Data[dtype][det][year] *= 0.001\n",
    "#     ds = \"data %s %s %f\\n\"%(dtype,det,Data[dtype][det][2022])\n",
    "#     dump.write(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9bccc",
   "metadata": {},
   "source": [
    "- impose a cap at Cap (30 PB/year if set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3526a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impose a cap at Cap on things derived from raw data\n",
    "\n",
    "dtype = \"Raw-Store\"\n",
    "\n",
    "Data[\"Raw-Store\"][\"Total\"] = {}\n",
    "for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "for det in Inputs.keys():\n",
    "\n",
    "    for year in Years:\n",
    "        \n",
    "        Data[dtype][\"Total\"][year] +=  Data[\"Raw-Store\"][det][year]\n",
    "        \n",
    "dtypes = [\"Raw-Store\"] #,\"Reco-Data-CPU\"]\n",
    "for dtype in dtypes:\n",
    "    for det in Inputs.keys():\n",
    "        #print (dtype,det,2035,1.0,Data[dtype][det][2035] )\n",
    "        for year in Years:\n",
    "            cap = Data[\"Raw-Store\"][\"Total\"][year]/Cap\n",
    "           # print (dtype,det,year,cap,Data[dtype][det][year] )\n",
    "            if cap > 1:\n",
    "                Data[dtype][det][year] /=cap\n",
    "        #print (dtype,det,2035,cap,Data[dtype][det][2035] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f092b",
   "metadata": {},
   "source": [
    "# Make a total across detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5652be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dtypes = [\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]\n",
    "\n",
    "\n",
    "\n",
    "for dtype in dtypes:\n",
    "    Data[dtype][\"Total\"] ={}\n",
    "    \n",
    "        \n",
    "    for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "    for det in Inputs.keys():\n",
    "        #if dtype != \"Analysis\":  # not certain what this does... I think it is leftover. \n",
    "        for year in Years:\n",
    "               Data[dtype][\"Total\"][year]+=  Data[dtype][det][year] \n",
    "    \n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aff17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\",\"Reco-Data-GPU\",\"Sim-GPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "ToCSV2(shortname+\"-Reco-Data-GPU\",\"Reco-Data-GPU\",PlotYears,Data,Units,Formats)\n",
    "ToCSV2(shortname+\"-Sim-GPU\",\"Sim-GPU\",PlotYears,Data,Units,Formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "print (Inputs.keys())\n",
    "other = list(Inputs[\"ND-SAND\"].keys())+[\"Total\"]\n",
    "\n",
    "print (other)\n",
    "\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749ce21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebeb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe9323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge protodune info\n",
    "\n",
    "if DEBUG: print (\"Data keys\",Data.keys())\n",
    "\n",
    "for dtype in Data.keys():\n",
    "    if DEBUG: print (\"Merge protodunes\",dtype)\n",
    "    det = \"PDs\" \n",
    "    Data[dtype][det] = {}\n",
    "    for year in Years:  \n",
    "        Data[dtype][det][year] = Data[dtype][\"SP\"][year] + Data[dtype][\"DP\"][year] + Data[dtype][\"PDHD\"][year] + Data[dtype][\"PDVD\"][year]\n",
    "\n",
    "    Data[dtype].pop(\"SP\")\n",
    "    Data[dtype].pop(\"PDHD\")\n",
    "    Data[dtype].pop(\"DP\")\n",
    "    Data[dtype].pop(\"PDVD\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge far detector into \"FDs\n",
    "if \"HD\" in Detectors and \"VD\" in Detectors:\n",
    "    for dtype in Data.keys():\n",
    "        det = \"FDs\"\n",
    "        print (\"merge FDS\",dtype)\n",
    "        Data[dtype][det] =  {}\n",
    "        for year in Years:  \n",
    "            Data[dtype][det][year] = Data[dtype][\"HD\"][year] + Data[dtype][\"VD\"][year]\n",
    "        Data[dtype].pop(\"HD\")\n",
    "        Data[dtype].pop(\"VD\")\n",
    "        \n",
    "# for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         Data[dtype][det] =  {}\n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] = 0\n",
    "        \n",
    "# for subdet in [\"Calib\",\"HighE\",\"LowE\",\"LBL\",\"Calib\",\"TP\"]:\n",
    "#     for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         print (\"merge FDS\",dtype)\n",
    "        \n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] += Data[dtype][subdet][year] \n",
    "#         Data[dtype].pop(\"subdet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a total CPU category\n",
    "\n",
    "Data[\"Total-CPU\"]={}\n",
    "\n",
    "for det in CombinedDetectors:\n",
    "    Data[\"Total-CPU\"][det] =  {}\n",
    "    for year in Years:\n",
    "        Data[\"Total-CPU\"][det][year] = Data[\"Reco-Data-CPU\"][det][year] + Data[\"Sim-CPU\"][det][year] + Data[\"Analysis-CPU\"][det][year]\n",
    "    #print(det,Data[\"Total-CPU\"][det])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make totals across categories. \n",
    "\n",
    "DataTypes = list(Data.keys())\n",
    "\n",
    "for dt in DataTypes:\n",
    "    Data[dt][\"Total\"] = {}\n",
    "    for year in Years:\n",
    "        Data[dt][\"Total\"][year]=0.0\n",
    "    for k in Data[dt].keys():\n",
    "        if k == \"Total\":\n",
    "          continue  \n",
    "        for year in Years:\n",
    "            Data[dt][\"Total\"][year] += Data[dt][k][year]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c793c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and make a special data type for cores\n",
    "\n",
    "Data[\"Cores\"] = {}\n",
    "Data[\"HS23\"] = {}\n",
    "Data[\"Wall\"] = {}\n",
    " \n",
    "MHrsPerYear = 1000000/365./24.\n",
    "print (\"MHrsPerYear\",MHrsPerYear)\n",
    "print (\"total-CPU keys\",Data[\"Total-CPU\"].keys())\n",
    "for k in Data[\"Total-CPU\"].keys():\n",
    "#     if \"MARS\" not in k :\n",
    "#         efficiency = config[\"Cores\"][\"Efficiency\"]\n",
    "#     else:\n",
    "#         efficiency = 1\n",
    "\n",
    "    scaleTo2020 = config[\"Cores\"][\"2020Units\"]\n",
    "    Data[\"Cores\"][k]={}\n",
    "    Data[\"Wall\"][k]={}\n",
    "    Data[\"HS23\"][k]={}\n",
    "#    Data[\"WALL\"][k]={}\n",
    "    for year in Years:\n",
    "        Data[\"Wall\"][k][year] = Data[\"Total-CPU\"][k][year]/scaleTo2020/efficiency\n",
    "        Data[\"Cores\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency\n",
    "        Data[\"HS23\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency*config[\"kHEPSPEC06PerCPU\"]\n",
    "#        Data[\"WALL\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/efficiency/scaleTo2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3de67",
   "metadata": {},
   "source": [
    "# Yearly info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6244923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"] \n",
    "DrawDet(shortname+\"_byyear\",\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines)#,cpuactual)\n",
    "DrawDet(shortname+\"_byyear\",\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines)#,coreactual)\n",
    "DrawDet(shortname+\"_byyear\",\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "DrawDet(shortname+\"_byyear\",\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for Storage work out split between different institutions\n",
    "\n",
    "Splits = {}\n",
    "for f in SplitsEarly:\n",
    "    Splits[f] = {}\n",
    "    for t in SplitsEarly[f]:\n",
    "        Splits[f][t] = {}\n",
    "        for loc in SplitsEarly[f][t]: \n",
    "            Splits[f][t][loc] = {}\n",
    "            #print (f,t,Splits[f][t],Splits[f][t][0])\n",
    "    \n",
    "            for y in Years:\n",
    "                if y < SplitsYear:\n",
    "                    Splits[f][t][loc][y]=SplitsEarly[f][t][loc]\n",
    "                else:\n",
    "                    Splits[f][t][loc][y]=SplitsLater[f][t][loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb06ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG: print (Splits[\"CPU\"])\n",
    "\n",
    "for key in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]: \n",
    "    \n",
    "    for site in [\"FNAL\",\"CERN\",\"Global\"]:\n",
    "        Data[key][site] = {}\n",
    "        for year in Years:\n",
    "            \n",
    "            Data[key][site][year] = Data[key][\"Total\"][year]*Splits[\"CPU\"][\"CPU\"][site][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc0ed4",
   "metadata": {},
   "source": [
    "# here is where we start doing cumulation across years for disk and reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do some Cumulative-work.  Stuff stays on tape/disk for different amounts of time and we have multiple copies\n",
    "\n",
    "Storage = {}\n",
    "for k in StorageTypes:\n",
    "    Storage[k] = {}\n",
    "Storage[\"Total\"] = {}\n",
    "Storage[\"Global\"] = {}\n",
    "Storage[\"FNAL\"] = {}\n",
    "Storage[\"CERN\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Disk\"] = {}\n",
    "\n",
    "\n",
    "for year in Years:\n",
    "    Storage[\"Total\"][\"Cumulative-Tape\"][year] = 0.0\n",
    "    Storage[\"Total\"][\"Cumulative-Disk\"][year] = 0.0\n",
    "\n",
    "for k in StorageTypes:\n",
    "    Storage[k][\"Tape\"] = {}\n",
    "    Storage[k][\"Disk\"] = {}\n",
    "    for year in Years:\n",
    "        Storage[k][\"Tape\"][year] = Data[k][\"Total\"][year]*TapeCopies[k]\n",
    "        Storage[k][\"Disk\"][year] = Data[k][\"Total\"][year]*DiskCopies[k]\n",
    "    # extend disk for Analysis HMS 6-24-2023\n",
    "    #Storage[k][\"Disk\"]  = extendMap(Years,Storage[k][\"Disk\"],AnalysisExtend) \n",
    "    \n",
    "    Storage[k][\"Cumulative-Tape\"] = cumulateMap(Years,Storage[k][\"Tape\"],TapeLifetimes[k])\n",
    "    Extend = cumulateMap(Years,Storage[k][\"Disk\"],DiskLifetimes[k])\n",
    "    if k != \"Test\": \n",
    "        Storage[k][\"Cumulative-Disk\"] = extendMap(Years,Extend,AnalysisExtend,k)\n",
    "    else:\n",
    "        Storage[k][\"Cumulative-Disk\"] = Extend\n",
    "    \n",
    "    for year in Years:\n",
    "        Storage[\"Total\"][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]\n",
    "        Storage[\"Total\"][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]\n",
    "    \n",
    "    \n",
    "        \n",
    "for loc in Splits[\"Disk\"][\"Raw-Store\"]:\n",
    "    for year in Years:\n",
    "        Storage[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "        Storage[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "        for k in StorageTypes:\n",
    "              Storage[loc][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]*Splits[\"Disk\"][k][loc][year]\n",
    "              Storage[loc][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]*Splits[\"Tape\"][k][loc][year]\n",
    "\n",
    "\n",
    "# cdisk = SumOver1(\"Cumulative-Disk\",Data)\n",
    "# print (\"sum over\",cdisk)\n",
    "\n",
    "# for year in Years:\n",
    "#         Data[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "#         Data[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "#         for k in StorageTypes:\n",
    "#               Data[loc][\"Cumulative-Disk\"][year] += Data[k][\"Cumulative-Disk\"][year] \n",
    "#               Data[loc][\"Cumulative-Tape\"][year] += Data[k][\"Cumulative-Tape\"][year] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texfile.write(\"\\\\section{Projected Disk and Tape needs by source and site}\\n\")\n",
    "#ToCSV1(shortname+\"-Disk_by_location\",\"Cumulative-Disk\",PlotYears,Storage,Units,Formats)\n",
    "#ToCSV1(shortname+\"-Tape_by_location\",\"Cumulative-Tape\",PlotYears,Storage,Units,Formats)\n",
    "# s = \"\\\\begin{table}[h]\\n \\\\centering\\\\csvautotabularright\\\n",
    "# {external/DUNERSEUSAGE-2022-11-14.csv}\\n \\\\label{Cumulative-Tape}\\n\\\n",
    "# \\\\caption{Rucio report on storage usage 2022-11-14 from the Scotgrid Dashboard \\\n",
    "# \\\\href{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}.}\\n \\\\end{table}\\n\"\n",
    "# s.replace(\"_\",\"\\_\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# s = TableTex(shortname+\"-Disk_by_location\",\"Disk requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Disk\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "# s = TableTex(shortname+\"-Tape_by_location\",\"Tape requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Tape\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# texfile.write(\"\\\\clearpage\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77df874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do some plots\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"]\n",
    "\n",
    "cpuactual = []\n",
    "coreactual = []\n",
    "wallactual = []\n",
    "\n",
    "Sites = [\"FNAL\",\"CERN\",\"Global\",\"Total\"]\n",
    "\n",
    "\n",
    "DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines,cpuactual)\n",
    "DrawDet(shortname,\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines,coreactual)\n",
    "DrawDet(shortname,\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "DrawDet(shortname,\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "# DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Sites,Units,DetColors,DetLines,cpuactual)\n",
    "# DrawDet(shortname,\"Cores\",PlotYears,Data,Sites,Units,DetColors,DetLines,coreactual)\n",
    "# #DrawDet(shortname,\"WALL\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "# DrawDet(shortname,\"HS23\",PlotYears,Data,Sites,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "for x in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]:\n",
    "    ToCSV2(shortname+\"-\"+x,x,PlotYears,Data,Units,Formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed88eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "Captions2 = {\"Events\":\"Projected million of detector events per year.  Reconstructed data resources are based on this number.\",\n",
    "\"Test\":\"Projected PB of Test data per year.\",\n",
    "\"Sim-Events\":\"Projected millions of simulated events per year. Simulated data resources are based on this number. \",\n",
    "\"Raw-Store\":\"Projected raw data written per year in PB, derived from the number of events.\",\n",
    "\"Reco-Data-CPU\":\"Projected CPU needs in core-hrs for data reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction.  Assumes rereconstruction of several years of older data.\",\n",
    "\"Sim-CPU\":\"Projected CPU needs in core-hrs for simulation and reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction. Based directly on the number of simulated Events.\",\n",
    "\"Reco-Data-Store\":\"Projected PB of reconstructed data per year. Includes reprocessing.\",\n",
    "\"Sim-Store\":\"Projected PB of simulated data/year\",\n",
    "\"Total-CPU\":\"Slot weighted CPU needs in core-years. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Cores\":\"Slot weighted CPU needs in number of cores. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"HS23\":\"Slot weighted CPU needs in kHS23 hrs. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Analysis-CPU\":\"Slot weighted analysis CPU needs in core-hrs. Assumed to be a weighted fraction of reco+sim needs.\",\n",
    "            }\n",
    "print (Data[\"Events\"][\"PDs\"])\n",
    "#print (Data[\"Events\"][\"FDs\"])\n",
    "print (Data[\"Events\"][\"ND-SAND\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3217fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for key in [\"Cores\",\"Total-CPU\",\"HS23\"]:\n",
    "#     print (\"Got to Here\")\n",
    "#     if not key in Units:\n",
    "#         print (\"no units for key\",key)\n",
    "#         continue\n",
    "#     ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "#     s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "#     #DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "#     #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     print  (\"Got to here\")\n",
    "#     s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     #texfile.write(s2)\n",
    "#     tablefile.write(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Storage.keys())\n",
    "    \n",
    "Captions1 = {\"Cumulative-Tape\":\"Cumulative Tape needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\", \n",
    "             \"Cumulative-Disk\":\"Cumulative Disk needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\",\n",
    "            \"HS23\":\"CPU needs in HS23 units\"}\n",
    "            \n",
    "\n",
    "for key in ['Cumulative-Tape', 'Cumulative-Disk']:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    # actual = None\n",
    "    # if key == \"Cumulative-Tape\":\n",
    "    #     actual = tapeactual\n",
    "    # if key == \"Cumulative-Disk\":\n",
    "    #     actual = diskactual\n",
    "    # print (actual)\n",
    "    ToCSV1(shortname+\"-\"+key,key,PlotYears,Storage,Units,Formats)\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Source\",key,PlotYears,Storage,Units,Formats,['Raw-Store', 'Test', 'Reco-Data-Store', 'Sim-Store', 'Total'])\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Request\",key,PlotYears,Storage,Units,Formats,['Global', 'FNAL', 'CERN', 'Total'])\n",
    "    s = TableTex(shortname+\"-\"+key,Captions1[key],key+\"\\n\")\n",
    "    print (key,s)\n",
    "    dunestyle.Preliminary()\n",
    "    DrawType(shortname,key,PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    " \n",
    "    s2 = BothTex(shortname,key+\".png\",Captions1[key],key)\n",
    "\n",
    "    #texfile.write(s2)\n",
    "    texfile.write(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Types)\n",
    "\n",
    "for key in Types:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "\n",
    "for key in Sites:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tapepoints = np.zeros(len(Years))\n",
    "diskpoints = np.zeros(len(Years))\n",
    "\n",
    "#DrawType(shortname,\"Tape\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Tape\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce17be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefile.close()\n",
    "#texfile.write(\"\\\\input{bibmaker.tex}\\n\")\n",
    "#texfile.write(\"\\\\clearpage\\n\")\n",
    "#texfile.write(\"\\\\section{Appendix - Model inputs}\\n\")\n",
    "#texfile.write(\"\\\\input{\"+dirname+\"/tables.tex}\\n\")\n",
    "#texfile.write(\"\\\\end{document}\\n\")\n",
    "texfile.close()\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a set of request numbers to add to the tex file - they need to have tex compatible nicknames\n",
    "\n",
    "macro = open(shortname+\"_macros.tex\",'w')\n",
    "\n",
    "command = makeParameter(\"HS23Request\",\"%10.0f\"%(Data[\"HS23\"][\"Total\"][RequestYear]))\n",
    "print (\"tex command\", command,Data[\"HS23\"][\"Total\"][RequestYear])\n",
    "\n",
    "Requests = {}\n",
    "Requests[\"CPU\"]=\"HS23\"\n",
    "Requests[\"CORES\"]=\"Cores\"\n",
    "\n",
    "Requests[\"DISK\"]=\"Cumulative-Disk\"\n",
    "Requests[\"TAPE\"]=\"Cumulative-Tape\"\n",
    "\n",
    "m = makeParameter(\"ThisYear\",\"%d\"%RequestYear)\n",
    "macro.write(m+\"\\n\")\n",
    "\n",
    "for y in Requests:\n",
    "    for x in Sites:\n",
    "        name = (\"%s%s\"%(y,x)).replace(\"-\",\"\")\n",
    "        if y == \"CPU\" or y == \"CORES\":\n",
    "            if y == \"CPU\": \n",
    "                m = makeParameter(name,\"%10.1f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "            else: \n",
    "                m = makeParameter(name,\"%10.0f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "        else:\n",
    "            m = makeParameter(name,\"%10.1f\"%(Storage[x][Requests[y]][RequestYear]))\n",
    "        macro.write(m+\"\\n\")\n",
    "macro.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd921d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jname = configfilename.replace(\".json\",\"_internal.json\")\n",
    "jj = open(jname,'w')\n",
    "commentjson.dump(Data,jj,indent=4)\n",
    "jj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmd='pdflatex MoreSim_2023-06-22-2040.tex'\n",
    "#get_ipython().system('{cmd}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
