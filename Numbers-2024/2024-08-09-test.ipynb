{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61957124-7283-4238-8c04-84c8c2be685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(sys.executable)\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0fd7b",
   "metadata": {},
   "source": [
    "\n",
    "Code to generate yearly summaries of DUNE data volumes from input parameters\n",
    "\n",
    "rewritten from the version in the CDR - mainly by using maps of years instead of arrays to make it clearer what is in each year.\n",
    "\n",
    "HMS 2022-10-23\n",
    "\n",
    "If you have json problems, run the program ../strip.py on your file to take off comments and then test using https://jsonlint.com\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481973c9-a71e-4064-a7e2-9f736e67ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DRAW = True\n",
    "import os,commentjson\n",
    "from csv import reader\n",
    "import json\n",
    "import numpy as np\n",
    "import dunestyle.matplotlib as dunestyle\n",
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import cumulateMap\n",
    "from NumberUtils import DrawDet\n",
    "from NumberUtils import DrawType\n",
    "from NumberUtils import makeArray\n",
    "from NumberUtils import ToCSV1\n",
    "from NumberUtils import ToCSV2\n",
    "#from NumberUtils import SumOver1\n",
    "#from NumberUtils import SumOver2\n",
    "from NumberUtils import TableTex\n",
    "from NumberUtils import BothTex\n",
    "from NumberUtils import extendMap\n",
    "from NumberUtils import makeParameter\n",
    "from DataHolder import DataHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c3326-7195-446a-8ca5-a432412c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many histograms to draw in multi-hist plots\n",
    "N_HISTS = 8   # exhibits all the colors in the Okabe-Ito cycler\n",
    "\n",
    "# specify the json file here.  Will create a subdirectory for plots with a similar name\n",
    "\n",
    "configfilename = \"NearTerm_2024-08-11-2040.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0efc9-6b66-4fcf-9725-b4a2bc229aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "theshortname = configfilename.replace(\".json\",\"\")\n",
    "if os.path.exists(configfilename):\n",
    "    with open(configfilename,'r') as f:\n",
    "        config = commentjson.load(f)\n",
    "        print (\"config file\",configfilename,\"found\")\n",
    "else:\n",
    "    print (\"no config file\",configfilename)\n",
    "    sys.exit(0)\n",
    "\n",
    "if not \"Version\" in config or config[\"Version\"] < 20:\n",
    "    print (\" this code expects Version >= 20\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32240021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MWCWeight = config[\"MWCWeight\"] # do we weight cores by available memory? \n",
    "MaxYear = config[\"MaxYear\"]\n",
    "MWCstring = \"_noMWC\"\n",
    "if MWCWeight: \n",
    "    print (\"MWC no longer enabled, ignore\")\n",
    "    MWCstring=\"\"\n",
    "config[\"filename\"] = configfilename\n",
    "TEST = config[\"Test\"]\n",
    "MinYear = config[\"MinYear\"]\n",
    "Detectors = config[\"Detectors\"]\n",
    "DataTypes = config[\"DataTypes\"]\n",
    "NativeTypes = config[\"NativeTypes\"]\n",
    "if TEST:\n",
    "    Detectors = config[\"TestDetectors\"]\n",
    "    DataTypes = config[\"TestTypes\"]\n",
    "    if \"TP\" not in DataTypes and \"TP\" in NativeTypes:\n",
    "        NativeTypes.remove(\"TP\")\n",
    "    \n",
    "Years = config[\"Years\"]\n",
    "\n",
    "shortname = theshortname.replace(\"2040\",\"%d\"%MaxYear)+MWCstring\n",
    "dirname = shortname\n",
    "if not os.path.exists(dirname):\n",
    "    os.mkdir(dirname)\n",
    "shortname = dirname+\"/\"+dirname\n",
    "# make a tex output file\n",
    "texfilename = dirname+\".tex\"\n",
    "texfile = open(texfilename,'w')\n",
    "tablefile = open(os.path.join(dirname,\"tables.tex\"),'w')\n",
    "#texfile.write(\"\\\\input{Header.tex}\\n\")\n",
    "\n",
    "size = len(Years)\n",
    "Units = config[\"Units\"]\n",
    "BaseUnits = config[\"BaseUnits\"]\n",
    "RequestYear=2024\n",
    "if \"RequestYear\" in config:\n",
    "    RequestYear= config[\"RequestYear\"]\n",
    "        \n",
    "Formats = config[\"Formats\"]\n",
    "Resources = config[\"Resources\"]\n",
    "Locations = config[\"Locations\"]\n",
    "PlotDetectors = Detectors+[\"Total\"]\n",
    "PlotDataTypes = DataTypes+[\"Total\"]\n",
    "PlotLocations = Locations+[\"Total\"]\n",
    "Scales = config[\"Scales\"]\n",
    "Cap = config[\"Cap\"]\n",
    "\n",
    "BaseMemory = config[\"Base-Memory\"]\n",
    "Splits= config[\"Splits\"]\n",
    "PDlist = config[\"PDlist\"]\n",
    "FDlist = config[\"FDlist\"]\n",
    "NDlist = config[\"NDlist\"]\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "print (\"Parameters\",DetectorParameters)\n",
    "\n",
    "if \"Comment\" in DetectorParameters:\n",
    "    DetectorParameters.remove(\"Comment\")\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "# this is how far you go back each time you reprocess reco.\n",
    "\n",
    "Reprocess = config[\"Reprocess\"]\n",
    "AnalysisExtend = config[\"AnalysisExtend\"]\n",
    "PerYear = config[\"PerYear\"]\n",
    "Slots = config[\"Slots\"]\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "#TypeColors=config[\"TypeColors\"]\n",
    "#TypeLines = config[\"TypeLines\"]\n",
    "\n",
    "#PatternFraction = config[\"PatternFraction\"]\n",
    "Explain = config[\"Explain\"]\n",
    "Explain[\"filename\"] = \"Input configuration file\"\n",
    "\n",
    "if DEBUG:\n",
    "    for i in config.keys():\n",
    "        if i not in Explain.keys():\n",
    "            print (\"Still need to explain\",i)\n",
    "\n",
    "for f in Explain.keys():\n",
    "    field = \"{\\\\tt %s:} %s = {\\\\tt %s} \\\\\\\\\\n\"%(f,Explain[f], config[f])\n",
    "    field = field.replace(\"_\",\"\\_\")\n",
    "    tablefile.write(field)\n",
    "    print (f, Explain[f], config[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97139b-4e67-4b07-8f8a-7e3af22bac46",
   "metadata": {},
   "source": [
    "## Make data container (holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b76549-5360-44f1-9230-a30bc041f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holder = DataHolder(theconfig=config,debug=DEBUG)\n",
    "holder.readTimeline()\n",
    "\n",
    "csvname = configfilename.replace(\".json\",\".csv\")\n",
    "csvData = holder.csvDump(dirname+\"/\"+csvname)\n",
    "\n",
    "holder.jsonDump(configfilename.replace(\".json\",\"safe.json\"))\n",
    "\n",
    "holder.debug=DEBUG\n",
    "\n",
    "if DEBUG: (\"Detector Parameters\",DetectorParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af1c79-65d5-445c-bcdb-f2ed18f2a7b2",
   "metadata": {},
   "source": [
    "# Change input (NativeTypes) into storage numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed3da6-f8c7-4754-a5ec-82736e78b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in other useful arrays\n",
    "\n",
    "holder.debug=DEBUG\n",
    "print (\"--------------- raw-storage ------------------\")\n",
    "print (\"NativeTypes\",NativeTypes)\n",
    "for detector in Detectors:\n",
    "    # first raw data events which have to be stored. \n",
    "    # Make \"input\" locations in to \"Store\" scaled by config[detector][type]\n",
    "    for olddatatype in config[\"NativeTypes\"]:\n",
    "        oldunits = Scales[olddatatype]\n",
    "        oldresource = \"input\"\n",
    "        newresource = \"Store\"\n",
    "        location = \"Total\"\n",
    "                 \n",
    "        if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "            if DEBUG: holder.printByTag(holder.tag(detector,olddatatype,oldresource,location,oldunits))\n",
    "            factor = 1\n",
    "            if olddatatype == \"Raw-Events\":\n",
    "                newdatatype = \"Raw-Data\"\n",
    "                factor = config[detector][\"Raw-Data-Store\"]\n",
    "                newunits = Scales[\"Raw-Data-Store\"]\n",
    "            else:\n",
    "                newdatatype = olddatatype\n",
    "                newunits = oldunits\n",
    "            # TP and Test are already in units of GB\n",
    "            if DEBUG: print (\"storage\",detector,olddatatype,newresource,location,newunits,factor)\n",
    "            newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":newdatatype,\"Resources\":newresource,\"Units\":newunits},factor)\n",
    "            if DEBUG: holder.printByTag(newtag)\n",
    "        else:\n",
    "            if DEBUG: print (\"could not find\", detector,olddatatype,oldresource,location,oldunits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "holder.debug = DEBUG\n",
    "\n",
    "holder.csvDump(dirname+\"/\"+\"after-raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ce56d-3ded-4778-978f-3ef2fef2b8cf",
   "metadata": {},
   "source": [
    "# calculate size of raw data coming from detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f688cf4-1b0d-4dce-9075-a80d5417bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complicated way of doing double sum  \n",
    "print (\"----------------------------- draw real data -----------------------\")\n",
    "RealDataTypes=[\"Raw-Data\",\"TP\",\"Test\"]\n",
    "\n",
    "realsubset={\"Detectors\":Detectors,\"DataTypes\":RealDataTypes,\"Resources\":\"Store\",\"Locations\":\"Total\"}\n",
    "\n",
    "realDataTotalDetector=holder.sumAcrossFilters(\n",
    "    filter=realsubset,sumCat=\"Detectors\",sumName=\"Sub-Total\")\n",
    "\n",
    "realsubset2={\"Detectors\":Detectors+[\"Sub-Total\"],\"DataTypes\":RealDataTypes,\"Resources\":\"Store\",\"Locations\":\"Total\"}\n",
    "\n",
    "realDataTotalDetectorStore=holder.sumAcrossFilters(\n",
    "    filter=realsubset2,sumCat=\"DataTypes\",sumName=\"Sub-Total\")\n",
    "    \n",
    "newsubset={\"Detectors\":([\"Sub-Total\"]),\"DataTypes\":RealDataTypes+[\"Sub-Total\"],\"Resources\":\"Store\",\"Locations\":\"Total\"}\n",
    "\n",
    "holder.Draw(dirname,Title=\"RealData\",YAxis=\"Storage\",Category=\"DataTypes\",filter=newsubset)\n",
    "            \n",
    "holder.csvDump(dirname+\"/\"+\"realData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53069e-15ad-48b5-9df7-68e07ff01dbd",
   "metadata": {},
   "source": [
    "# extend events for Reco and calculate storage/CPU/GPU per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f6f88-38c9-4de5-b4d6-8f635298b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  transform Events into CPU estimates  ------------------\") \n",
    "for detector in Detectors:\n",
    "    for newdatatype in [\"Reco-Data\",\"Reco-Sim\"]:\n",
    "        oldresource = \"input\"\n",
    "\n",
    "        if newdatatype == \"Reco-Data\": \n",
    "            olddatatype = \"Raw-Events\"\n",
    "\n",
    "        if newdatatype == \"Reco-Sim\":\n",
    "            olddatatype = \"Sim-Events\"\n",
    "\n",
    "        oldunits = Scales[olddatatype]\n",
    "        location = \"Total\"\n",
    "\n",
    "        # Reco gets reprocessed so has a special cumulation\n",
    "\n",
    "        for resource in [\"CPU\",\"GPU\",\"Store\"]:\n",
    "            newunits = Scales[newdatatype+\"-\"+resource]    \n",
    "            if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "                if DEBUG: holder.printByTag(holder.tag(detector,olddatatype,oldresource,location,oldunits))                 \n",
    "                if DEBUG: print (\"--before Events->Things\",olddatatype,resource)\n",
    "                newunits = Scales[newdatatype+\"-\"+resource]\n",
    "                factor = config[detector][newdatatype + \"-\" +resource]*PerYear[newdatatype+\"-\"+resource]\n",
    "                if DEBUG: print (\"factor\",detector,newdatatype,resource,factor)\n",
    "                thedatatype = newdatatype\n",
    "                newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":thedatatype,\"Resources\":resource,\"Units\":newunits},factor)\n",
    "                if DEBUG: holder.printByTag(newtag)\n",
    "                if DEBUG: print (\"--after Events->Things\",newdatatype,resource)\n",
    "\n",
    "                # special to say you redo previous Reprocess years of reco every year.\n",
    "                if thedatatype == \"Reco-Data\":  \n",
    "                    newtag = holder.cumulateMe(detector,newdatatype,resource,location,newunits,{\"DataTypes\":\"Reco-Data\"},Reprocess[detector]) \n",
    "                    \n",
    "                if DEBUG: holder.printByTag(newtag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ed50b",
   "metadata": {},
   "source": [
    "# calculate analysis based on scaling of data/sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bf389-a4d7-41db-87ea-22bdca06b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"---------------  make analysis ------------------\")\n",
    "for detector in Detectors:\n",
    "    for resource in [\"CPU\"]:   \n",
    "        location = \"Total\"\n",
    "        \n",
    "        recoAtag = holder.scale(detector,\"Reco-Data\",resource,location,Scales[\"Reco-Data-CPU\"],{\"DataTypes\":\"Analysis-Data\"},config[detector][\"Analysis-CPU\"]*PerYear[\"Analysis-CPU\"])\n",
    "        simAtag = holder.scale(detector,\"Reco-Sim\",resource,location,Scales[\"Reco-Sim-CPU\"],{\"DataTypes\":\"Analysis-Sim\"},config[detector][\"Analysis-CPU\"]*PerYear[\"Analysis-CPU\"])\n",
    "        if DEBUG: print (recoAtag)\n",
    "        # extend\n",
    "        # extend Analysis\n",
    "        recoAtag = holder.extendMe(detector,\"Analysis-Data\",resource,location,Scales[\"Reco-Data-CPU\"],{},AnalysisExtend)\n",
    "        simAtag = holder.extendMe(detector,\"Analysis-Sim\",resource,location,Scales[\"Reco-Sim-CPU\"],{},AnalysisExtend)\n",
    "        if DEBUG: print (\"make analysis:\",recoAtag,simAtag)\n",
    "\n",
    "holder.csvDump(\"after-analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  make different CPU units ------------------\")\n",
    "\n",
    "MHrsPerYear = 1000000./365/24.\n",
    "for detector in Detectors:\n",
    "    for datatype in DataTypes:\n",
    "        for oldresource in [\"CPU\",\"GPU\"]:\n",
    "            oldunits = \"MHr\"\n",
    "            location = \"Total\"\n",
    "        \n",
    "            for newunit in [\"Wall\",\"kHS23-Yr\",\"Cores\"]:\n",
    "                \n",
    "                newresource = oldresource + \" \" + newunit\n",
    "                factor = 1./Slots[\"Efficiency\"]/Slots[\"2020Units\"]\n",
    "                newunits = \"MHr\"\n",
    "                if newunit == \"kHS23-Yr\":\n",
    "                    factor *= config[\"kHEPSPEC06PerCPU\"]*MHrsPerYear\n",
    "                    newunits = \"kHS23-Yr\"\n",
    "                if newunit == \"Cores\":\n",
    "                    newunits = \"Cores\"\n",
    "                    factor *= MHrsPerYear\n",
    "                newtag = holder.scale(detector,datatype,oldresource,location,oldunits,{\"DataTypes\":datatype,\"Resources\":newresource,\"Units\":newunits},factor)\n",
    "                if newtag != None and DEBUG:\n",
    "                    print (newtag,holder.holder[newtag])\n",
    "                \n",
    "holder.csvDump(dirname+\"/\"+\"after-CPUscale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4badfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d75683",
   "metadata": {},
   "outputs": [],
   "source": [
    "holder.debug = DEBUG\n",
    "\n",
    "print(\"---------------------- sum across CPU ---------------------------------\")\n",
    "\n",
    "# filter on derived event types\n",
    "\n",
    "CPUTypes = [\"GPU\",\"CPU\",\"Total\",\"CPU Wall\",\"CPU kHS23-Yr\", \"CPU Cores\"] \n",
    "filter = {\"Detectors\":Detectors,\"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"],\"Resources\":CPUTypes,\"Locations\":[\"Total\"]}\n",
    "if DEBUG:\n",
    "    show = json.dumps(filter,indent=4)\n",
    "    print (show)\n",
    "\n",
    "CPUTotals=holder.sumAcrossFilters(filter=filter,sumCat=\"DataTypes\",sumName=\"Total\")\n",
    "\n",
    "filter2 = {\"Detectors\":Detectors,\"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"]+[\"Total\"],\"Resources\":CPUTypes,\"Locations\":[\"Total\"]}\n",
    "\n",
    "CPUTotalsAllDetectors=holder.sumAcrossFilters(filter=filter2, sumCat=\"Detectors\",sumName= \"Total\")\n",
    "print (\"DataTypes\",DataTypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8856cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make filters and then draw\n",
    "\n",
    "CPUByDetector = {\"Detectors\":Detectors+[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"CPU\"],\"Locations\":[\"Total\"]}\n",
    "CPUByType = {\"Detectors\":detector,\"DataTypes\":(DataTypes+[\"Total\"]),\"Resources\":[\"CPU\"],\"Locations\":[\"Total\"]}\n",
    "WallByDetector = {\"Detectors\":Detectors+[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"CPU Wall\"],\"Locations\":[\"Total\"]}\n",
    "WallByType = {\"Detectors\":detector,\"DataTypes\":(DataTypes+[\"Total\"]),\"Resources\":[\"CPU Wall\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "kHS23ByDetector = {\"Detectors\":Detectors+[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"CPU kHS23-Yr\"],\"Locations\":[\"Total\"]}\n",
    "kHS23ByType = {\"Detectors\":[\"Total\"],\"DataTypes\":(DataTypes+[\"Total\"]),\"Resources\":[\"CPU kHS23-Yr\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "CoresByDetector = {\"Detectors\":Detectors+[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"CPU Cores\"],\"Locations\":[\"Total\"]}\n",
    "CoresByType = {\"Detectors\":[\"Total\"],\"DataTypes\":(DataTypes+[\"Total\"]),\"Resources\":[\"CPU Cores\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "\n",
    "holder.storeFilter(filter=CPUByDetector,name=\"CPUByDetector\")\n",
    "holder.storeFilter(filter=CPUByType,name=\"CPUByType\")\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"CPU by Detector\",YAxis=\"CPU\",Category=\"Detectors\",filter=CPUByDetector)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"CPU by Type\",YAxis=\"CPU\",Category=\"DataTypes\",filter=CPUByType)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"Wall time by Detector\",YAxis=\"CPU\",Category=\"Detectors\",filter=WallByDetector)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"Wall time by Type\",YAxis=\"CPU\",Category=\"DataTypes\",filter=WallByType)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"kHS23-Yr by Detector\",YAxis=\"CPU\",Category=\"Detectors\",filter=kHS23ByDetector)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"kHS23-Yr by Type\",YAxis=\"CPU\",Category=\"DataTypes\",filter=kHS23ByType)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"Core-Yr by Detector\",YAxis=\"CPU\",Category=\"Detectors\",filter=CoresByDetector)\n",
    "\n",
    "holder.Draw(Dir=dirname,Title=\"Core-Yr by Type\",YAxis=\"CPU\",Category=\"DataTypes\",filter=CoresByType)\n",
    "\n",
    "\n",
    "holder.csvDump(dirname+\"/\"+\"after-total2.csv\")\n",
    "\n",
    "if DEBUG: print (json.dumps(filter2,indent=4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c17cf0",
   "metadata": {},
   "source": [
    "# make tape and disk and them cumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------- change Store into Disk and Tape ---------------------------------\")\n",
    "\n",
    "oldresource = \"Store\"\n",
    "for detector in Detectors:\n",
    "    for datatype in DataTypes:\n",
    "        if datatype in holder.nosum:\n",
    "            continue\n",
    "        if datatype in [\"Raw-Events\",\"Sim-Events\"]: continue\n",
    "        for newresource in [\"Disk\",\"Tape\"]:\n",
    "            for locations in [\"Total\"]:\n",
    "                if newresource == \"Disk\": \n",
    "                    factor = DiskCopies[datatype]\n",
    "                if newresource == \"Tape\": \n",
    "                    factor = TapeCopies[datatype]\n",
    "                newtag = holder.scale(detector= detector,datatype=datatype,resource=oldresource,location=locations,units=\"TB\",categories={\"Resources\":newresource},factor=factor)\n",
    "\n",
    "holder.csvDump(dirname+\"/\"+\"disk-tape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------- split disk and tape across sites ---------------------------------\")\n",
    "print (Detectors)\n",
    "holder.debug=DEBUG\n",
    "oldlocation = \"Total\"\n",
    "for detector in Detectors:\n",
    "    split = None\n",
    "    if detector in PDlist:\n",
    "        split = Splits[\"PD\"]\n",
    "    elif detector in FDlist:\n",
    "        split = Splits[\"FD\"]\n",
    "    elif detector in NDlist:\n",
    "        split = Splits[\"ND\"]\n",
    "    if split is None:\n",
    "        print (\"can't figure out split\", detector)\n",
    "        break\n",
    "    if DEBUG: print (split.keys())\n",
    "    for datatype in DataTypes:\n",
    "        #if datatype in holder.nosum: continue            \n",
    "        for resource in [\"Disk\",\"Tape\",\"GPU\",\"CPU\"]:\n",
    "            thedatatype = datatype\n",
    "            \n",
    "            if resource in [\"CPU\",\"GPU\"]:  # right now this is generic \n",
    "                thedatatype = resource\n",
    "            for location in Locations:\n",
    "                if location in holder.nosum: continue\n",
    "                oldtag = holder.tag(detector,datatype,resource,oldlocation,BaseUnits[resource])\n",
    "                if oldtag not in holder.holder:\n",
    "                    if DEBUG: print (\"skip split tag\",oldtag)\n",
    "                    continue\n",
    "                if DEBUG: print (\"check\", resource,thedatatype,location)\n",
    "                factor = split[resource][thedatatype][location]\n",
    "                if DEBUG: print (\"split\",factor)\n",
    "                newtag = holder.scale(detector= detector,datatype=datatype,resource=resource,location=oldlocation,units=\"TB\",categories={\"Locations\":location},factor=factor)\n",
    "\n",
    "holder.csvDump(dirname+\"/\"+\"split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of generic storage\n",
    "for detector in Detectors:\n",
    "    for datatype in config[\"NativeTypes\"]:\n",
    "        location = \"Total\"\n",
    "        resource = \"Store\"\n",
    "        newtag = holder.tag(detector,datatype,location,resource,\"TB\")\n",
    "        if newtag in holder.holder:\n",
    "            holder.remove(newtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd241073",
   "metadata": {},
   "source": [
    "# do the cumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------- cumulate storage by retention -------------\")\n",
    "#DEBUG=True\n",
    "\n",
    "print (Detectors)\n",
    "for detector in Detectors:\n",
    "    if detector in holder.nosum: continue\n",
    "    for datatype in DataTypes:\n",
    "        if datatype in [\"Raw-Events\",\"Sim-Events\"]: continue\n",
    "        for newresource in [\"Disk\",\"Tape\"]:\n",
    "            for location in Locations+[\"Total\"]:\n",
    "\n",
    "                if newresource == \"Disk\": \n",
    "                    retain = DiskLifetimes[datatype]\n",
    "                    retresource = \"Cumulative-Disk\"\n",
    "                    if \"Reco\" in datatype:\n",
    "                        if DEBUG: print (\"extend later\",detector,datatype,newresource,location)\n",
    "                        retresource = \"Unextended-Cumulative-Disk\"\n",
    "                    #print (detector,datatype,newresource,location)\n",
    "\n",
    "                if newresource == \"Tape\": \n",
    "                    retain = TapeLifetimes[datatype]\n",
    "                    retresource = \"Cumulative-Tape\"\n",
    "\n",
    "                newertag = holder.cumulateMe(detector=detector,datatype=datatype,resource=newresource,location=location,units=\"TB\",categories={\"Resources\":retresource},period=retain)\n",
    "                # if DEBUG: print (newertag,holder.holder,newertag)\n",
    "                # # and extend time for reconstructed disk so one can analyze\n",
    "                # if (\"Reco\" in datatype and retresource == \"Cumulative-Disk\"):\n",
    "                #     if DEBUG: print (\"extend by \",AnalysisExtend,newertag)\n",
    "                #     newertag = holder.extendMe(detector,datatype,retresource,location,\"TB\",{},AnalysisExtend)\n",
    "                if DEBUG: print (newertag)\n",
    "                \n",
    "holder.csvDump(\"cumulate.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ddd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------- extend reco samples on disk -------------\")\n",
    "#DEBUG=True\n",
    "print (Detectors)\n",
    "for detector in Detectors:\n",
    "    #if detector in holder.nosum: continue\n",
    "    for datatype in [\"Reco-Data\",\"Reco-Sim\"]:   \n",
    "        for newresource in [\"Unextended-Cumulative-Disk\"]:\n",
    "            for location in Locations+[\"Total\"]:\n",
    "                if \"Reco\" in datatype:\n",
    "                    #print (detector,datatype,newresource,location)\n",
    "                    pretag = holder.tag(detector,datatype,newresource,location,\"TB\")\n",
    "                    if pretag not in holder.holder:\n",
    "                        print (\"pretag not there\",pretag)\n",
    "                        continue\n",
    "                    if DEBUG: print (\"extend by \",AnalysisExtend,pretag)\n",
    "                    \n",
    "                    if DEBUG and pretag in holder.holder:\n",
    "                        print (holder.holder[pretag])\n",
    "                    #newtype = datatype.replace(\"Reco\",\"Analysis\")\n",
    "                    newertag = holder.extendMe(detector,datatype,newresource,location,\"TB\",{\"Resources\":\"Cumulative-Disk\"},AnalysisExtend)\n",
    "                    if DEBUG: print (\"removing\",pretag)\n",
    "                    holder.removeTag(pretag)\n",
    "                if DEBUG: print (newertag)\n",
    "                \n",
    "holder.csvDump(dirname+\"/\"+\"extend.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ab978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Detectors)\n",
    "print (Locations)\n",
    "while \"Total\" in Detectors:\n",
    "    Detectors.remove(\"Total\")\n",
    "print (Detectors)\n",
    "print (\"------------------ sum across storage types -------------------\")\n",
    "StorageTypes=[\"Tape\",\"Disk\",\"Cumulative-Tape\",\"Cumulative-Disk\"]\n",
    "\n",
    "Storage = {\"Detectors\":Detectors,\"DataTypes\":DataTypes,\"Resources\":StorageTypes,\"Locations\":Locations}\n",
    "\n",
    "#holder.debug=True\n",
    "holder.sumAcrossAll(filter=Storage,sumName=\"Total\")\n",
    "holder.debug=DEBUG\n",
    "\n",
    "holder.csvDump(dirname+\"/\"+\"sumacross.csv\")\n",
    "print (Detectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009c9a5",
   "metadata": {},
   "source": [
    "## Define subsamples to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4839829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Storage = {\"Detectors\":(Detectors+[\"Total\"]),\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":StorageTypes,\"Locations\":[\"Total\"]}\n",
    "\n",
    "TapeStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "CumulativeTapeStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "DiskStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "DiskStorageFDVD = {\"Detectors\":[\"FDVD\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "CumulativeDiskStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "DiskStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":Locations+[\"Total\"]}\n",
    "DiskStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"]}\n",
    "TapeStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":Locations+[\"Total\"]}\n",
    "TapeStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "CumulativeDiskStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"]}\n",
    "CumulativeDiskStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":Locations+[\"Total\"]}\n",
    "\n",
    "CumulativeTapeStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"]}\n",
    "CumulativeTapeStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":Locations+[\"Total\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holder.Draw(dirname,\"New Tape by Type\",YAxis=\"Storage\",Category=\"DataTypes\",filter=TapeStorage)\n",
    "holder.Draw(dirname,\"New Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=TapeStorageByDetector)\n",
    "holder.Draw(dirname,\"New Tape by Site\",YAxis=\"Storage\",Category=\"Locations\",filter=TapeStorageBySite)\n",
    "holder.Draw(dirname,\"Cumulative Tape by Type\",YAxis=\"Storage\",Category=\"DataTypes\",filter=CumulativeTapeStorage)\n",
    "holder.Draw(dirname,\"Cumulative Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=CumulativeTapeStorageByDetector)\n",
    "holder.Draw(dirname,\"Cumulative Tape by Site\",YAxis=\"Storage\",Category=\"Locations\",filter=CumulativeTapeStorageBySite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holder.Draw(dirname,\"New Disk by Type\",YAxis=\"Storage\",Category=\"DataTypes\",filter=DiskStorage)\n",
    "holder.Draw(dirname,\"New Disk by Type for FDVD\",YAxis=\"Storage\",Category=\"DataTypes\",filter=DiskStorageFDVD)\n",
    "holder.Draw(dirname,\"New Disk by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=DiskStorageByDetector)\n",
    "holder.Draw(dirname,\"New Disk by Site\",YAxis=\"Storage\",Category=\"Locations\",filter=DiskStorageBySite)\n",
    "holder.Draw(dirname,\"Cumulative Disk by Type\",YAxis=\"Storage\",Category=\"DataTypes\",filter=CumulativeDiskStorage)\n",
    "holder.Draw(dirname,\"Cumulative Disk by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=CumulativeDiskStorageByDetector)\n",
    "holder.Draw(dirname,\"Cumulative Disk by Site\",YAxis=\"Storage\",Category=\"Locations\",filter=CumulativeDiskStorageBySite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by detector plots\n",
    "\n",
    "for detector in Detectors:\n",
    "    if detector == \"Total\": continue\n",
    "    TapeStorage = {\"Detectors\":detector,\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "    CumulativeTapeStorage = {\"Detectors\":detector,\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "    DiskStorage = {\"Detectors\":detector,\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "    CumulativeDiskStorage = {\"Detectors\":detector,\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"]}\n",
    "\n",
    "    DiskStorageBySite = {\"Detectors\":detector,\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":Locations+[\"Total\"]}\n",
    "    \n",
    "    TapeStorageBySite = {\"Detectors\":detector,\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":Locations+[\"Total\"]}\n",
    "\n",
    "    CumulativeDiskStorageBySite = {\"Detectors\":detector,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":Locations+[\"Total\"]}\n",
    "    \n",
    "    CumulativeTapeStorageBySite = {\"Detectors\":detector,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":Locations+[\"Total\"]}\n",
    "\n",
    "    holder.Draw(dirname,\"New Disk by Type \"+detector,YAxis=\"Storage\",Category=\"DataTypes\",filter=DiskStorage)\n",
    "    \n",
    "    holder.Draw(dirname,\"New Disk by Site \"+detector,YAxis=\"Storage\",Category=\"Locations\",filter=DiskStorageBySite)\n",
    "    holder.Draw(dirname,\"Cumulative Disk by Type \"+detector,YAxis=\"Storage\",Category=\"DataTypes\",filter=CumulativeDiskStorage)\n",
    "    \n",
    "    holder.Draw(dirname,\"Cumulative Disk by Site \"+detector,YAxis=\"Storage\",Category=\"Locations\",filter=CumulativeDiskStorageBySite)\n",
    "\n",
    "    holder.Draw(dirname,\"New Tape by Type \"+detector,YAxis=\"Storage\",Category=\"DataTypes\",filter=TapeStorage)\n",
    "    #holder.Draw(dirname,\"New Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=TapeStorageByDetector)\n",
    "    holder.Draw(dirname,\"New Tape by Site \"+detector,YAxis=\"Storage\",Category=\"Locations\",filter=TapeStorageBySite)\n",
    "    holder.Draw(dirname,\"Cumulative Tape by Type \"+detector,YAxis=\"Storage\",Category=\"DataTypes\",filter=CumulativeTapeStorage)\n",
    "    #holder.Draw(dirname,\"Cumulative Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=CumulativeTapeStorageByDetector)\n",
    "    holder.Draw(dirname,\"Cumulative Tape by Site \"+detector,YAxis=\"Storage\",Category=\"Locations\",filter=CumulativeTapeStorageBySite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tagsets=holder.makeTagSet(CumulativeDiskStorageBySite)\n",
    "for tags in tagsets:\n",
    "    print (tags,holder.holder[tags])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e02190",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# EventTags = []\n",
    "# RecoCPUTags = []\n",
    "\n",
    "# for detector  in Detectors:\n",
    "#     EventTags.append(holder.tag(detector,\"Raw-Data\",\"Store\",\"Total\",Scales[\"Raw-Data-Store\"]))\n",
    "#     RecoCPUTags.append(holder.tag(detector,\"Reco-Data\",\"CPU\",\"Total\",Scales[\"Reco-Data-CPU\"]))\n",
    "#     CPUTags\n",
    "# if DRAW: CPUholder.Draw(\"CPU by Detector\",\"Total\",\"Detectors\")\n",
    "\n",
    "# sys.exit(1)\n",
    "if DRAW: holder.Draw(\"Test1\",\"Raw-Data\",\"Detectors\",EventTags)\n",
    "if DRAW: holder.Draw(\"CPU\",\"Reco-Data\",\"Detectors\",RecoCPUTags)\n",
    "\n",
    "    # for datatype in [\"Analysis\"]:  # keep analyzing for a few years. \n",
    "    #     for resource in Resources:\n",
    "    #         for location in Locations:\n",
    "    #             newtag = holder.cumulateMe(detector,datatype,resource,location,\"Datatypes\",resource,factor)\n",
    "       \n",
    "    #     mc = extendMap(Years,Inputs[det][\"Sim-CPU\"],AnalysisExtend)\n",
    "    #     if DEBUG: print (\"mc\",mc)\n",
    "    #     for year in Years:\n",
    "    #         total = data[year]\n",
    "    #         total += mc[year]\n",
    "    #         Inputs[det][key][year] = total *config[det][\"Analysis-CPU\"]  # this scales by a factor relative to reco/sim-MWC\n",
    "        \n",
    "    #     if DEBUG: print (\"other key\",det,key)\n",
    "\n",
    "\n",
    "\n",
    "# do a little cleanup\n",
    "\n",
    "# for det in Inputs.keys():\n",
    "    \n",
    "#     if \"Sim-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Sim-Memory\")\n",
    "#     if \"Reco-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Reco-Memory\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a data file which uses # of events to figure out how big samples are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if PerYear[\"Reco-Data-Store\"]!=PerYear[\"Reco-Data-CPU\"]:\n",
    "    print (\"Data growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Data-Store\"] = PerYear[\"Reco-Data-CPU\"]\n",
    "if PerYear[\"Reco-Sim-Store\"]!=PerYear[\"Reco-Sim-CPU\"]:\n",
    "    print (\"Sim growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Sim-Store\"] = PerYear[\"Reco-Sim-CPU\"]\n",
    "\n",
    "#Data = {}\n",
    "#dump = open(\"dump.txt\",'w')\n",
    "\n",
    "    \n",
    "#print (Inputs.keys())\n",
    "# fields = config[\"Scales\"]\n",
    "# print (\"fields\",fields)\n",
    "# for dtype in fields:\n",
    "#     Data[dtype] = {}\n",
    "#     if \"Memory\" in dtype:\n",
    "#         continue\n",
    "#     for det in Detectors:\n",
    "        \n",
    "#         # this allows you to, say, do 2 passes of reco/year\n",
    "        \n",
    "#         # print(\"makeData\",dtype, det, Inputs[det][dtype][year])\n",
    "#         for year in Years:\n",
    "#             Data[dtype][det][year] = float(Inputs[det][dtype][year]) * float(PerYear[dtype])\n",
    "#         # compensate for nominal units being millions and TB or singles and MB\n",
    "#         if Units[dtype] == \"PB\":\n",
    "#             for year in Years:\n",
    "#                 Data[dtype][det][year] *= 0.001\n",
    "#         ds = \"data %s %s %f\\n\"%(dtype,det,Data[dtype][det][2022])\n",
    "#         dump.write(ds)\n",
    "\n",
    "\n",
    "# - impose a cap at Cap (30 PB/year if set)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# impose a cap at Cap on things derived from raw data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350a325",
   "metadata": {},
   "source": [
    "\n",
    "dtype = \"Raw-Store\"\n",
    "\n",
    "Data[\"Raw-Store\"][\"Total\"] = {}\n",
    "for year in Years:\n",
    "    Data[dtype][\"Total\"][year] = 0.0\n",
    "for det in Inputs.keys():\n",
    "\n",
    "    for year in Years:\n",
    "        \n",
    "        Data[dtype][\"Total\"][year] +=  Data[\"Raw-Store\"][det][year]\n",
    "        \n",
    "dtypes = [\"Raw-Store\"] #,\"Reco-Data-CPU\"]\n",
    "for dtype in dtypes:\n",
    "    for det in Inputs.keys():\n",
    "        #print (dtype,det,2035,1.0,Data[dtype][det][2035] )\n",
    "        for year in Years:\n",
    "            cap = Data[\"Raw-Store\"][\"Total\"][year]/Cap\n",
    "           # print (dtype,det,year,cap,Data[dtype][det][year] )\n",
    "            if cap > 1:\n",
    "                Data[dtype][det][year] /=cap\n",
    "        #print (dtype,det,2035,cap,Data[dtype][det][2035] )\n",
    "\n",
    "\n",
    "# # Make a total across detectors\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688c5b9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "dtypes = [\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]\n",
    "\n",
    "\n",
    "\n",
    "for dtype in dtypes:\n",
    "    Data[dtype][\"Total\"] ={}\n",
    "    \n",
    "        \n",
    "    for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "    for det in Inputs.keys():\n",
    "        #if dtype != \"Analysis\":  # not certain what this does... I think it is leftover. \n",
    "        for year in Years:\n",
    "            Data[dtype][\"Total\"][year]+=  Data[dtype][det][year] \n",
    "    \n",
    "             \n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Raw-Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\",\"Reco-Data-GPU\",\"Sim-GPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "ToCSV2(shortname+\"-Reco-Data-GPU\",\"Reco-Data-GPU\",PlotYears,Data,Units,Formats)\n",
    "ToCSV2(shortname+\"-Sim-GPU\",\"Sim-GPU\",PlotYears,Data,Units,Formats)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "print (Inputs.keys())\n",
    "other = list(Inputs[\"ND-SAND\"].keys())+[\"Total\"]\n",
    "\n",
    "print (other)\n",
    "\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Raw-Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# merge protodune info\n",
    "\n",
    "if DEBUG: print (\"Data keys\",Data.keys())\n",
    "\n",
    "for dtype in Data.keys():\n",
    "    if DEBUG: print (\"Merge protodunes\",dtype)\n",
    "    det = \"PDs\" \n",
    "    Data[dtype][det] = {}\n",
    "    for year in Years:  \n",
    "        Data[dtype][det][year] = Data[dtype][\"SP\"][year] + Data[dtype][\"DP\"][year] + Data[dtype][\"PDHD\"][year] + Data[dtype][\"PDVD\"][year]\n",
    "\n",
    "    Data[dtype].pop(\"SP\")\n",
    "    Data[dtype].pop(\"PDHD\")\n",
    "    Data[dtype].pop(\"DP\")\n",
    "    Data[dtype].pop(\"PDVD\")\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# merge far detector into \"FDs\n",
    "if \"HD\" in Detectors and \"VD\" in Detectors:\n",
    "    for dtype in Data.keys():\n",
    "        det = \"FDs\"\n",
    "        print (\"merge FDS\",dtype)\n",
    "        Data[dtype][det] =  {}\n",
    "        for year in Years:  \n",
    "            Data[dtype][det][year] = Data[dtype][\"HD\"][year] + Data[dtype][\"VD\"][year]\n",
    "        Data[dtype].pop(\"HD\")\n",
    "        Data[dtype].pop(\"VD\")\n",
    "        \n",
    "# for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         Data[dtype][det] =  {}\n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] = 0\n",
    "        \n",
    "# for subdet in [\"Calib\",\"HighE\",\"LowE\",\"LBL\",\"Calib\",\"TP\"]:\n",
    "#     for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         print (\"merge FDS\",dtype)\n",
    "        \n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] += Data[dtype][subdet][year] \n",
    "#         Data[dtype].pop(\"subdet\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a total CPU category\n",
    "\n",
    "Data[\"Total-CPU\"]={}\n",
    "\n",
    "for det in CombinedDetectors:\n",
    "    Data[\"Total-CPU\"][det] =  {}\n",
    "    for year in Years:\n",
    "        Data[\"Total-CPU\"][det][year] = Data[\"Reco-Data-CPU\"][det][year] + Data[\"Sim-CPU\"][det][year] + Data[\"Analysis-CPU\"][det][year]\n",
    "    #print(det,Data[\"Total-CPU\"][det])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make totals across categories. \n",
    "\n",
    "DataTypes = list(Data.keys())\n",
    "\n",
    "for dt in DataTypes:\n",
    "    Data[dt][\"Total\"] = {}\n",
    "    for year in Years:\n",
    "        Data[dt][\"Total\"][year]=0.0\n",
    "    for k in Data[dt].keys():\n",
    "        if k == \"Total\":\n",
    "          continue  \n",
    "        for year in Years:\n",
    "            Data[dt][\"Total\"][year] += Data[dt][k][year]\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# and make a special data type for cores\n",
    "\n",
    "Data[\"Cores\"] = {}\n",
    "Data[\"HS23\"] = {}\n",
    "Data[\"Wall\"] = {}\n",
    " \n",
    "MHrsPerYear = 1000000/365./24.\n",
    "print (\"MHrsPerYear\",MHrsPerYear)\n",
    "print (\"total-CPU keys\",Data[\"Total-CPU\"].keys())\n",
    "for k in Data[\"Total-CPU\"].keys():\n",
    "#     if \"MARS\" not in k :\n",
    "#         efficiency = config[\"Cores\"][\"Efficiency\"]\n",
    "#     else:\n",
    "#         efficiency = 1\n",
    "\n",
    "    scaleTo2020 = config[\"Cores\"][\"2020Units\"]\n",
    "    Data[\"Cores\"][k]={}\n",
    "    Data[\"Wall\"][k]={}\n",
    "    Data[\"HS23\"][k]={}\n",
    "#    Data[\"WALL\"][k]={}\n",
    "    for year in Years:\n",
    "        Data[\"Wall\"][k][year] = Data[\"Total-CPU\"][k][year]/scaleTo2020/efficiency\n",
    "        Data[\"Cores\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency\n",
    "        Data[\"HS23\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency*config[\"kHEPSPEC06PerCPU\"]\n",
    "#        Data[\"WALL\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/efficiency/scaleTo2020\n",
    "\n",
    "\n",
    "# # Yearly info:\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"] \n",
    "if DRAW:\n",
    "    DrawDet(shortname+\"_byyear\",\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines)#,cpuactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines)#,coreactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#  for Storage work out split between different institutions\n",
    "\n",
    "Splits = {}\n",
    "for f in SplitsEarly:\n",
    "    Splits[f] = {}\n",
    "    for t in SplitsEarly[f]:\n",
    "        Splits[f][t] = {}\n",
    "        for loc in SplitsEarly[f][t]: \n",
    "            Splits[f][t][loc] = {}\n",
    "            #print (f,t,Splits[f][t],Splits[f][t][0])\n",
    "    \n",
    "            for y in Years:\n",
    "                if y < SplitsYear:\n",
    "                    Splits[f][t][loc][y]=SplitsEarly[f][t][loc]\n",
    "                else:\n",
    "                    Splits[f][t][loc][y]=SplitsLater[f][t][loc]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if DEBUG: print (Splits[\"CPU\"])\n",
    "\n",
    "for key in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]: \n",
    "    \n",
    "    for site in [\"FNAL\",\"CERN\",\"Global\"]:\n",
    "        Data[key][site] = {}\n",
    "        for year in Years:\n",
    "            \n",
    "            Data[key][site][year] = Data[key][\"Total\"][year]*Splits[\"CPU\"][\"CPU\"][site][year]\n",
    "            \n",
    "\n",
    "\n",
    "# # here is where we start doing cumulation across years for disk and reconstruction\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# now do some Cumulative-work.  Stuff stays on tape/disk for different amounts of time and we have multiple copies\n",
    "\n",
    "Storage = {}\n",
    "for k in StorageTypes:\n",
    "    Storage[k] = {}\n",
    "Storage[\"Total\"] = {}\n",
    "Storage[\"Global\"] = {}\n",
    "Storage[\"FNAL\"] = {}\n",
    "Storage[\"CERN\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Disk\"] = {}\n",
    "\n",
    "\n",
    "for year in Years:\n",
    "    Storage[\"Total\"][\"Cumulative-Tape\"][year] = 0.0\n",
    "    Storage[\"Total\"][\"Cumulative-Disk\"][year] = 0.0\n",
    "\n",
    "for k in StorageTypes:\n",
    "    Storage[k][\"Tape\"] = {}\n",
    "    Storage[k][\"Disk\"] = {}\n",
    "    for year in Years:\n",
    "        Storage[k][\"Tape\"][year] = Data[k][\"Total\"][year]*TapeCopies[k]\n",
    "        Storage[k][\"Disk\"][year] = Data[k][\"Total\"][year]*DiskCopies[k]\n",
    "    # extend disk for Analysis HMS 6-24-2023\n",
    "    #Storage[k][\"Disk\"]  = extendMap(Years,Storage[k][\"Disk\"],AnalysisExtend) \n",
    "    \n",
    "    Storage[k][\"Cumulative-Tape\"] = cumulateMap(Years,Storage[k][\"Tape\"],TapeLifetimes[k])\n",
    "    Extend = cumulateMap(Years,Storage[k][\"Disk\"],DiskLifetimes[k])\n",
    "    if k != \"Test\": \n",
    "        Storage[k][\"Cumulative-Disk\"] = extendMap(Years,Extend,AnalysisExtend,k)\n",
    "    else:\n",
    "        Storage[k][\"Cumulative-Disk\"] = Extend\n",
    "    \n",
    "    for year in Years:\n",
    "        Storage[\"Total\"][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]\n",
    "        Storage[\"Total\"][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]\n",
    "    \n",
    "    \n",
    "        \n",
    "for loc in Splits[\"Disk\"][\"Raw-Store\"]:\n",
    "    for year in Years:\n",
    "        Storage[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "        Storage[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "        for k in StorageTypes:\n",
    "              Storage[loc][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]*Splits[\"Disk\"][k][loc][year]\n",
    "              Storage[loc][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]*Splits[\"Tape\"][k][loc][year]\n",
    "\n",
    "\n",
    "# cdisk = SumOver1(\"Cumulative-Disk\",Data)\n",
    "# print (\"sum over\",cdisk)\n",
    "\n",
    "# for year in Years:\n",
    "#         Data[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "#         Data[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "#         for k in StorageTypes:\n",
    "#               Data[loc][\"Cumulative-Disk\"][year] += Data[k][\"Cumulative-Disk\"][year] \n",
    "#               Data[loc][\"Cumulative-Tape\"][year] += Data[k][\"Cumulative-Tape\"][year] \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "texfile.write(\"\\\\section{Projected Disk and Tape needs by source and site}\\n\")\n",
    "#ToCSV1(shortname+\"-Disk_by_location\",\"Cumulative-Disk\",PlotYears,Storage,Units,Formats)\n",
    "#ToCSV1(shortname+\"-Tape_by_location\",\"Cumulative-Tape\",PlotYears,Storage,Units,Formats)\n",
    "# s = \"\\\\begin{table}[h]\\n \\\\centering\\\\csvautotabularright\\\n",
    "# {external/DUNERSEUSAGE-2022-11-14.csv}\\n \\\\label{Cumulative-Tape}\\n\\\n",
    "# \\\\caption{Rucio report on storage usage 2022-11-14 from the Scotgrid Dashboard \\\n",
    "# \\\\href{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}.}\\n \\\\end{table}\\n\"\n",
    "# s.replace(\"_\",\"\\_\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# s = TableTex(shortname+\"-Disk_by_location\",\"Disk requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Disk\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "# s = TableTex(shortname+\"-Tape_by_location\",\"Tape requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Tape\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# texfile.write(\"\\\\clearpage\\n\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# now do some plots\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"]\n",
    "\n",
    "cpuactual = []\n",
    "coreactual = []\n",
    "wallactual = []\n",
    "\n",
    "Sites = [\"FNAL\",\"CERN\",\"Global\",\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines,cpuactual)\n",
    "    DrawDet(shortname,\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines,coreactual)\n",
    "    DrawDet(shortname,\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "    DrawDet(shortname,\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "# DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Sites,Units,DetColors,DetLines,cpuactual)\n",
    "# DrawDet(shortname,\"Cores\",PlotYears,Data,Sites,Units,DetColors,DetLines,coreactual)\n",
    "# #DrawDet(shortname,\"WALL\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "# DrawDet(shortname,\"HS23\",PlotYears,Data,Sites,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "for x in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]:\n",
    "    ToCSV2(shortname+\"-\"+x,x,PlotYears,Data,Units,Formats)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Captions2 = {\"Raw-Events\":\"Projected million of detector events per year.  Reconstructed data resources are based on this number.\",\n",
    "\"Test\":\"Projected PB of Test data per year.\",\n",
    "\"Sim-Events\":\"Projected millions of simulated events per year. Simulated data resources are based on this number. \",\n",
    "\"Raw-Store\":\"Projected raw data written per year in PB, derived from the number of events.\",\n",
    "\"Reco-Data-CPU\":\"Projected CPU needs in core-hrs for data reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction.  Assumes rereconstruction of several years of older data.\",\n",
    "\"Sim-CPU\":\"Projected CPU needs in core-hrs for simulation and reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction. Based directly on the number of simulated Events.\",\n",
    "\"Reco-Data-Store\":\"Projected PB of reconstructed data per year. Includes reprocessing.\",\n",
    "\"Sim-Store\":\"Projected PB of simulated data/year\",\n",
    "\"Total-CPU\":\"Slot weighted CPU needs in core-years. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Cores\":\"Slot weighted CPU needs in number of cores. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"HS23\":\"Slot weighted CPU needs in kHS23 hrs. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Analysis-CPU\":\"Slot weighted analysis CPU needs in core-hrs. Assumed to be a weighted fraction of reco+sim needs.\",\n",
    "            }\n",
    "print (Data[\"Raw-Events\"][\"PDs\"])\n",
    "#print (Data[\"Raw-Events\"][\"FDs\"])\n",
    "print (Data[\"Raw-Events\"][\"ND-SAND\"])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# for key in [\"Cores\",\"Total-CPU\",\"HS23\"]:\n",
    "#     print (\"Got to Here\")\n",
    "#     if not key in Units:\n",
    "#         print (\"no units for key\",key)\n",
    "#         continue\n",
    "#     ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "#     s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "#     #DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "#     #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     print  (\"Got to here\")\n",
    "#     s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     #texfile.write(s2)\n",
    "#     tablefile.write(s2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print (Storage.keys())\n",
    "    \n",
    "Captions1 = {\"Cumulative-Tape\":\"Cumulative Tape needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\", \n",
    "             \"Cumulative-Disk\":\"Cumulative Disk needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\",\n",
    "            \"HS23\":\"CPU needs in HS23 units\"}\n",
    "            \n",
    "\n",
    "for key in ['Cumulative-Tape', 'Cumulative-Disk']:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    # actual = None\n",
    "    # if key == \"Cumulative-Tape\":\n",
    "    #     actual = tapeactual\n",
    "    # if key == \"Cumulative-Disk\":\n",
    "    #     actual = diskactual\n",
    "    # print (actual)\n",
    "    ToCSV1(shortname+\"-\"+key,key,PlotYears,Storage,Units,Formats)\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Source\",key,PlotYears,Storage,Units,Formats,['Raw-Store', 'Test', 'Reco-Data-Store', 'Sim-Store', 'Total'])\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Request\",key,PlotYears,Storage,Units,Formats,['Global', 'FNAL', 'CERN', 'Total'])\n",
    "    s = TableTex(shortname+\"-\"+key,Captions1[key],key+\"\\n\")\n",
    "    print (key,s)\n",
    "    dunestyle.Preliminary()\n",
    "    DrawType(shortname,key,PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    " \n",
    "    s2 = BothTex(shortname,key+\".png\",Captions1[key],key)\n",
    "\n",
    "    #texfile.write(s2)\n",
    "    texfile.write(s2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print (Types)\n",
    "\n",
    "for key in Types:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "\n",
    "for key in Sites:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "        \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "tapepoints = np.zeros(len(Years))\n",
    "diskpoints = np.zeros(len(Years))\n",
    "\n",
    "#DrawType(shortname,\"Tape\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Tape\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "tablefile.close()\n",
    "#texfile.write(\"\\\\input{bibmaker.tex}\\n\")\n",
    "#texfile.write(\"\\\\clearpage\\n\")\n",
    "#texfile.write(\"\\\\section{Appendix - Model inputs}\\n\")\n",
    "#texfile.write(\"\\\\input{\"+dirname+\"/tables.tex}\\n\")\n",
    "#texfile.write(\"\\\\end{document}\\n\")\n",
    "texfile.close()\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a set of request numbers to add to the tex file - they need to have tex compatible nicknames\n",
    "\n",
    "macro = open(shortname+\"_macros.tex\",'w')\n",
    "\n",
    "command = makeParameter(\"HS23Request\",\"%10.0f\"%(Data[\"HS23\"][\"Total\"][RequestYear]))\n",
    "print (\"tex command\", command,Data[\"HS23\"][\"Total\"][RequestYear])\n",
    "\n",
    "Requests = {}\n",
    "Requests[\"CPU\"]=\"HS23\"\n",
    "Requests[\"CORES\"]=\"Cores\"\n",
    "\n",
    "Requests[\"DISK\"]=\"Cumulative-Disk\"\n",
    "Requests[\"TAPE\"]=\"Cumulative-Tape\"\n",
    "\n",
    "m = makeParameter(\"ThisYear\",\"%d\"%RequestYear)\n",
    "macro.write(m+\"\\n\")\n",
    "\n",
    "for y in Requests:\n",
    "    for x in Sites:\n",
    "        name = (\"%s%s\"%(y,x)).replace(\"-\",\"\")\n",
    "        if y == \"CPU\" or y == \"CORES\":\n",
    "            if y == \"CPU\": \n",
    "                m = makeParameter(name,\"%10.1f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "            else: \n",
    "                m = makeParameter(name,\"%10.0f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "        else:\n",
    "            m = makeParameter(name,\"%10.1f\"%(Storage[x][Requests[y]][RequestYear]))\n",
    "        macro.write(m+\"\\n\")\n",
    "macro.close()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "jname = configfilename.replace(\".json\",\"_internal.json\")\n",
    "jj = open(jname,'w')\n",
    "commentjson.dump(Data,jj,indent=4)\n",
    "jj.close()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#cmd='pdflatex MoreSim_2023-06-22-2040.tex'\n",
    "#get_ipython().system('{cmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b485c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bce31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
