{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61957124-7283-4238-8c04-84c8c2be685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# code to generate yearly summaries of DUNE data volumes from input parameters\n",
    "# rewritten from the version in the CDR - mainly by using maps of years instead of arrays to make it clearer what is in each year.\n",
    "# HMS 2022-10-23\n",
    "\n",
    "# if you have json problems, run the program ../strip.py on your file to take off comments\n",
    "# and then test using https://jsonlint.com\n",
    "#import numberutils\n",
    "\n",
    "import os,commentjson\n",
    "\n",
    "from csv import reader\n",
    "import json\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481973c9-a71e-4064-a7e2-9f736e67ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "DRAW = True\n",
    "import numpy as np\n",
    "#import scipy\n",
    "import dunestyle.matplotlib as dunestyle\n",
    "\n",
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import cumulateMap\n",
    "from NumberUtils import DrawDet\n",
    "from NumberUtils import DrawType\n",
    "from NumberUtils import makeArray\n",
    "from NumberUtils import ToCSV1\n",
    "from NumberUtils import ToCSV2\n",
    "from NumberUtils import SumOver1\n",
    "from NumberUtils import SumOver2\n",
    "from NumberUtils import TableTex\n",
    "from NumberUtils import BothTex\n",
    "from NumberUtils import extendMap\n",
    "from NumberUtils import makeParameter\n",
    "\n",
    "from DataHolder import DataHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c3326-7195-446a-8ca5-a432412c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many histograms to draw in multi-hist plots\n",
    "N_HISTS = 8   # exhibits all the colors in the Okabe-Ito cycler\n",
    "\n",
    "\n",
    "# # specify the json file here.  Will create a subdirectory for plots with a similar name\n",
    "\n",
    "# ## \n",
    "\n",
    "# \"Tex\"# read in a \n",
    "# file\n",
    "# #configfilename = \"Parameters_2022-11-21-2040.json\"\n",
    "# \n",
    "# #configfilename = \"DOE23-NDLAr_2023-11-03-2040b.json\"\n",
    "# #configfilename = \"DOE23-NDLAr_2023-12-11-2040.json\"  # increase sim for ND\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "configfilename = \"NearTerm_2024-08-09-2040.json\"\n",
    "#if len(sys.argv) > 1:\n",
    "#  configfile = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0efc9-6b66-4fcf-9725-b4a2bc229aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortname = configfilename.replace(\".json\",\"\")\n",
    "if os.path.exists(configfilename):\n",
    "    with open(configfilename,'r') as f:\n",
    "        #x = f.read()\n",
    "        #print (x[6000:6960])\n",
    "        config = commentjson.load(f)\n",
    "else:\n",
    "    print (\"no config file\",configfilename)\n",
    "    sys.exit(0)\n",
    "\n",
    "if not \"Version\" in config or config[\"Version\"] < 20:\n",
    "    print (\" this code expects Version >= 20\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "MWCWeight = config[\"MWCWeight\"] # do we weight cores by available memory? \n",
    "MaxYear = config[\"MaxYear\"]\n",
    "MWCstring = \"_noMWC\"\n",
    "if MWCWeight: MWCstring=\"\"\n",
    "config[\"filename\"] = configfilename\n",
    "MinYear = config[\"MinYear\"]\n",
    "Detectors = config[\"Detectors\"]\n",
    "Years = config[\"Years\"]\n",
    "\n",
    "shortname = shortname.replace(\"2040\",\"%d\"%MaxYear)+MWCstring\n",
    "dirname = shortname\n",
    "if not os.path.exists(dirname):\n",
    "    os.mkdir(dirname)\n",
    "shortname = dirname+\"/\"+dirname\n",
    "# make a tex output file\n",
    "texfilename = dirname+\".tex\"\n",
    "texfile = open(texfilename,'w')\n",
    "tablefile = open(os.path.join(dirname,\"tables.tex\"),'w')\n",
    "#texfile.write(\"\\\\input{Header.tex}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "size = len(Years)\n",
    "\n",
    "Units = config[\"Units\"]\n",
    "\n",
    "RequestYear=2024\n",
    "if \"RequestYear\" in config:\n",
    "    RequestYear= config[\"RequestYear\"]\n",
    "\n",
    "# if not MWCWeight: \n",
    "#     print (\"remove MWC\")\n",
    "#     for type in Units.keys():\n",
    "#         Units[type] = Units[type].replace(\"MWC-\",\"\")\n",
    "#         Units[type] = Units[type].replace(\"Memory weighted \",\"\")\n",
    "#         Units[type] = Units[type].replace(\"Memory Weighted \",\"\")\n",
    "#     print (\"Units\", Units)\n",
    "        \n",
    "Formats = config[\"Formats\"]\n",
    "\n",
    "Detectors = config[\"Detectors\"]\n",
    "\n",
    "DataTypes = config[\"DataTypes\"]\n",
    "NativeTypes = config[\"NativeTypes\"]\n",
    "Resources = config[\"Resources\"]\n",
    "Locations = config[\"Locations\"]\n",
    "Scales = config[\"Scales\"]\n",
    "Cap = config[\"Cap\"]\n",
    "\n",
    "BaseMemory = config[\"Base-Memory\"]\n",
    "\n",
    "\n",
    "print (Detectors)\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "print (\"Parameters\",DetectorParameters)\n",
    "\n",
    "\n",
    "if \"Comment\" in DetectorParameters:\n",
    "    DetectorParameters.remove(\"Comment\")\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "# this is how far you go back each time you reprocess reco.\n",
    "Reprocess = config[\"Reprocess\"]\n",
    "\n",
    "AnalysisExtend = config[\"AnalysisExtend\"]\n",
    "\n",
    "PerYear = config[\"PerYear\"]\n",
    "\n",
    "StorageTypes = list(TapeCopies.keys())\n",
    "\n",
    "print (StorageTypes)\n",
    "# plot config\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "TypeColors=config[\"TypeColors\"]\n",
    "TypeLines = config[\"TypeLines\"]\n",
    "\n",
    "PatternFraction = config[\"PatternFraction\"]\n",
    "\n",
    "SplitsYear = config[\"SplitsYear\"]\n",
    "SplitsEarly = config[\"SplitsEarly\"]\n",
    "SplitsLater = config[\"SplitsLater\"]\n",
    "\n",
    "Explain = config[\"Explain\"]\n",
    "Explain[\"filename\"] = \"Input configuration file\"\n",
    "\n",
    "\n",
    "for f in Explain.keys():\n",
    "\n",
    "    field = \"{\\\\tt %s:} %s = {\\\\tt %s} \\\\\\\\\\n\"%(f,Explain[f], config[f])\n",
    "    field = field.replace(\"_\",\"\\_\")\n",
    "    tablefile.write(field)\n",
    "    print (Explain[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97139b-4e67-4b07-8f8a-7e3af22bac46",
   "metadata": {},
   "source": [
    "## Make data container (holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acbc7c-4d6a-479c-9c4b-9c139ff5f1de",
   "metadata": {},
   "source": [
    "## Make data container (holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b76549-5360-44f1-9230-a30bc041f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "holder = DataHolder(theconfig=config,debug=DEBUG)\n",
    "holder.readTimeline()\n",
    "\n",
    "csvname = configfilename.replace(\".json\",\".csv\")\n",
    "csvData = holder.csvDump(csvname)\n",
    "\n",
    "\n",
    "holder.jsonDump(configfilename.replace(\".json\",\"safe.json\"))\n",
    "\n",
    "\n",
    "holder.debug=True\n",
    "\n",
    "print (\"Detector Parameters\",DetectorParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af1c79-65d5-445c-bcdb-f2ed18f2a7b2",
   "metadata": {},
   "source": [
    "# Change input (NativeTypes) into storage numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed3da6-f8c7-4754-a5ec-82736e78b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in other useful arrays\n",
    "\n",
    "\n",
    "for detector in Detectors:\n",
    "    print (\"--------------- raw-storage ------------------\")\n",
    "\n",
    "    # first raw data events which have to be stored. \n",
    "    # Make \"input\" locations in to \"Store\" scled by config[detector][type]\n",
    "    for olddatatype in config[\"NativeTypes\"]:\n",
    "        oldunits = Scales[olddatatype]\n",
    "        oldresource = \"input\"\n",
    "        newresource = \"Store\"\n",
    "        location = \"ALL\"\n",
    "                 \n",
    "        if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "            holder.printByTag(holder.tag(detector,olddatatype,oldresource,location,oldunits))\n",
    "            factor = 1\n",
    "            if olddatatype == \"Raw-Events\":\n",
    "                newdatatype = \"Raw-Data\"\n",
    "                factor = config[detector][\"Raw-Data-Store\"]\n",
    "                newunits = Scales[\"Raw-Data-Store\"]\n",
    "            else:\n",
    "                newdatatype = olddatatype\n",
    "                newunits = oldunits\n",
    "            # TP and Test are already in units of GB\n",
    "            # if DEBUG: print (\"storage\",detector,olddatatype,newresource,location,newunits,factor)\n",
    "            newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":newdatatype,\"Resources\":newresource,\"Units\":newunits},factor)\n",
    "            holder.printByTag(newtag)\n",
    "        else:\n",
    "            print (\"could not find\", detector,olddatatype,oldresource,location,oldunits)\n",
    "\n",
    "   \n",
    "\n",
    "holder.csvDump(\"after-raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ce56d-3ded-4778-978f-3ef2fef2b8cf",
   "metadata": {},
   "source": [
    "# calculate size of raw data coming from detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f688cf4-1b0d-4dce-9075-a80d5417bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealDataTypes=[\"Raw-Data\",\"TP\",\"Test\"]\n",
    "\n",
    "realsubset={\"Detectors\":Detectors,\"DataTypes\":RealDataTypes,\"Resources\":\"Store\",\"Locations\":\"ALL\"}\n",
    "\n",
    "realDataTotalDetector=holder.sumAcrossFilters(\n",
    "    filter=realsubset,sumCat=\"Detectors\",sumName=\"Sub-Total\")\n",
    "\n",
    "realsubset2={\"Detectors\":Detectors+[\"Sub-Total\"],\"DataTypes\":RealDataTypes,\"Resources\":\"Store\",\"Locations\":\"ALL\"}\n",
    "\n",
    "realDataTotalDetectorStore=holder.sumAcrossFilters(\n",
    "    filter=realsubset2,sumCat=\"DataTypes\",sumName=\"Sub-Total\")\n",
    "    \n",
    "newsubset={\"Detectors\":([\"Sub-Total\"]),\"DataTypes\":RealDataTypes+[\"Sub-Total\"],\"Resources\":\"Store\",\"Locations\":\"ALL\"}\n",
    "\n",
    "# holder.storeFilter(newsubset,\"real data storage\")\n",
    "\n",
    "# print (\"newsubset\",holder.makeTagSet(newsubset))\n",
    "\n",
    "print (\"newsubset\",holder.makeTagSet(newsubset))\n",
    "print (\"Draw\")\n",
    "holder.Draw(Title=\"RealData\",YAxis=\"Storage\",Category=\"DataTypes\",filter=newsubset)\n",
    "            \n",
    "holder.csvDump(\"realData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53069e-15ad-48b5-9df7-68e07ff01dbd",
   "metadata": {},
   "source": [
    "# extend events for Reco and calculate storage/CPU/GPU per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f6f88-38c9-4de5-b4d6-8f635298b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detector in Detectors:\n",
    "\n",
    "    print (\"---------------  makereco ------------------\") \n",
    "    for newdatatype in [\"Reco-Data\",\"Reco-Sim\"]:\n",
    "        oldresource = \"input\"\n",
    "        if newdatatype == \"Reco-Data\": \n",
    "            olddatatype = \"Raw-Events\"\n",
    "        if newdatatype == \"Reco-Sim\":\n",
    "            olddatatype = \"Sim-Events\"\n",
    "        oldunits = Scales[olddatatype]\n",
    "        location = \"ALL\"\n",
    "        # Reco gets reprocessed so has a special cumulation\n",
    "        for resource in [\"CPU\",\"GPU\",\"Store\"]:\n",
    "            newunits = Scales[newdatatype+\"-\"+resource]    \n",
    "            if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "                holder.printByTag(holder.tag(detector,olddatatype,oldresource,location,oldunits))                 \n",
    "                if DEBUG: print (\"--before Events->Things\",olddatatype,resource)\n",
    "                newunits = Scales[newdatatype+\"-\"+resource]\n",
    "                factor = config[detector][newdatatype + \"-\" +resource]*PerYear[newdatatype+\"-\"+resource]\n",
    "                if DEBUG: print (\"factor\",detector,newdatatype,resource,factor)\n",
    "                newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":newdatatype,\"Resources\":resource,\"Units\":newunits},factor)\n",
    "                holder.printByTag(newtag)\n",
    "                if DEBUG: print (\"--after Events->Things\",newdatatype,resource)\n",
    "\n",
    "                # special to say you redo previous Reprocess years of reco every year.\n",
    "                if newdatatype == \"Reco-Data\":  \n",
    "                    newtag = holder.cumulateMe(detector,newdatatype,resource,location,newunits,{\"DataTypes\":\"Reco-Data\"},Reprocess[detector])   \n",
    "                           \n",
    "                # extend both Sim and Data for analysis\n",
    "                if DEBUG:\n",
    "                    print (\"newtag\",newtag)\n",
    "                    print (\"Try to extend\", detector,newdatatype,resource,location,newunits)\n",
    "                if newdatatype in [\"Reco-Data\",\"Reco-Sim\"]:\n",
    "                    nwtag = holder.extendMe(detector,newdatatype,resource,location,newunits,{\"DataTypes\":newdatatype},AnalysisExtend)\n",
    "                holder.printByTag(newtag)\n",
    "\n",
    "holder.csvDump(\"after-reco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bf389-a4d7-41db-87ea-22bdca06b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  make analysis ------------------\")\n",
    "for detector in Detectors:\n",
    "    for resource in [\"CPU\"]:   \n",
    "        location = \"ALL\"\n",
    "        recoAtag = holder.scale(detector,\"Reco-Data\",resource,location,Scales[\"Reco-Data-CPU\"],{\"DataTypes\":\"Analysis-Data\"},config[detector][\"Analysis-CPU\"]*PerYear[\"Analysis-CPU\"])\n",
    "        simAtag = holder.scale(detector,\"Reco-Sim\",resource,location,Scales[\"Reco-Sim-CPU\"],{\"DataTypes\":\"Analysis-Sim\"},config[detector][\"Analysis-CPU\"]*PerYear[\"Analysis-CPU\"])\n",
    "        print (\"make analysis:\",recoAtag,simAtag)\n",
    "\n",
    "\n",
    "        \n",
    "holder.debug = False\n",
    "\n",
    "filter = {\"Detectors\":Detectors,\"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"],\"Resources\":[\"CPU\",\"GPU\"],\"Locations\":[\"ALL\"]}\n",
    "show = json.dumps(filter,indent=4)\n",
    "\n",
    "\n",
    "\n",
    "CPUTotals=holder.sumAcrossFilters(\\\n",
    "    filter=filter,sumCat=\"DataTypes\",sumName=\"Total\")\n",
    "holder.csvDump(\"after-total.csv\")\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------\")\n",
    "print (show)\n",
    "\n",
    "filter2 = {\"Detectors\":Detectors,\"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"]+[\"Total\"],\"Resources\":[\"CPU\",\"GPU\"],\"Locations\":[\"ALL\"]}\n",
    "\n",
    "CPUTotalsAllDetectors=holder.sumAcrossFilters(filter=filter2, sumCat=\"Detectors\",sumName= \"Total\")\n",
    "print (\"DataTypes\",DataTypes)\n",
    "\n",
    "CPUByDetector = {\"Detectors\":Detectors+[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"CPU\"],\"Locations\":[\"ALL\"]}\n",
    "CPUByType = {\"Detectors\":[\"Total\"],\"DataTypes\":(DataTypes+[\"Total\"]),\"Resources\":[\"CPU\"],\"Locations\":[\"ALL\"]}\n",
    "\n",
    "\n",
    "\n",
    "holder.storeFilter(filter=CPUByDetector,name=\"CPUByDetector\")\n",
    "print (\"CPUByType - dict\",CPUByType)\n",
    "\n",
    "holder.debug=False\n",
    "#holder.storeFilter(filter=CPUByType,name=\"CPUByType\")\n",
    "\n",
    "#print (\"CPUByType -list \",holder.filters[\"CPUByType\"])\n",
    "#holder.debug=False\n",
    "holder.Draw(Title=\"CPU by Detector\",YAxis=\"CPU\",Category=\"Detectors\",filter=CPUByDetector)\n",
    "\n",
    "holder.Draw(Title=\"CPU by type\",YAxis=\"CPU\",Category=\"DataTypes\",filter=CPUByType)\n",
    "\n",
    "CPUTotalsAllDetectors=holder.sumAcrossFilters(filter=filter2, sumCat=\"Detectors\",sumName= \"Total\")\n",
    "\n",
    "holder.csvDump(\"after-total2.csv\")\n",
    "\n",
    "print (json.dumps(filter2,indent=4))\n",
    "\n",
    "\n",
    "# CPUSlice = holder.makeSlice(criteria={\"Detectors\":Detectors,\"Resources\":[\"CPU\"]},name=\"CPUSlice\")\n",
    "\n",
    "# CPUholder = DataHolder(theconfig=config)\n",
    "\n",
    "# holder.copyToNewHolder(otherholder=CPUholder,slice=CPUSlice)\n",
    "\n",
    "\n",
    "\n",
    "# holder.printSlice(\"CPUSlice\")\n",
    "# newtags = CPUholder.sumAcrossSlice(category=\"DataTypes\",sumOver=[\"Analysis-Data\",\"Analysis-Sim\",\"Reco-Sim\",\"Reco-Data\"],slice=\"CPUSlice\",sumName=\"Total\")\n",
    "\n",
    "# CPUholder.csvDump(\"CPUholder.csv\")\n",
    "# print (newtags)\n",
    "            \n",
    "            \n",
    "#newtags = holder.sumAcross(\"DataTypes\",[\"Total-Analysis\",\"Reco-Data\",\"Reco-Sim\"])          \n",
    "\n",
    "holder.csvDump(\"after-analyze.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# EventTags = []\n",
    "# RecoCPUTags = []\n",
    "\n",
    "# for detector  in Detectors:\n",
    "#     EventTags.append(holder.tag(detector,\"Raw-Data\",\"Store\",\"ALL\",Scales[\"Raw-Data-Store\"]))\n",
    "#     RecoCPUTags.append(holder.tag(detector,\"Reco-Data\",\"CPU\",\"ALL\",Scales[\"Reco-Data-CPU\"]))\n",
    "#     CPUTags\n",
    "# if DRAW: CPUholder.Draw(\"CPU by Detector\",\"Total\",\"Detectors\")\n",
    "\n",
    "# sys.exit(1)\n",
    "if DRAW: holder.Draw(\"Test1\",\"Raw-Data\",\"Detectors\",EventTags)\n",
    "if DRAW: holder.Draw(\"CPU\",\"Reco-Data\",\"Detectors\",RecoCPUTags)\n",
    "\n",
    "    # for datatype in [\"Analysis\"]:  # keep analyzing for a few years. \n",
    "    #     for resource in Resources:\n",
    "    #         for location in Locations:\n",
    "    #             newtag = holder.cumulateMe(detector,datatype,resource,location,\"Datatypes\",resource,factor)\n",
    "       \n",
    "    #     mc = extendMap(Years,Inputs[det][\"Sim-CPU\"],AnalysisExtend)\n",
    "    #     if DEBUG: print (\"mc\",mc)\n",
    "    #     for year in Years:\n",
    "    #         total = data[year]\n",
    "    #         total += mc[year]\n",
    "    #         Inputs[det][key][year] = total *config[det][\"Analysis-CPU\"]  # this scales by a factor relative to reco/sim-MWC\n",
    "        \n",
    "    #     if DEBUG: print (\"other key\",det,key)\n",
    "\n",
    "\n",
    "\n",
    "# do a little cleanup\n",
    "\n",
    "# for det in Inputs.keys():\n",
    "    \n",
    "#     if \"Sim-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Sim-Memory\")\n",
    "#     if \"Reco-Memory\" in Inputs[det]:\n",
    "#         Inputs[det].pop(\"Reco-Memory\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a data file which uses # of events to figure out how big samples are\n",
    "\n",
    "if PerYear[\"Reco-Data-Store\"]!=PerYear[\"Reco-Data-CPU\"]:\n",
    "    print (\"Data growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Data-Store\"] = PerYear[\"Reco-Data-CPU\"]\n",
    "if PerYear[\"Reco-Sim-Store\"]!=PerYear[\"Reco-Sim-CPU\"]:\n",
    "    print (\"Sim growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco-Sim-Store\"] = PerYear[\"Reco-Sim-CPU\"]\n",
    "\n",
    "#Data = {}\n",
    "#dump = open(\"dump.txt\",'w')\n",
    "\n",
    "    \n",
    "#print (Inputs.keys())\n",
    "# fields = config[\"Scales\"]\n",
    "# print (\"fields\",fields)\n",
    "# for dtype in fields:\n",
    "#     Data[dtype] = {}\n",
    "#     if \"Memory\" in dtype:\n",
    "#         continue\n",
    "#     for det in Detectors:\n",
    "        \n",
    "#         # this allows you to, say, do 2 passes of reco/year\n",
    "        \n",
    "#         # print(\"makeData\",dtype, det, Inputs[det][dtype][year])\n",
    "#         for year in Years:\n",
    "#             Data[dtype][det][year] = float(Inputs[det][dtype][year]) * float(PerYear[dtype])\n",
    "#         # compensate for nominal units being millions and TB or singles and MB\n",
    "#         if Units[dtype] == \"PB\":\n",
    "#             for year in Years:\n",
    "#                 Data[dtype][det][year] *= 0.001\n",
    "#         ds = \"data %s %s %f\\n\"%(dtype,det,Data[dtype][det][2022])\n",
    "#         dump.write(ds)\n",
    "\n",
    "\n",
    "# - impose a cap at Cap (30 PB/year if set)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# impose a cap at Cap on things derived from raw data\n",
    "\n",
    "\n",
    "\n",
    "dtype = \"Raw-Store\"\n",
    "\n",
    "Data[\"Raw-Store\"][\"Total\"] = {}\n",
    "for year in Years:\n",
    "    Data[dtype][\"Total\"][year] = 0.0\n",
    "for det in Inputs.keys():\n",
    "\n",
    "    for year in Years:\n",
    "        \n",
    "        Data[dtype][\"Total\"][year] +=  Data[\"Raw-Store\"][det][year]\n",
    "        \n",
    "dtypes = [\"Raw-Store\"] #,\"Reco-Data-CPU\"]\n",
    "for dtype in dtypes:\n",
    "    for det in Inputs.keys():\n",
    "        #print (dtype,det,2035,1.0,Data[dtype][det][2035] )\n",
    "        for year in Years:\n",
    "            cap = Data[\"Raw-Store\"][\"Total\"][year]/Cap\n",
    "           # print (dtype,det,year,cap,Data[dtype][det][year] )\n",
    "            if cap > 1:\n",
    "                Data[dtype][det][year] /=cap\n",
    "        #print (dtype,det,2035,cap,Data[dtype][det][2035] )\n",
    "\n",
    "\n",
    "# # Make a total across detectors\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "dtypes = [\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]\n",
    "\n",
    "\n",
    "\n",
    "for dtype in dtypes:\n",
    "    Data[dtype][\"Total\"] ={}\n",
    "    \n",
    "        \n",
    "    for year in Years:\n",
    "        Data[dtype][\"Total\"][year] = 0.0\n",
    "    for det in Inputs.keys():\n",
    "        #if dtype != \"Analysis\":  # not certain what this does... I think it is leftover. \n",
    "        for year in Years:\n",
    "            Data[dtype][\"Total\"][year]+=  Data[dtype][det][year] \n",
    "    \n",
    "             \n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Raw-Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\",\"Reco-Data-GPU\",\"Sim-GPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "ToCSV2(shortname+\"-Reco-Data-GPU\",\"Reco-Data-GPU\",PlotYears,Data,Units,Formats)\n",
    "ToCSV2(shortname+\"-Sim-GPU\",\"Sim-GPU\",PlotYears,Data,Units,Formats)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "PlotYears = []\n",
    "for i in range(MinYear,MaxYear+1):\n",
    "    PlotYears.append(i)\n",
    "#PlotYears = Years\n",
    "print (\"PlotYears\",PlotYears)\n",
    "# draw things\n",
    "things = list(Inputs.keys())+[\"Total\"]\n",
    "\n",
    "print (Inputs.keys())\n",
    "other = list(Inputs[\"ND-SAND\"].keys())+[\"Total\"]\n",
    "\n",
    "print (other)\n",
    "\n",
    "\n",
    "if DRAW:\n",
    "    for stuff in [\"Raw-Events\",\"Test\",\"Sim-Events\",\"Raw-Store\",\"Reco-Data-Store\",\"Sim-Store\",\"Reco-Data-CPU\",\"Sim-CPU\",\"Analysis-CPU\"]:\n",
    "        DrawDet(shortname,stuff,PlotYears,Data,things,Units,DetColors,DetLines)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# merge protodune info\n",
    "\n",
    "if DEBUG: print (\"Data keys\",Data.keys())\n",
    "\n",
    "for dtype in Data.keys():\n",
    "    if DEBUG: print (\"Merge protodunes\",dtype)\n",
    "    det = \"PDs\" \n",
    "    Data[dtype][det] = {}\n",
    "    for year in Years:  \n",
    "        Data[dtype][det][year] = Data[dtype][\"SP\"][year] + Data[dtype][\"DP\"][year] + Data[dtype][\"PDHD\"][year] + Data[dtype][\"PDVD\"][year]\n",
    "\n",
    "    Data[dtype].pop(\"SP\")\n",
    "    Data[dtype].pop(\"PDHD\")\n",
    "    Data[dtype].pop(\"DP\")\n",
    "    Data[dtype].pop(\"PDVD\")\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# merge far detector into \"FDs\n",
    "if \"HD\" in Detectors and \"VD\" in Detectors:\n",
    "    for dtype in Data.keys():\n",
    "        det = \"FDs\"\n",
    "        print (\"merge FDS\",dtype)\n",
    "        Data[dtype][det] =  {}\n",
    "        for year in Years:  \n",
    "            Data[dtype][det][year] = Data[dtype][\"HD\"][year] + Data[dtype][\"VD\"][year]\n",
    "        Data[dtype].pop(\"HD\")\n",
    "        Data[dtype].pop(\"VD\")\n",
    "        \n",
    "# for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         Data[dtype][det] =  {}\n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] = 0\n",
    "        \n",
    "# for subdet in [\"Calib\",\"HighE\",\"LowE\",\"LBL\",\"Calib\",\"TP\"]:\n",
    "#     for dtype in Data.keys():\n",
    "#         det = \"FDs\"\n",
    "#         print (\"merge FDS\",dtype)\n",
    "        \n",
    "#         for year in Years:  \n",
    "#             Data[dtype][det][year] += Data[dtype][subdet][year] \n",
    "#         Data[dtype].pop(\"subdet\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a total CPU category\n",
    "\n",
    "Data[\"Total-CPU\"]={}\n",
    "\n",
    "for det in CombinedDetectors:\n",
    "    Data[\"Total-CPU\"][det] =  {}\n",
    "    for year in Years:\n",
    "        Data[\"Total-CPU\"][det][year] = Data[\"Reco-Data-CPU\"][det][year] + Data[\"Sim-CPU\"][det][year] + Data[\"Analysis-CPU\"][det][year]\n",
    "    #print(det,Data[\"Total-CPU\"][det])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make totals across categories. \n",
    "\n",
    "DataTypes = list(Data.keys())\n",
    "\n",
    "for dt in DataTypes:\n",
    "    Data[dt][\"Total\"] = {}\n",
    "    for year in Years:\n",
    "        Data[dt][\"Total\"][year]=0.0\n",
    "    for k in Data[dt].keys():\n",
    "        if k == \"Total\":\n",
    "          continue  \n",
    "        for year in Years:\n",
    "            Data[dt][\"Total\"][year] += Data[dt][k][year]\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# and make a special data type for cores\n",
    "\n",
    "Data[\"Cores\"] = {}\n",
    "Data[\"HS23\"] = {}\n",
    "Data[\"Wall\"] = {}\n",
    " \n",
    "MHrsPerYear = 1000000/365./24.\n",
    "print (\"MHrsPerYear\",MHrsPerYear)\n",
    "print (\"total-CPU keys\",Data[\"Total-CPU\"].keys())\n",
    "for k in Data[\"Total-CPU\"].keys():\n",
    "#     if \"MARS\" not in k :\n",
    "#         efficiency = config[\"Cores\"][\"Efficiency\"]\n",
    "#     else:\n",
    "#         efficiency = 1\n",
    "\n",
    "    scaleTo2020 = config[\"Cores\"][\"2020Units\"]\n",
    "    Data[\"Cores\"][k]={}\n",
    "    Data[\"Wall\"][k]={}\n",
    "    Data[\"HS23\"][k]={}\n",
    "#    Data[\"WALL\"][k]={}\n",
    "    for year in Years:\n",
    "        Data[\"Wall\"][k][year] = Data[\"Total-CPU\"][k][year]/scaleTo2020/efficiency\n",
    "        Data[\"Cores\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency\n",
    "        Data[\"HS23\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/scaleTo2020/efficiency*config[\"kHEPSPEC06PerCPU\"]\n",
    "#        Data[\"WALL\"][k][year] = Data[\"Total-CPU\"][k][year]*MHrsPerYear/efficiency/scaleTo2020\n",
    "\n",
    "\n",
    "# # Yearly info:\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"] \n",
    "if DRAW:\n",
    "    DrawDet(shortname+\"_byyear\",\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines)#,cpuactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines)#,coreactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "    DrawDet(shortname+\"_byyear\",\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines)#,wallactual)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#  for Storage work out split between different institutions\n",
    "\n",
    "Splits = {}\n",
    "for f in SplitsEarly:\n",
    "    Splits[f] = {}\n",
    "    for t in SplitsEarly[f]:\n",
    "        Splits[f][t] = {}\n",
    "        for loc in SplitsEarly[f][t]: \n",
    "            Splits[f][t][loc] = {}\n",
    "            #print (f,t,Splits[f][t],Splits[f][t][0])\n",
    "    \n",
    "            for y in Years:\n",
    "                if y < SplitsYear:\n",
    "                    Splits[f][t][loc][y]=SplitsEarly[f][t][loc]\n",
    "                else:\n",
    "                    Splits[f][t][loc][y]=SplitsLater[f][t][loc]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "if DEBUG: print (Splits[\"CPU\"])\n",
    "\n",
    "for key in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]: \n",
    "    \n",
    "    for site in [\"FNAL\",\"CERN\",\"Global\"]:\n",
    "        Data[key][site] = {}\n",
    "        for year in Years:\n",
    "            \n",
    "            Data[key][site][year] = Data[key][\"Total\"][year]*Splits[\"CPU\"][\"CPU\"][site][year]\n",
    "            \n",
    "\n",
    "\n",
    "# # here is where we start doing cumulation across years for disk and reconstruction\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# now do some Cumulative-work.  Stuff stays on tape/disk for different amounts of time and we have multiple copies\n",
    "\n",
    "Storage = {}\n",
    "for k in StorageTypes:\n",
    "    Storage[k] = {}\n",
    "Storage[\"Total\"] = {}\n",
    "Storage[\"Global\"] = {}\n",
    "Storage[\"FNAL\"] = {}\n",
    "Storage[\"CERN\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Total\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"FNAL\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"CERN\"][\"Cumulative-Disk\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Tape\"] = {}\n",
    "Storage[\"Global\"][\"Cumulative-Disk\"] = {}\n",
    "\n",
    "\n",
    "for year in Years:\n",
    "    Storage[\"Total\"][\"Cumulative-Tape\"][year] = 0.0\n",
    "    Storage[\"Total\"][\"Cumulative-Disk\"][year] = 0.0\n",
    "\n",
    "for k in StorageTypes:\n",
    "    Storage[k][\"Tape\"] = {}\n",
    "    Storage[k][\"Disk\"] = {}\n",
    "    for year in Years:\n",
    "        Storage[k][\"Tape\"][year] = Data[k][\"Total\"][year]*TapeCopies[k]\n",
    "        Storage[k][\"Disk\"][year] = Data[k][\"Total\"][year]*DiskCopies[k]\n",
    "    # extend disk for Analysis HMS 6-24-2023\n",
    "    #Storage[k][\"Disk\"]  = extendMap(Years,Storage[k][\"Disk\"],AnalysisExtend) \n",
    "    \n",
    "    Storage[k][\"Cumulative-Tape\"] = cumulateMap(Years,Storage[k][\"Tape\"],TapeLifetimes[k])\n",
    "    Extend = cumulateMap(Years,Storage[k][\"Disk\"],DiskLifetimes[k])\n",
    "    if k != \"Test\": \n",
    "        Storage[k][\"Cumulative-Disk\"] = extendMap(Years,Extend,AnalysisExtend,k)\n",
    "    else:\n",
    "        Storage[k][\"Cumulative-Disk\"] = Extend\n",
    "    \n",
    "    for year in Years:\n",
    "        Storage[\"Total\"][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]\n",
    "        Storage[\"Total\"][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]\n",
    "    \n",
    "    \n",
    "        \n",
    "for loc in Splits[\"Disk\"][\"Raw-Store\"]:\n",
    "    for year in Years:\n",
    "        Storage[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "        Storage[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "        for k in StorageTypes:\n",
    "              Storage[loc][\"Cumulative-Disk\"][year] += Storage[k][\"Cumulative-Disk\"][year]*Splits[\"Disk\"][k][loc][year]\n",
    "              Storage[loc][\"Cumulative-Tape\"][year] += Storage[k][\"Cumulative-Tape\"][year]*Splits[\"Tape\"][k][loc][year]\n",
    "\n",
    "\n",
    "# cdisk = SumOver1(\"Cumulative-Disk\",Data)\n",
    "# print (\"sum over\",cdisk)\n",
    "\n",
    "# for year in Years:\n",
    "#         Data[loc][\"Cumulative-Disk\"][year] = 0.0\n",
    "#         Data[loc][\"Cumulative-Tape\"][year] = 0.0       \n",
    "#         for k in StorageTypes:\n",
    "#               Data[loc][\"Cumulative-Disk\"][year] += Data[k][\"Cumulative-Disk\"][year] \n",
    "#               Data[loc][\"Cumulative-Tape\"][year] += Data[k][\"Cumulative-Tape\"][year] \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "texfile.write(\"\\\\section{Projected Disk and Tape needs by source and site}\\n\")\n",
    "#ToCSV1(shortname+\"-Disk_by_location\",\"Cumulative-Disk\",PlotYears,Storage,Units,Formats)\n",
    "#ToCSV1(shortname+\"-Tape_by_location\",\"Cumulative-Tape\",PlotYears,Storage,Units,Formats)\n",
    "# s = \"\\\\begin{table}[h]\\n \\\\centering\\\\csvautotabularright\\\n",
    "# {external/DUNERSEUSAGE-2022-11-14.csv}\\n \\\\label{Cumulative-Tape}\\n\\\n",
    "# \\\\caption{Rucio report on storage usage 2022-11-14 from the Scotgrid Dashboard \\\n",
    "# \\\\href{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}{https://dune.monitoring.edi.scotgrid.ac.uk/app/dashboards}.}\\n \\\\end{table}\\n\"\n",
    "# s.replace(\"_\",\"\\_\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# s = TableTex(shortname+\"-Disk_by_location\",\"Disk requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Disk\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "# s = TableTex(shortname+\"-Tape_by_location\",\"Tape requests by location. The top 4 lines show the source, the bottom 4 show the locations requested and the total request.\",\"Cumulative-Tape\"+\"\\n\")\n",
    "# texfile.write(s)\n",
    "\n",
    "# texfile.write(\"\\\\clearpage\\n\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# now do some plots\n",
    "\n",
    "Types = CombinedDetectors+[\"Analysis\",\"Total\"]\n",
    "\n",
    "cpuactual = []\n",
    "coreactual = []\n",
    "wallactual = []\n",
    "\n",
    "Sites = [\"FNAL\",\"CERN\",\"Global\",\"Total\"]\n",
    "\n",
    "if DRAW:\n",
    "    DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Types,Units,DetColors,DetLines,cpuactual)\n",
    "    DrawDet(shortname,\"Cores\",PlotYears,Data,Types,Units,DetColors,DetLines,coreactual)\n",
    "    DrawDet(shortname,\"Wall\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "    DrawDet(shortname,\"HS23\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "# DrawDet(shortname,\"Total-CPU\",PlotYears,Data,Sites,Units,DetColors,DetLines,cpuactual)\n",
    "# DrawDet(shortname,\"Cores\",PlotYears,Data,Sites,Units,DetColors,DetLines,coreactual)\n",
    "# #DrawDet(shortname,\"WALL\",PlotYears,Data,Types,Units,DetColors,DetLines,wallactual)\n",
    "# DrawDet(shortname,\"HS23\",PlotYears,Data,Sites,Units,DetColors,DetLines,wallactual)\n",
    "\n",
    "\n",
    "\n",
    "for x in [\"Total-CPU\",\"Cores\",\"HS23\",\"Wall\"]:\n",
    "    ToCSV2(shortname+\"-\"+x,x,PlotYears,Data,Units,Formats)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Captions2 = {\"Raw-Events\":\"Projected million of detector events per year.  Reconstructed data resources are based on this number.\",\n",
    "\"Test\":\"Projected PB of Test data per year.\",\n",
    "\"Sim-Events\":\"Projected millions of simulated events per year. Simulated data resources are based on this number. \",\n",
    "\"Raw-Store\":\"Projected raw data written per year in PB, derived from the number of events.\",\n",
    "\"Reco-Data-CPU\":\"Projected CPU needs in core-hrs for data reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction.  Assumes rereconstruction of several years of older data.\",\n",
    "\"Sim-CPU\":\"Projected CPU needs in core-hrs for simulation and reconstruction. \\\n",
    "             Slot weighted wall time takes into account memory use and an efficiency correction. Based directly on the number of simulated Events.\",\n",
    "\"Reco-Data-Store\":\"Projected PB of reconstructed data per year. Includes reprocessing.\",\n",
    "\"Sim-Store\":\"Projected PB of simulated data/year\",\n",
    "\"Total-CPU\":\"Slot weighted CPU needs in core-years. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Cores\":\"Slot weighted CPU needs in number of cores. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"HS23\":\"Slot weighted CPU needs in kHS23 hrs. Slot weighted wall time takes into account memory and efficiency.\",\n",
    "\"Analysis-CPU\":\"Slot weighted analysis CPU needs in core-hrs. Assumed to be a weighted fraction of reco+sim needs.\",\n",
    "            }\n",
    "print (Data[\"Raw-Events\"][\"PDs\"])\n",
    "#print (Data[\"Raw-Events\"][\"FDs\"])\n",
    "print (Data[\"Raw-Events\"][\"ND-SAND\"])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# for key in [\"Cores\",\"Total-CPU\",\"HS23\"]:\n",
    "#     print (\"Got to Here\")\n",
    "#     if not key in Units:\n",
    "#         print (\"no units for key\",key)\n",
    "#         continue\n",
    "#     ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "#     s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "#     #DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "#     #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     print  (\"Got to here\")\n",
    "#     s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "#     #texfile.write(s2)\n",
    "#     tablefile.write(s2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print (Storage.keys())\n",
    "    \n",
    "Captions1 = {\"Cumulative-Tape\":\"Cumulative Tape needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\", \n",
    "             \"Cumulative-Disk\":\"Cumulative Disk needs in PB. Includes multiple copies and data lifetimes.\\\n",
    " The top 4 lines show the source of the data while the last four propose responsibilities.\",\n",
    "            \"HS23\":\"CPU needs in HS23 units\"}\n",
    "            \n",
    "\n",
    "for key in ['Cumulative-Tape', 'Cumulative-Disk']:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    # actual = None\n",
    "    # if key == \"Cumulative-Tape\":\n",
    "    #     actual = tapeactual\n",
    "    # if key == \"Cumulative-Disk\":\n",
    "    #     actual = diskactual\n",
    "    # print (actual)\n",
    "    ToCSV1(shortname+\"-\"+key,key,PlotYears,Storage,Units,Formats)\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Source\",key,PlotYears,Storage,Units,Formats,['Raw-Store', 'Test', 'Reco-Data-Store', 'Sim-Store', 'Total'])\n",
    "    ToCSV1(shortname+\"-\"+key+\"-Request\",key,PlotYears,Storage,Units,Formats,['Global', 'FNAL', 'CERN', 'Total'])\n",
    "    s = TableTex(shortname+\"-\"+key,Captions1[key],key+\"\\n\")\n",
    "    print (key,s)\n",
    "    dunestyle.Preliminary()\n",
    "    DrawType(shortname,key,PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    " \n",
    "    s2 = BothTex(shortname,key+\".png\",Captions1[key],key)\n",
    "\n",
    "    #texfile.write(s2)\n",
    "    texfile.write(s2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print (Types)\n",
    "\n",
    "for key in Types:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "\n",
    "for key in Sites:\n",
    "    if not key in Units:\n",
    "        print (\"no units for key\",key)\n",
    "        continue\n",
    "    ToCSV2(shortname+\"-\"+key,key,PlotYears,Data,Units,Formats)\n",
    "    s = TableTex(shortname+\"-\"+key,Captions2[key],key+\"\\n\")\n",
    "    DrawDet(shortname,key,PlotYears,Data,list(Data[key].keys()),Units,DetColors,DetLines)\n",
    "    #s2 = DrawTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    s2 = BothTex(shortname,key+\".png\",Captions2[key],key)\n",
    "    #texfile.write(s2)\n",
    "    tablefile.write(s2)\n",
    "        \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "tapepoints = np.zeros(len(Years))\n",
    "diskpoints = np.zeros(len(Years))\n",
    "\n",
    "#DrawType(shortname,\"Tape\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Tape\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",PlotYears,Storage,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "#DrawType(shortname,\"Cumulative-Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines,None,None)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "tablefile.close()\n",
    "#texfile.write(\"\\\\input{bibmaker.tex}\\n\")\n",
    "#texfile.write(\"\\\\clearpage\\n\")\n",
    "#texfile.write(\"\\\\section{Appendix - Model inputs}\\n\")\n",
    "#texfile.write(\"\\\\input{\"+dirname+\"/tables.tex}\\n\")\n",
    "#texfile.write(\"\\\\end{document}\\n\")\n",
    "texfile.close()\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# make a set of request numbers to add to the tex file - they need to have tex compatible nicknames\n",
    "\n",
    "macro = open(shortname+\"_macros.tex\",'w')\n",
    "\n",
    "command = makeParameter(\"HS23Request\",\"%10.0f\"%(Data[\"HS23\"][\"Total\"][RequestYear]))\n",
    "print (\"tex command\", command,Data[\"HS23\"][\"Total\"][RequestYear])\n",
    "\n",
    "Requests = {}\n",
    "Requests[\"CPU\"]=\"HS23\"\n",
    "Requests[\"CORES\"]=\"Cores\"\n",
    "\n",
    "Requests[\"DISK\"]=\"Cumulative-Disk\"\n",
    "Requests[\"TAPE\"]=\"Cumulative-Tape\"\n",
    "\n",
    "m = makeParameter(\"ThisYear\",\"%d\"%RequestYear)\n",
    "macro.write(m+\"\\n\")\n",
    "\n",
    "for y in Requests:\n",
    "    for x in Sites:\n",
    "        name = (\"%s%s\"%(y,x)).replace(\"-\",\"\")\n",
    "        if y == \"CPU\" or y == \"CORES\":\n",
    "            if y == \"CPU\": \n",
    "                m = makeParameter(name,\"%10.1f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "            else: \n",
    "                m = makeParameter(name,\"%10.0f\"%(Data[Requests[y]][x][RequestYear]))\n",
    "        else:\n",
    "            m = makeParameter(name,\"%10.1f\"%(Storage[x][Requests[y]][RequestYear]))\n",
    "        macro.write(m+\"\\n\")\n",
    "macro.close()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "jname = configfilename.replace(\".json\",\"_internal.json\")\n",
    "jj = open(jname,'w')\n",
    "commentjson.dump(Data,jj,indent=4)\n",
    "jj.close()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#cmd='pdflatex MoreSim_2023-06-22-2040.tex'\n",
    "#get_ipython().system('{cmd}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
