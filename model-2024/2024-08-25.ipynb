{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61957124-7283-4238-8c04-84c8c2be685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(sys.executable)\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28567446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c0fd7b",
   "metadata": {},
   "source": [
    "\n",
    "Code to generate yearly summaries of DUNE data volumes from input parameters\n",
    "\n",
    "Complete rewrite of data structures to allow selection of any subsample\n",
    "\n",
    "HMS 2024-08-11\n",
    "\n",
    "If you have json problems, run the program ../strip.py on your json file to take off comments and then test using https://jsonlint.com\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481973c9-a71e-4064-a7e2-9f736e67ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DRAW = \".py\" not in sys.argv[0] # only draw if in notebook - otherwise write to file\n",
    "import os,commentjson\n",
    "from csv import reader\n",
    "import json\n",
    "import numpy as np\n",
    "import dunestyle.matplotlib as dunestyle\n",
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n",
    "from NumberUtils import cumulateMap\n",
    "from NumberUtils import DrawDet\n",
    "from NumberUtils import DrawType\n",
    "from NumberUtils import makeArray\n",
    "from NumberUtils import ToCSV1\n",
    "from NumberUtils import ToCSV2\n",
    "#from NumberUtils import SumOver1\n",
    "#from NumberUtils import SumOver2\n",
    "from NumberUtils import TableTex\n",
    "from NumberUtils import BothTex\n",
    "from NumberUtils import extendMap\n",
    "from NumberUtils import makeParameter\n",
    "from DataHolder import DataHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c3326-7195-446a-8ca5-a432412c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many histograms to draw in multi-hist plots\n",
    "N_HISTS = 8   # exhibits all the colors in the Okabe-Ito cycler\n",
    "\n",
    "# specify the json file here.  Will create a subdirectory for plots with a similar name\n",
    "\n",
    "configfilename = \"NearTerm_2024-08-14-2040.json\"\n",
    "if len(sys.argv) > 1 and sys.argv[1] == \"old\":\n",
    "    configfilename = \"Feb24.json\"\n",
    "print (configfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0efc9-6b66-4fcf-9725-b4a2bc229aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "theshortname = configfilename.replace(\".json\",\"\")\n",
    "if os.path.exists(configfilename):\n",
    "    with open(configfilename,'r') as f:\n",
    "        config = commentjson.load(f)\n",
    "        print (\"config file\",configfilename,\"found\")\n",
    "else:\n",
    "    print (\"no config file\",configfilename)\n",
    "    sys.exit(0)\n",
    "\n",
    "if not \"Version\" in config or config[\"Version\"] < 20:\n",
    "    print (\" this code expects Version >= 20\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32240021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MWCWeight = config[\"MWCWeight\"] # do we weight cores by available memory? \n",
    "MaxYear = config[\"MaxYear\"]\n",
    "MWCstring = \"_noMWC\"\n",
    "if MWCWeight: \n",
    "    print (\"MWC no longer enabled, ignore\")\n",
    "    MWCstring=\"\"\n",
    "config[\"filename\"] = configfilename\n",
    "TEST = config[\"Test\"]\n",
    "MinYear = config[\"MinYear\"]\n",
    "Detectors = config[\"Detectors\"]\n",
    "DataTypes = config[\"DataTypes\"]\n",
    "NativeTypes = config[\"NativeTypes\"]\n",
    "if TEST:\n",
    "    Detectors = config[\"TestDetectors\"]\n",
    "    DataTypes = config[\"TestTypes\"]\n",
    "    if \"TP\" not in DataTypes and \"TP\" in NativeTypes:\n",
    "        NativeTypes.remove(\"TP\")\n",
    "    \n",
    "Years = config[\"Years\"]\n",
    "\n",
    "shortname = theshortname.replace(\"2040\",\"%d\"%MaxYear)+MWCstring\n",
    "dirname = shortname\n",
    "if not os.path.exists(dirname):\n",
    "    os.mkdir(dirname)\n",
    "shortname = os.path.join(dirname,dirname)\n",
    "# make a tex output file\n",
    "texfilename = os.path.join(dirname,dirname+\".tex\")\n",
    "texfile = open(texfilename,'w')\n",
    "tablefile = open(os.path.join(dirname,\"tables.tex\"),'w')\n",
    "texfile.write(\"\\\\input{../Header.tex}\\n\")\n",
    "\n",
    "size = len(Years)\n",
    "Units = config[\"Units\"]\n",
    "BaseUnits = config[\"BaseUnits\"]\n",
    "RequestYear=2024\n",
    "if \"RequestYear\" in config:\n",
    "    RequestYear= config[\"RequestYear\"]\n",
    "        \n",
    "Formats = config[\"Formats\"]\n",
    "Resources = config[\"Resources\"]\n",
    "Locations = config[\"Locations\"]\n",
    "PlotDetectors = Detectors+[\"Total\"]\n",
    "PlotDataTypes = DataTypes+[\"Total\"]\n",
    "PlotLocations = Locations+[\"Total\"]\n",
    "Scales = config[\"Scales\"]\n",
    "Cap = config[\"Cap\"]\n",
    "CapInTB = Cap*1000\n",
    "\n",
    "BaseMemory = config[\"Base-Memory\"]\n",
    "Splits= config[\"Splits\"]\n",
    "PDlist = config[\"PDlist\"]\n",
    "FDlist = config[\"FDlist\"]\n",
    "NDlist = config[\"NDlist\"]\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "print (\"Parameters\",DetectorParameters)\n",
    "\n",
    "if \"Comment\" in DetectorParameters:\n",
    "    DetectorParameters.remove(\"Comment\")\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "# this is how far you go back each time you reprocess reco.\n",
    "\n",
    "Reprocess = config[\"Reprocess\"]\n",
    "AnalysisExtend = config[\"AnalysisExtend\"]\n",
    "PerYear = config[\"PerYear\"]\n",
    "Slots = config[\"Slots\"]\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "#TypeColors=config[\"TypeColors\"]\n",
    "#TypeLines = config[\"TypeLines\"]\n",
    "\n",
    "#PatternFraction = config[\"PatternFraction\"]\n",
    "Explain = config[\"Explain\"]\n",
    "Explain[\"filename\"] = \"Input configuration file\"\n",
    "\n",
    "if DEBUG:\n",
    "    for i in config.keys():\n",
    "        if i not in Explain.keys():\n",
    "            print (\"Still need to explain\",i)\n",
    "\n",
    "for f in Explain.keys():\n",
    "    field = \"{\\\\tt %s:} %s = {\\\\tt %s} \\\\\\\\\\n\"%(f,Explain[f], config[f])\n",
    "    field = field.replace(\"_\",\"\\_\")\n",
    "    tablefile.write(field)\n",
    "    print (f, Explain[f], config[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97139b-4e67-4b07-8f8a-7e3af22bac46",
   "metadata": {},
   "source": [
    "## Make data container (holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b76549-5360-44f1-9230-a30bc041f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holder = DataHolder(theconfig=config,debug=DEBUG)\n",
    "holder.readTimeline()\n",
    "holder.showPlot = DRAW\n",
    "csvname = configfilename.replace(\".json\",\"_inputs.csv\")\n",
    "csvData = holder.csvDump(dirname,csvname)\n",
    "\n",
    "holder.jsonDump(dirname,configfilename.replace(\".json\",\"_safe.json\"))\n",
    "\n",
    "holder.debug=DEBUG\n",
    "\n",
    "if DEBUG: (\"Detector Parameters\",DetectorParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af1c79-65d5-445c-bcdb-f2ed18f2a7b2",
   "metadata": {},
   "source": [
    "# Change input (NativeTypes) into storage numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed3da6-f8c7-4754-a5ec-82736e78b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in other useful arrays\n",
    "\n",
    "holder.debug=DEBUG\n",
    "print (\"--------------- raw-storage ------------------\")\n",
    "print (\"NativeTypes\",NativeTypes)\n",
    "for detector in Detectors:\n",
    "    # first raw data events which have to be stored. \n",
    "    # Make \"input\" locations in to \"Store\" scaled by config[detector][type]\n",
    "    for olddatatype in config[\"NativeTypes\"]:\n",
    "        oldunits = Scales[olddatatype]\n",
    "        oldresource = \"input\"\n",
    "        newresource = \"Store\"\n",
    "        location = \"Total\"\n",
    "                 \n",
    "        if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "            if DEBUG: holder.printByTag(holder.tag(detector,olddatatype,oldresource,location,oldunits))\n",
    "            factor = 1\n",
    "            if olddatatype == \"Raw-Events\":\n",
    "                newdatatype = \"Raw-Data\"\n",
    "                factor = config[detector][\"Raw-Data-Store\"]\n",
    "                newunits = Scales[\"Raw-Data-Store\"]\n",
    "            else:\n",
    "                newdatatype = olddatatype\n",
    "                newunits = oldunits\n",
    "            # TP and Test are already in units of GB\n",
    "            if DEBUG: print (\"storage\",detector,olddatatype,newresource,location,newunits,factor)\n",
    "            newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":newdatatype,\"Resources\":newresource,\"Units\":newunits},factor,explanation=\"Change native types into storage using factor %.2f\"%factor)\n",
    "            if DEBUG: holder.printByTag(newtag)\n",
    "        else:\n",
    "            if DEBUG: print (\"could not find\", detector,olddatatype,oldresource,location,oldunits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ce56d-3ded-4778-978f-3ef2fef2b8cf",
   "metadata": {},
   "source": [
    "# calculate size of raw data coming from Far detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f688cf4-1b0d-4dce-9075-a80d5417bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complicated way of doing double sum  \n",
    "print (\"----------------------------- draw real data -----------------------\")\n",
    "RealDataTypes=[\"Raw-Data\",\"TP\",\"Test\"]\n",
    "FarDetectors = [\"FDHD\",\"FDVD\"]\n",
    "realsubset={\"Detectors\":FarDetectors,\"DataTypes\":RealDataTypes,\"Resources\":[\"Store\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "explanation = \"Sum over raw data types from Far detector\"\n",
    "realDataTotalDetector=holder.sumAcrossFilters(\n",
    "    filter=realsubset,sumCat=\"Detectors\",sumName=\"Sub-Total\",\n",
    "    explanation=explanation)\n",
    "\n",
    "realsubset2={\"Detectors\":FarDetectors+[\"Sub-Total\"],\n",
    "             \"DataTypes\":RealDataTypes,\"Resources\":[\"Store\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "realDataTotalDetectorStore=holder.sumAcrossFilters(\n",
    "    filter=realsubset2,sumCat=\"DataTypes\",sumName=\"Sub-Total\",\n",
    "    explanation=\"second sum over raw types\")\n",
    "    \n",
    "newsubset={\"Detectors\":([\"Sub-Total\"]),\n",
    "           \"DataTypes\":RealDataTypes+[\"Sub-Total\"],\n",
    "           \"Resources\":[\"Store\"],\n",
    "           \"Locations\":[\"Total\"],\n",
    "           \"Units\":[\"TB\"]}\n",
    "\n",
    "fig= holder.Draw(dirname,Title=\"RealData\",YAxis=\"Storage\",\n",
    "            Resource=\"Store\",Category=\"DataTypes\",filter=newsubset)\n",
    "texfile.write(holder.TexFigure(fig,\"Real data create/year in TB\",label=\"realdata\"))\n",
    "holder.csvDump(dirname,\"realData.csv\")\n",
    "\n",
    "holder.debug = DEBUG\n",
    "\n",
    "holder.csvDump(dirname,dirname+\"after-raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae2ae7",
   "metadata": {},
   "source": [
    "## special section to impose the cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b60e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale everything year by year so it meets the cap\n",
    "DEBUG=True\n",
    "subtotaltag  = holder.tag(\"Sub-Total\",\"Sub-Total\",\"Store\",\"Total\",\"TB\")\n",
    "print (subtotaltag)\n",
    "\n",
    "subtotal = holder.holder[subtotaltag]\n",
    "factors = {}\n",
    "for year in Years:\n",
    "    if subtotal[year] > CapInTB:\n",
    "        factors[year] = CapInTB/subtotal[year]\n",
    "    else:\n",
    "        factors[year] = 1.0\n",
    "\n",
    "if DEBUG: print (\"Cap scaling factor\", factors)\n",
    "\n",
    "\n",
    "toRescale = {\"Detectors\":FarDetectors+[\"Sub-Total\"],\n",
    "             \"DataTypes\":RealDataTypes+[\"Sub-Total\"],\n",
    "             \"Resources\":[\"Store\",\"input\"],\n",
    "             \"Locations\":[\"Total\"],\n",
    "             \"Units\":[\"TB\",\"Million\"]\n",
    "             }\n",
    "\n",
    "tagsToRescale=holder.makeTagSet(toRescale)\n",
    "\n",
    "for tag in tagsToRescale:\n",
    "    modified = False\n",
    "    # att = holder.tagToDict(tag)\n",
    "    # if DEBUG: print (\"Check\", att)\n",
    "    # if att[\"Detectors\"] in FarDetectors and att[\"DataTypes\"] in RealDataTypes+[\"Raw-Events\"]:\n",
    "\n",
    "    if DEBUG: holder.printByTag(tag)\n",
    "    for year in Years:\n",
    "        if factors[year] < 1.0:\n",
    "            holder.holder[tag][year] *= factors[year]\n",
    "            modified = True\n",
    "    if modified:\n",
    "        print (\"Rescale to fit cap of %d PB \"%Cap)\n",
    "        holder.explanation[tag] += \" rescaled to meet cap of %d\"%Cap\n",
    "    if DEBUG: holder.printByTag(tag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#holder.sumAcrossAll(filter=to,sumName=\"Sub-Total\",explanation=\"Rescaled after cap\")\n",
    "\n",
    "drawfilter= {\"Detectors\":[\"Sub-Total\"],\n",
    "             \"DataTypes\":RealDataTypes+[\"Sub-Total\"],\n",
    "             \"Resources\":[\"Store\"],\n",
    "             \"Locations\":[\"Total\"],\n",
    "             \"Units\":[\"TB\"]\n",
    "             }\n",
    "\n",
    "DEBUG=False\n",
    "\n",
    "holder.csvDump(dirname,\"aftercap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124cac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= holder.Draw(dirname,Title=\"Real Data after scaling to cap of %d PB.\"%Cap,YAxis=\"Storage\",\n",
    "            Resource=\"Store\",Category=\"DataTypes\",filter=drawfilter)\n",
    "texfile.write(holder.TexFigure(fig,\"Real data created/year in TB, after scaling to cap of %d PB.  All data types are scaled by the same factor. \"%Cap,label=\"realdataCapped\"))\n",
    "holder.csvDump(dirname,\"realDataCapped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53069e-15ad-48b5-9df7-68e07ff01dbd",
   "metadata": {},
   "source": [
    "# extend events for Reco and calculate storage/CPU/GPU per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f6f88-38c9-4de5-b4d6-8f635298b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  transform Events into CPU estimates  ------------------\") \n",
    "for detector in Detectors:\n",
    "    for newdatatype in [\"Reco-Data\",\"Reco-Sim\"]:\n",
    "        oldresource = \"input\"\n",
    "\n",
    "        if newdatatype == \"Reco-Data\": \n",
    "            olddatatype = \"Raw-Events\"\n",
    "\n",
    "        if newdatatype == \"Reco-Sim\":\n",
    "            olddatatype = \"Sim-Events\"\n",
    "\n",
    "        oldunits = Scales[olddatatype]\n",
    "        location = \"Total\"\n",
    "\n",
    "        # Reco gets reprocessed so has a special cumulation\n",
    "\n",
    "        for resource in [\"CPU\",\"GPU\",\"Store\"]:\n",
    "            newunits = Scales[newdatatype+\"-\"+resource]    \n",
    "            if holder.hasTag(detector,olddatatype,oldresource,location,oldunits):\n",
    "                if DEBUG: holder.printByTag(\n",
    "                    holder.tag(detector,olddatatype,oldresource,location,oldunits))                 \n",
    "                if DEBUG: print (\"--before Events->Things\",olddatatype,resource)\n",
    "                newunits = Scales[newdatatype+\"-\"+resource]\n",
    "                factor = config[detector][newdatatype + \"-\" +resource]*PerYear[newdatatype+\"-\"+resource]\n",
    "                if DEBUG: print (\"factor\",detector,newdatatype,resource,factor)\n",
    "                thedatatype = newdatatype\n",
    "                newtag = holder.scale(detector,olddatatype,oldresource,location,oldunits,{\"DataTypes\":thedatatype,\"Resources\":resource,\"Units\":newunits},factor,explanation=\"Scale inputs by %.2f\"%factor)\n",
    "                if DEBUG: holder.printByTag(newtag)\n",
    "                if DEBUG: print (\"--after Events->Things\",newdatatype,resource)\n",
    "\n",
    "                # special to say you redo previous Reprocess years of reco every year.\n",
    "                if thedatatype == \"Reco-Data\":  \n",
    "                    newtag = holder.cumulateMe(detector,newdatatype,resource,\n",
    "                                               location,newunits,{\"DataTypes\":\"Reco-Data\"},\n",
    "                                               Reprocess[detector],\n",
    "                                               explanation=\"Go back %.2f years for Reco-Data\"%(Reprocess[detector])) \n",
    "                    \n",
    "                if DEBUG: holder.printByTag(newtag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ed50b",
   "metadata": {},
   "source": [
    "# calculate analysis based on scaling of data/sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bf389-a4d7-41db-87ea-22bdca06b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"---------------  make analysis ------------------\")\n",
    "for detector in Detectors:\n",
    "    for resource in [\"CPU\"]:   \n",
    "        location = \"Total\"\n",
    "        factor = config[detector][\"Analysis-CPU\"]*PerYear[\"Analysis-CPU\"]\n",
    "        recoAtag = holder.scale(detector,\"Reco-Data\",\n",
    "                                resource,location,Scales[\"Reco-Data-CPU\"],{\"DataTypes\":\"Analysis-Data\"},factor,\n",
    "                                explanation=\"Make Analysis using factor %.2f\"%factor)\n",
    "        simAtag = holder.scale(detector,\"Reco-Sim\",\n",
    "                               resource,location,Scales[\"Reco-Sim-CPU\"],{\"DataTypes\":\"Analysis-Sim\"},factor,\n",
    "                               explanation=\"Make Analysis using factor %.2f\"%factor)\n",
    "        if DEBUG: print (recoAtag)\n",
    "      \n",
    "        recoAtag = holder.extendMe(detector,\"Analysis-Data\",\n",
    "                                   resource,location,Scales[\"Reco-Data-CPU\"],{},AnalysisExtend,\n",
    "                                   explanation=\"Extend Analysis processing by %.2f years\"%AnalysisExtend)\n",
    "        simAtag = holder.extendMe(detector,\"Analysis-Sim\",\n",
    "                                  resource,location,Scales[\"Reco-Sim-CPU\"],{},AnalysisExtend,\n",
    "                                  explanation=\"Extend Analysis processing by %.2f years\"%AnalysisExtend)\n",
    "        if DEBUG: print (\"make analysis:\",recoAtag,simAtag)\n",
    "\n",
    "holder.csvDump(dirname,\"after-analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"---------------  make different CPU units ------------------\")\n",
    "\n",
    "MHrsPerYear = 1000000./365/24.\n",
    "for detector in Detectors:\n",
    "    for datatype in DataTypes:\n",
    "        for oldresource in [\"CPU\",\"GPU\"]:\n",
    "            oldunits = \"MHr\"\n",
    "            location = \"Total\"\n",
    "        \n",
    "            for newunit in [\"Wall\",\"kHS23-Yr\",\"Cores\"]:\n",
    "                \n",
    "                newresource = oldresource + \" \" + newunit\n",
    "                factor = 1./Slots[\"Efficiency\"]/Slots[\"2020Units\"]\n",
    "                \n",
    "                newunits = \"MHr\"\n",
    "                if newunit == \"kHS23-Yr\":\n",
    "                    factor *= config[\"kHEPSPEC06PerCPU\"]*MHrsPerYear\n",
    "                    newunits = \"kHS23-Yr\"\n",
    "                if newunit == \"Cores\":\n",
    "                    newunits = \"Cores\"\n",
    "                    factor *= MHrsPerYear\n",
    "                if DEBUG:\n",
    "                    print (newunit,newunits,factor)\n",
    "                newtag = holder.scale(detector,datatype,oldresource,location,oldunits,{\"DataTypes\":datatype,\"Resources\":newresource,\"Units\":newunits},factor,explanation=\"Add %.2f efficiency Change units from %s to %s using factor of %.2f\"%(Slots[\"Efficiency\"],oldunits,newunits,factor))\n",
    "                if newtag != None and DEBUG:\n",
    "                    print (newtag,holder.holder[newtag])\n",
    "              \n",
    "holder.csvDump(dirname,\"after-CPUscale.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436dd98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4badfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d75683",
   "metadata": {},
   "outputs": [],
   "source": [
    "holder.debug = DEBUG\n",
    "\n",
    "print(\"---------------------- sum across CPU ---------------------------------\")\n",
    "\n",
    "# filter on derived event types\n",
    "\n",
    "CPUTypes = [\"GPU\",\"CPU\",\"Total\",\"CPU Wall\",\"CPU kHS23-Yr\", \"CPU Cores\"] \n",
    "filter = {\"Detectors\":Detectors,\"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"],\"Resources\":CPUTypes,\"Locations\":[\"Total\"],\"Units\":Units}\n",
    "if DEBUG:\n",
    "    show = json.dumps(filter,indent=4)\n",
    "    print (show)\n",
    "\n",
    "CPUTotals=holder.sumAcrossFilters(filter=filter,sumCat=\"DataTypes\",\n",
    "                                  sumName=\"Total\",explanation=\"Sum processing across DataTypes\")\n",
    "\n",
    "filter2 = {\"Detectors\":Detectors,\n",
    "           \"DataTypes\":[\"Reco-Sim\",\"Reco-Data\",\"Analysis-Data\",\"Analysis-Sim\"]+[\"Total\"],\"Resources\":CPUTypes,\"Locations\":[\"Total\"],\"Units\":Units}\n",
    "\n",
    "#print (filter2)\n",
    "CPUTotalsAllDetectors=holder.sumAcrossFilters(\n",
    "    filter=filter2, sumCat=\"Detectors\",sumName= \"Total\",\n",
    "    explanation=\"Sum processing across Detectors\")\n",
    "#print (\"DataTypes\",DataTypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8856cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make filters and then draw\n",
    "print (\"draw CPU info\")\n",
    "\n",
    "CPUResources = [\"CPU\",\"CPU Wall\",\"CPU kHS23-Yr\", \"CPU Cores\"]\n",
    "CPUResourcesByDetector = {\"Detectors\":Detectors+[\"Total\"],\n",
    "                          \"DataTypes\":[\"Total\"],\"Resources\":CPUResources,\"Locations\":[\"Total\"],\"Units\":Units}\n",
    "CPUResourcesByType = {\"Detectors\":[\"Total\"],\n",
    "                      \"DataTypes\":DataTypes+[\"Total\"],\"Resources\":CPUResources,\"Locations\":[\"Total\"],\"Units\":Units}\n",
    "\n",
    "holder.storeFilter(filter=CPUResourcesByDetector,name=\"CPUResourcedByDetector\")\n",
    "holder.storeFilter(filter=CPUResourcesByType,name=\"CPUResourcesByType\")\n",
    "\n",
    "for resource in CPUResources:\n",
    "    fig = holder.Draw(Dir=dirname,Title=\"Processing by Type\",\n",
    "                YAxis=resource,Resource=resource,Category=\"DataTypes\",filter=CPUResourcesByType)\n",
    "    texfile.write(holder.TexFigure(fig,\"%s resources by data types by year.\"%resource,label=resource+\"_Types\"))\n",
    "    fig = holder.Draw(Dir=dirname,Title=\"Processing by Detector\",\n",
    "                YAxis=resource,Resource=resource,Category=\"Detectors\",filter=CPUResourcesByDetector)\n",
    "    texfile.write(holder.TexFigure(fig,\"%s resources by detector by year.\"%resource,label=resource+\"_Detectors\"))\n",
    "    \n",
    "holder.debug = DEBUG\n",
    "holder.csvDump(dirname,\"after-total2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c17cf0",
   "metadata": {},
   "source": [
    "# make tape and disk and them cumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------- change Store into Disk and Tape ---------------------------------\")\n",
    "\n",
    "oldresource = \"Store\"\n",
    "for detector in Detectors:\n",
    "    for datatype in DataTypes:\n",
    "        if datatype in holder.nosum:\n",
    "            continue\n",
    "        if datatype in [\"Raw-Events\",\"Sim-Events\"]: continue\n",
    "        for newresource in [\"Disk\",\"Tape\"]:\n",
    "            for locations in [\"Total\"]:\n",
    "                if newresource == \"Disk\": \n",
    "                    factor = DiskCopies[datatype]\n",
    "                if newresource == \"Tape\": \n",
    "                    factor = TapeCopies[datatype]\n",
    "                newtag = holder.scale(detector= detector,datatype=datatype,resource=oldresource,location=locations,units=\"TB\",categories={\"Resources\":newresource},factor=factor,explanation=\"Scale by number of copies, %.2f\"%factor)\n",
    "\n",
    "holder.csvDump(dirname,\"disk-tape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------- split disk and tape across sites ---------------------------------\")\n",
    "print (Detectors)\n",
    "holder.debug=DEBUG\n",
    "oldlocation = \"Total\"\n",
    "for detector in Detectors:\n",
    "    split = None\n",
    "    if detector in PDlist:\n",
    "        split = Splits[\"PD\"]\n",
    "    elif detector in FDlist:\n",
    "        split = Splits[\"FD\"]\n",
    "    elif detector in NDlist:\n",
    "        split = Splits[\"ND\"]\n",
    "    if split is None:\n",
    "        print (\"can't figure out split\", detector)\n",
    "        break\n",
    "    if DEBUG: print (split.keys())\n",
    "    for datatype in DataTypes:\n",
    "        #if datatype in holder.nosum: continue            \n",
    "        for resource in Resources:\n",
    "            thedatatype = datatype\n",
    "            if resource in holder.nosum: continue\n",
    "            #if resource in [\"CPU\",\"GPU\"]:  # right now this is generic \n",
    "            #    thedatatype = resource\n",
    "            for location in Locations:\n",
    "                if location in holder.nosum: continue\n",
    "                oldtag = holder.tag(detector,datatype,resource,oldlocation,BaseUnits[resource])\n",
    "                if oldtag not in holder.holder:\n",
    "                    if DEBUG: print (\"skip split tag\",oldtag)\n",
    "                    continue\n",
    "                if DEBUG: print (\"check\", resource,thedatatype,location)\n",
    "                if \"CPU\" in resource:\n",
    "                    factor = split[\"CPU\"][\"CPU\"][location]\n",
    "                elif \"GPU\" in resource:\n",
    "                    factor = split[\"GPU\"][\"GPU\"][location]\n",
    "                else:\n",
    "                    factor = split[resource][thedatatype][location]\n",
    "                if DEBUG: print (\"split\",factor)\n",
    "                newtag = holder.scale(detector= detector,datatype=datatype,resource=resource,location=oldlocation,units=BaseUnits[resource],\n",
    "                                      categories={\"Locations\":location},factor=factor,explanation=\"Split  by %.2f\"%factor)\n",
    "\n",
    "holder.csvDump(dirname,\"split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of generic storage\n",
    "for detector in Detectors:\n",
    "    for datatype in config[\"NativeTypes\"]:\n",
    "        location = \"Total\"\n",
    "        resource = \"Store\"\n",
    "        newtag = holder.tag(detector,datatype,location,resource,\"TB\")\n",
    "        if newtag in holder.holder:\n",
    "            holder.remove(newtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd241073",
   "metadata": {},
   "source": [
    "# do the cumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------- cumulate storage by retention -------------\")\n",
    "#DEBUG=True\n",
    "\n",
    "print (Detectors)\n",
    "for detector in Detectors:\n",
    "    if detector in holder.nosum: continue\n",
    "    for datatype in DataTypes:\n",
    "        if datatype in [\"Raw-Events\",\"Sim-Events\"]: continue\n",
    "        for newresource in [\"Disk\",\"Tape\"]:\n",
    "            for location in Locations+[\"Total\"]:\n",
    "\n",
    "                if newresource == \"Disk\": \n",
    "                    retain = DiskLifetimes[datatype]\n",
    "                    retresource = \"Cumulative-Disk\"\n",
    "                    if \"Reco\" in datatype:\n",
    "                        if DEBUG: print (\"extend later\",detector,datatype,newresource,location)\n",
    "                        retresource = \"Unextended-Cumulative-Disk\"\n",
    "                    #print (detector,datatype,newresource,location)\n",
    "\n",
    "                if newresource == \"Tape\": \n",
    "                    retain = TapeLifetimes[datatype]\n",
    "                    retresource = \"Cumulative-Tape\"\n",
    "\n",
    "                newertag = holder.cumulateMe(detector=detector,datatype=datatype,resource=newresource,location=location,units=\"TB\",categories={\"Resources\":retresource},period=retain,explanation=\"Look back %.2f years and keep that Storage \"%factor)\n",
    "                # if DEBUG: print (newertag,holder.holder,newertag)\n",
    "                # # and extend time for reconstructed disk so one can analyze\n",
    "                # if (\"Reco\" in datatype and retresource == \"Cumulative-Disk\"):\n",
    "                #     if DEBUG: print (\"extend by \",AnalysisExtend,newertag)\n",
    "                #     newertag = holder.extendMe(detector,datatype,retresource,location,\"TB\",{},AnalysisExtend)\n",
    "                if DEBUG: print (newertag)\n",
    "                \n",
    "holder.csvDump(dirname,\"cumulate.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ddd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------- extend reco samples on disk -------------\")\n",
    "#DEBUG=True\n",
    "print (Detectors)\n",
    "for detector in Detectors:\n",
    "    #if detector in holder.nosum: continue\n",
    "    for datatype in [\"Reco-Data\",\"Reco-Sim\"]:   \n",
    "        for newresource in [\"Unextended-Cumulative-Disk\"]:\n",
    "            for location in Locations+[\"Total\"]:\n",
    "                if \"Reco\" in datatype:\n",
    "                    #print (detector,datatype,newresource,location)\n",
    "                    pretag = holder.tag(detector,datatype,newresource,location,\"TB\")\n",
    "                    if pretag not in holder.holder:\n",
    "                        print (\"pretag not there\",pretag)\n",
    "                        continue\n",
    "                    if DEBUG: print (\"extend by \",AnalysisExtend,pretag)\n",
    "                    \n",
    "                    if DEBUG and pretag in holder.holder:\n",
    "                        print (holder.holder[pretag])\n",
    "                    #newtype = datatype.replace(\"Reco\",\"Analysis\")\n",
    "                    newertag = holder.extendMe(detector,datatype,newresource,location,\"TB\",{\"Resources\":\"Cumulative-Disk\"},AnalysisExtend,explanation=\"Extend disk by %.2f years as still analyzing\"%(AnalysisExtend))\n",
    "                    if DEBUG: print (\"removing\",pretag)\n",
    "                    holder.removeTag(pretag)\n",
    "                if DEBUG: print (newertag)\n",
    "                \n",
    "holder.csvDump(dirname,\"extend.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ab978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (Detectors)\n",
    "print (Locations)\n",
    "while \"Total\" in Detectors:\n",
    "    Detectors.remove(\"Total\")\n",
    "print (Detectors)\n",
    "print (\"------------------ sum across storage types -------------------\")\n",
    "StorageTypes=[\"Tape\",\"Disk\",\"Cumulative-Tape\",\"Cumulative-Disk\"]\n",
    "\n",
    "Storage = {\"Detectors\":Detectors,\"DataTypes\":DataTypes,\"Resources\":StorageTypes,\"Locations\":Locations,\"Units\":[\"TB\"]}\n",
    "\n",
    "#holder.debug=True\n",
    "holder.sumAcrossAll(filter=Storage,sumName=\"Total\",explanation=\"Sum across storage types\")\n",
    "holder.debug=DEBUG\n",
    "\n",
    "holder.csvDump(dirname,\"sumacross.csv\")\n",
    "print (Detectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce620b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeFilter={\"Detectors\":Detectors,\"DataTypes\":[\"Raw-Data\",\"Reco-Sim\",\"TP\",\"Test\"],\"Resources\":[\"Store\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "holder.sumAcrossAll(filter=storeFilter,sumName=\"Store-Total\",explanation=\"show raw added storage/year\")\n",
    "storeFilter={\"Detectors\":Detectors+[\"Store-Total\"],\"DataTypes\":[\"Raw-Data\",\"Reco-Sim\",\"TP\",\"Test\",\"Store-Total\"],\"Resources\":[\"Store\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "holder.csvDump(dirname,\"InputStore.csv\",filter=storeFilter,dropColumns=[\"Resources\",\"Locations\",\"Units\",\"Explanation\"],format=\"%d\")\n",
    "texfile.write(holder.TexTable(name=\"InputStore.csv\",caption=\"Initial raw storage generated by detector and type per year. Units are TB. This estimate does not include multiple copies.\",label=\"inputStore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009c9a5",
   "metadata": {},
   "source": [
    "## Define subsamples to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4839829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Storage = {\"Detectors\":(Detectors+[\"Total\"]),\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":StorageTypes,\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "TapeStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "CumulativeTapeStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "DiskStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "DiskStorageFDVD = {\"Detectors\":[\"FDVD\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "CumulativeDiskStorage = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "DiskStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "DiskStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "TapeStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "TapeStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "CumulativeDiskStorageByType = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes,\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "CumulativeDiskStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "CumulativeDiskStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "CumulativeTapeStorageByDetector = {\"Detectors\":Detectors,\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "CumulativeTapeStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":DataTypes,\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "CumulativeTapeStorageBySite = {\"Detectors\":[\"Total\"],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = holder.Draw(dirname,\"New Tape by Type\",YAxis=\"Storage\",Resource=\"Tape\",Category=\"DataTypes\",filter=TapeStorage)\n",
    "texfile.write(holder.TexFigure(fig,\"New Tape by data type.\",label=\"TapeByYearByType\"))\n",
    "              \n",
    "fig = holder.Draw(dirname,\"New Tape by Detector\",YAxis=\"Storage\",Resource=\"Tape\",Category=\"Detectors\",filter=TapeStorageByDetector)\n",
    "texfile.write(holder.TexFigure(fig,\"New Tape by detector.\",label=\"TapeByYearByDetector\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"New Tape by Site\",YAxis=\"Storage\",Resource=\"Tape\",Category=\"Locations\",filter=TapeStorageBySite)\n",
    "texfile.write(holder.TexFigure(fig,\"New Tape by site.\",label=\"TapeByYearBySite\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Tape by Type\",YAxis=\"Storage\",Resource=\"Cumulative-Tape\",Category=\"DataTypes\",filter=CumulativeTapeStorage)\n",
    "\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Tape by data type.\",label=\"TapeByYearByType\"))\n",
    "\n",
    "holder.csvDump(dirname,\"CumulativeTapeBySite.csv\",filter=CumulativeTapeStorageBySite,dropColumns=[\"Detectors\",\"DataTypes\",\"Resources\",\"Explanation\"],format=\"%d\")\n",
    "table = holder.TexTable(\"CumulativeTapeBySite.csv\",caption=\"Cumulative Tape by Site. Units are TB\",label=\"CumulativeTapeBySiteTable\")\n",
    "texfile.write(table)\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Tape by Detector\",YAxis=\"Storage\",Resource=\"Cumulative-Tape\",Category=\"Detectors\",filter=CumulativeTapeStorageByDetector)\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Tape by detector.\",label=\"TapeByYearByType\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Tape by Site\",YAxis=\"Storage\",Resource=\"Cumulative-Tape\",Category=\"Locations\",filter=CumulativeTapeStorageBySite)\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Tape by site.\",label=\"TapeByYearByType\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = holder.Draw(dirname,\"New Disk by Type\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"DataTypes\",filter=DiskStorage)\n",
    "texfile.write(holder.TexFigure(fig,\"New Disk by data type.\",label=\"DiskByYearByType\"))\n",
    "              \n",
    "fig = holder.Draw(dirname,\"New Disk by Detector\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"Detectors\",filter=DiskStorageByDetector)\n",
    "texfile.write(holder.TexFigure(fig,\"New Disk by detector.\",label=\"DiskByYearByDetector\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"New Disk by Site\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"Locations\",filter=DiskStorageBySite)\n",
    "texfile.write(holder.TexFigure(fig,\"New Disk by site.\",label=\"DiskByYearBySite\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Disk by Type\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"DataTypes\",filter=CumulativeDiskStorage)\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Disk by data type.\",label=\"DiskByYearByType\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Disk by Detector\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"Detectors\",filter=CumulativeDiskStorageByDetector)\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Disk by detector.\",label=\"DiskByYearByType\"))\n",
    "\n",
    "fig = holder.Draw(dirname,\"Cumulative Disk by Site\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"Locations\",filter=CumulativeDiskStorageBySite)\n",
    "texfile.write(holder.TexFigure(fig,\"Cumulative Disk by site.\",label=\"DiskByYearByType\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# holder.Draw(dirname,\"New Disk by Type\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"DataTypes\",filter=DiskStorage)\n",
    "# holder.Draw(dirname,\"New Disk by Type for FDVD\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"DataTypes\",filter=DiskStorageFDVD)\n",
    "# holder.Draw(dirname,\"New Disk by Detector\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"Detectors\",filter=DiskStorageByDetector)\n",
    "# holder.Draw(dirname,\"New Disk by Site\",YAxis=\"Storage\",Resource=\"Disk\",Category=\"Locations\",filter=DiskStorageBySite)\n",
    "# holder.Draw(dirname,\"Cumulative Disk by Type\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"DataTypes\",filter=CumulativeDiskStorage)\n",
    "# holder.Draw(dirname,\"Cumulative Disk by Detector\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"Detectors\",filter=CumulativeDiskStorageByDetector)\n",
    "# holder.Draw(dirname,\"Cumulative Disk by Site\",YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"Locations\",filter=CumulativeDiskStorageBySite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7abfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texfile.write(\"\\\\end{document}\")\n",
    "# texfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3ced8",
   "metadata": {},
   "source": [
    "# by detector plots\n",
    "\n",
    "for detector in Detectors:\n",
    "    if detector == \"Total\": continue\n",
    "    TapeStorage = {\"Detectors\":[detector],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    CumulativeTapeStorage = {\"Detectors\":[detector],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    DiskStorage = {\"Detectors\":[detector],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    CumulativeDiskStorage = {\"Detectors\":[detector],\"DataTypes\":DataTypes+[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    DiskStorageBySite = {\"Detectors\":[detector],\"DataTypes\":[\"Total\"],\"Resources\":[\"Disk\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "    \n",
    "    TapeStorageBySite = {\"Detectors\":[detector],\"DataTypes\":[\"Total\"],\"Resources\":[\"Tape\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    CumulativeDiskStorageBySite = {\"Detectors\":[detector],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Disk\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "    \n",
    "    CumulativeTapeStorageBySite = {\"Detectors\":[detector],\"DataTypes\":[\"Total\"],\"Resources\":[\"Cumulative-Tape\"],\"Locations\":Locations+[\"Total\"],\"Units\":[\"TB\"]}\n",
    "\n",
    "    holder.Draw(dirname,\"New Disk by Type \"+detector,YAxis=\"Storage\",Resource=\"Disk\",Category=\"DataTypes\",filter=DiskStorage)\n",
    "    \n",
    "    holder.Draw(dirname,\"New Disk by Site \"+detector,YAxis=\"Storage\",Resource=\"Disk\",Category=\"Locations\",filter=DiskStorageBySite)\n",
    "    holder.Draw(dirname,\"Cumulative Disk by Type \"+detector,YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"DataTypes\",filter=CumulativeDiskStorage)\n",
    "    \n",
    "    holder.Draw(dirname,\"Cumulative Disk by Site \"+detector,YAxis=\"Storage\",Resource=\"Cumulative-Disk\",Category=\"Locations\",filter=CumulativeDiskStorageBySite)\n",
    "\n",
    "    holder.Draw(dirname,\"New Tape by Type \"+detector,YAxis=\"Storage\",Resource=\"Tape\",Category=\"DataTypes\",filter=TapeStorage)\n",
    "    #holder.Draw(dirname,\"New Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=TapeStorageByDetector)\n",
    "    holder.Draw(dirname,\"New Tape by Site \"+detector,YAxis=\"Storage\",Resource=\"Tape\",Category=\"Locations\",filter=TapeStorageBySite)\n",
    "    holder.Draw(dirname,\"Cumulative Tape by Type \"+detector,YAxis=\"Storage\",Resource=\"Cumulative-Tape\",Category=\"DataTypes\",filter=CumulativeTapeStorage)\n",
    "    #holder.Draw(dirname,\"Cumulative Tape by Detector\",YAxis=\"Storage\",Category=\"Detectors\",filter=CumulativeTapeStorageByDetector)\n",
    "    holder.Draw(dirname,\"Cumulative Tape by Site \"+detector,YAxis=\"Storage\",Resource=\"Cumulative-Tape\",Category=\"Locations\",filter=CumulativeTapeStorageBySite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texfile.write(\"\\\\end{document}\")\n",
    "texfile.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
